{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(\"Pipeline\")\n",
    "log.setLevel(logging.INFO)\n",
    "format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(format)\n",
    "log.addHandler(ch)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import predict_mortality as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directory\n",
    "\n",
    "A top level directory to store all the data for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirName = '/home/yram0006/phd/chapter_2/workspace/mortality_data/imbalance_experiment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity_WHITE</th>\n",
       "      <th>ethnicity_BLACK</th>\n",
       "      <th>ethnicity_UNKNOWN</th>\n",
       "      <th>ethnicity_OTHER</th>\n",
       "      <th>ethnicity_HISPANIC</th>\n",
       "      <th>ethnicity_ASIAN</th>\n",
       "      <th>ethnicity_UNABLE_TO_OBTAIN</th>\n",
       "      <th>ethnicity_AMERICAN_INDIAN</th>\n",
       "      <th>anchor_time</th>\n",
       "      <th>death_datetime</th>\n",
       "      <th>heartrate_min</th>\n",
       "      <th>sysbp_min</th>\n",
       "      <th>diabp_min</th>\n",
       "      <th>meanbp_min</th>\n",
       "      <th>resprate_min</th>\n",
       "      <th>tempc_min</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>gcseye_min</th>\n",
       "      <th>gcsverbal_min</th>\n",
       "      <th>gcsmotor_min</th>\n",
       "      <th>heartrate_max</th>\n",
       "      <th>sysbp_max</th>\n",
       "      <th>diabp_max</th>\n",
       "      <th>meanbp_max</th>\n",
       "      <th>resprate_max</th>\n",
       "      <th>tempc_max</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>gcseye_max</th>\n",
       "      <th>gcsverbal_max</th>\n",
       "      <th>gcsmotor_max</th>\n",
       "      <th>heartrate_avg</th>\n",
       "      <th>sysbp_avg</th>\n",
       "      <th>diabp_avg</th>\n",
       "      <th>meanbp_avg</th>\n",
       "      <th>resprate_avg</th>\n",
       "      <th>tempc_avg</th>\n",
       "      <th>spo2_avg</th>\n",
       "      <th>gcseye_avg</th>\n",
       "      <th>gcsverbal_avg</th>\n",
       "      <th>gcsmotor_avg</th>\n",
       "      <th>heartrate_stddev</th>\n",
       "      <th>sysbp_stddev</th>\n",
       "      <th>diabp_stddev</th>\n",
       "      <th>meanbp_stddev</th>\n",
       "      <th>resprate_stddev</th>\n",
       "      <th>tempc_stddev</th>\n",
       "      <th>spo2_stddev</th>\n",
       "      <th>gcseye_stddev</th>\n",
       "      <th>gcsverbal_stddev</th>\n",
       "      <th>gcsmotor_stddev</th>\n",
       "      <th>heartrate_first</th>\n",
       "      <th>sysbp_first</th>\n",
       "      <th>diabp_first</th>\n",
       "      <th>meanbp_first</th>\n",
       "      <th>resprate_first</th>\n",
       "      <th>tempc_first</th>\n",
       "      <th>spo2_first</th>\n",
       "      <th>gcseye_first</th>\n",
       "      <th>gcsverbal_first</th>\n",
       "      <th>gcsmotor_first</th>\n",
       "      <th>heartrate_last</th>\n",
       "      <th>sysbp_last</th>\n",
       "      <th>diabp_last</th>\n",
       "      <th>meanbp_last</th>\n",
       "      <th>resprate_last</th>\n",
       "      <th>tempc_last</th>\n",
       "      <th>spo2_last</th>\n",
       "      <th>gcseye_last</th>\n",
       "      <th>gcsverbal_last</th>\n",
       "      <th>gcsmotor_last</th>\n",
       "      <th>chloride_serum_min</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>sodium_serum_min</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>platelet_count_min</th>\n",
       "      <th>urea_nitrogen_min</th>\n",
       "      <th>glucose_serum_min</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>potassium_serum_min</th>\n",
       "      <th>anion_gap_min</th>\n",
       "      <th>leukocytes_blood_manual_min</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>chloride_serum_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>sodium_serum_max</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelet_count_max</th>\n",
       "      <th>urea_nitrogen_max</th>\n",
       "      <th>glucose_serum_max</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>potassium_serum_max</th>\n",
       "      <th>anion_gap_max</th>\n",
       "      <th>leukocytes_blood_manual_max</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>chloride_serum_avg</th>\n",
       "      <th>creatinine_avg</th>\n",
       "      <th>sodium_serum_avg</th>\n",
       "      <th>hemoglobin_avg</th>\n",
       "      <th>platelet_count_avg</th>\n",
       "      <th>urea_nitrogen_avg</th>\n",
       "      <th>glucose_serum_avg</th>\n",
       "      <th>bicarbonate_avg</th>\n",
       "      <th>potassium_serum_avg</th>\n",
       "      <th>anion_gap_avg</th>\n",
       "      <th>leukocytes_blood_manual_avg</th>\n",
       "      <th>hematocrit_avg</th>\n",
       "      <th>chloride_serum_stddev</th>\n",
       "      <th>creatinine_stddev</th>\n",
       "      <th>sodium_serum_stddev</th>\n",
       "      <th>hemoglobin_stddev</th>\n",
       "      <th>glucose_serum_stddev</th>\n",
       "      <th>bicarbonate_stddev</th>\n",
       "      <th>potassium_serum_stddev</th>\n",
       "      <th>chloride_serum_first</th>\n",
       "      <th>creatinine_first</th>\n",
       "      <th>sodium_serum_first</th>\n",
       "      <th>hemoglobin_first</th>\n",
       "      <th>platelet_count_first</th>\n",
       "      <th>urea_nitrogen_first</th>\n",
       "      <th>glucose_serum_first</th>\n",
       "      <th>bicarbonate_first</th>\n",
       "      <th>potassium_serum_first</th>\n",
       "      <th>anion_gap_first</th>\n",
       "      <th>leukocytes_blood_manual_first</th>\n",
       "      <th>hematocrit_first</th>\n",
       "      <th>chloride_serum_last</th>\n",
       "      <th>creatinine_last</th>\n",
       "      <th>sodium_serum_last</th>\n",
       "      <th>hemoglobin_last</th>\n",
       "      <th>platelet_count_last</th>\n",
       "      <th>urea_nitrogen_last</th>\n",
       "      <th>glucose_serum_last</th>\n",
       "      <th>bicarbonate_last</th>\n",
       "      <th>potassium_serum_last</th>\n",
       "      <th>anion_gap_last</th>\n",
       "      <th>leukocytes_blood_manual_last</th>\n",
       "      <th>hematocrit_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2144679073</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2190-01-30 19:22:00</td>\n",
       "      <td>2194-04-23 19:27:00</td>\n",
       "      <td>-0.272794</td>\n",
       "      <td>1.217771</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>0.861968</td>\n",
       "      <td>0.878048</td>\n",
       "      <td>0.189353</td>\n",
       "      <td>0.317249</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.030099</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>0.069606</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>-0.309282</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.671766</td>\n",
       "      <td>0.838925</td>\n",
       "      <td>0.734657</td>\n",
       "      <td>0.755136</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>0.595497</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.047481</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>-0.025099</td>\n",
       "      <td>-0.700168</td>\n",
       "      <td>-0.113932</td>\n",
       "      <td>-0.042762</td>\n",
       "      <td>-0.054623</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-1.241070</td>\n",
       "      <td>-0.100946</td>\n",
       "      <td>-0.093761</td>\n",
       "      <td>-0.277365</td>\n",
       "      <td>-0.176019</td>\n",
       "      <td>-0.090217</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.521863</td>\n",
       "      <td>1.715295</td>\n",
       "      <td>0.616779</td>\n",
       "      <td>0.846636</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>1.093242</td>\n",
       "      <td>-0.663478</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>0.285937</td>\n",
       "      <td>0.076969</td>\n",
       "      <td>-0.734973</td>\n",
       "      <td>-0.012647</td>\n",
       "      <td>0.669296</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.915664</td>\n",
       "      <td>-0.348052</td>\n",
       "      <td>0.099873</td>\n",
       "      <td>0.214809</td>\n",
       "      <td>-0.011713</td>\n",
       "      <td>-0.309154</td>\n",
       "      <td>-0.534404</td>\n",
       "      <td>0.297850</td>\n",
       "      <td>-0.994593</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-1.025656</td>\n",
       "      <td>-0.767333</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>-0.395681</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>-0.014171</td>\n",
       "      <td>-0.015245</td>\n",
       "      <td>-0.012701</td>\n",
       "      <td>0.347919</td>\n",
       "      <td>-0.948893</td>\n",
       "      <td>-0.020354</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>-0.013272</td>\n",
       "      <td>-1.114836</td>\n",
       "      <td>-0.162093</td>\n",
       "      <td>-0.233373</td>\n",
       "      <td>-0.012429</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.590509</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>-0.030961</td>\n",
       "      <td>-0.601701</td>\n",
       "      <td>-1.056430</td>\n",
       "      <td>0.743687</td>\n",
       "      <td>-0.694348</td>\n",
       "      <td>-0.191987</td>\n",
       "      <td>-0.406075</td>\n",
       "      <td>0.116251</td>\n",
       "      <td>-0.789275</td>\n",
       "      <td>-0.022292</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>-0.788282</td>\n",
       "      <td>-1.346000</td>\n",
       "      <td>-0.054095</td>\n",
       "      <td>-0.572535</td>\n",
       "      <td>0.656699</td>\n",
       "      <td>-0.695650</td>\n",
       "      <td>-0.087780</td>\n",
       "      <td>0.157334</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.863655</td>\n",
       "      <td>-0.015096</td>\n",
       "      <td>0.214490</td>\n",
       "      <td>-0.408989</td>\n",
       "      <td>-0.979015</td>\n",
       "      <td>-0.516496</td>\n",
       "      <td>0.100735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2142084288</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2161-07-10 08:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073643</td>\n",
       "      <td>-0.427373</td>\n",
       "      <td>0.222451</td>\n",
       "      <td>-1.935422</td>\n",
       "      <td>1.165394</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>-0.256040</td>\n",
       "      <td>1.199315</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>-0.026310</td>\n",
       "      <td>-0.053989</td>\n",
       "      <td>-0.057963</td>\n",
       "      <td>-0.040074</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.134094</td>\n",
       "      <td>-0.066312</td>\n",
       "      <td>0.750897</td>\n",
       "      <td>0.395390</td>\n",
       "      <td>0.617088</td>\n",
       "      <td>0.086249</td>\n",
       "      <td>-0.167731</td>\n",
       "      <td>0.860623</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>-0.347862</td>\n",
       "      <td>-0.101546</td>\n",
       "      <td>-0.018473</td>\n",
       "      <td>-1.069636</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.299599</td>\n",
       "      <td>0.244989</td>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.378146</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.305525</td>\n",
       "      <td>-0.056425</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.313804</td>\n",
       "      <td>0.682207</td>\n",
       "      <td>1.280328</td>\n",
       "      <td>1.020767</td>\n",
       "      <td>1.692185</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>0.793315</td>\n",
       "      <td>-0.435926</td>\n",
       "      <td>0.507737</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.477509</td>\n",
       "      <td>-0.012129</td>\n",
       "      <td>0.066001</td>\n",
       "      <td>-0.301095</td>\n",
       "      <td>-0.563366</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>0.502304</td>\n",
       "      <td>0.510556</td>\n",
       "      <td>-0.011635</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.320511</td>\n",
       "      <td>0.179330</td>\n",
       "      <td>-0.090891</td>\n",
       "      <td>-0.021989</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.292875</td>\n",
       "      <td>-0.091176</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.390295</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>0.012011</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>-0.067964</td>\n",
       "      <td>-0.387671</td>\n",
       "      <td>-0.018131</td>\n",
       "      <td>-0.019468</td>\n",
       "      <td>-0.011258</td>\n",
       "      <td>-0.206481</td>\n",
       "      <td>-0.083122</td>\n",
       "      <td>0.450207</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.011498</td>\n",
       "      <td>-0.343805</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.029291</td>\n",
       "      <td>-0.226259</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.474016</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>0.614182</td>\n",
       "      <td>0.464202</td>\n",
       "      <td>-0.020737</td>\n",
       "      <td>-0.276849</td>\n",
       "      <td>-0.022242</td>\n",
       "      <td>0.012654</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>-0.216607</td>\n",
       "      <td>0.465424</td>\n",
       "      <td>0.183603</td>\n",
       "      <td>-0.508245</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>0.430555</td>\n",
       "      <td>0.701722</td>\n",
       "      <td>-0.447977</td>\n",
       "      <td>-0.013025</td>\n",
       "      <td>-0.196256</td>\n",
       "      <td>-0.900551</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.217026</td>\n",
       "      <td>0.473387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2133944014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141-03-25 16:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.173219</td>\n",
       "      <td>0.630220</td>\n",
       "      <td>0.572854</td>\n",
       "      <td>0.478013</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>0.147108</td>\n",
       "      <td>-0.419837</td>\n",
       "      <td>-0.374217</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.020620</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>-0.012100</td>\n",
       "      <td>-0.044139</td>\n",
       "      <td>-0.215037</td>\n",
       "      <td>-0.080454</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.322070</td>\n",
       "      <td>0.427622</td>\n",
       "      <td>0.130176</td>\n",
       "      <td>0.083759</td>\n",
       "      <td>-0.701402</td>\n",
       "      <td>-0.062385</td>\n",
       "      <td>-0.402458</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>0.394775</td>\n",
       "      <td>0.594702</td>\n",
       "      <td>-0.024181</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.048238</td>\n",
       "      <td>-0.064594</td>\n",
       "      <td>-0.313192</td>\n",
       "      <td>-0.119714</td>\n",
       "      <td>-0.001438</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>1.970708</td>\n",
       "      <td>-0.371864</td>\n",
       "      <td>-0.770334</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-0.327789</td>\n",
       "      <td>-0.803119</td>\n",
       "      <td>0.165851</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>-0.907586</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>-0.230580</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>-0.227737</td>\n",
       "      <td>-0.198151</td>\n",
       "      <td>-0.315867</td>\n",
       "      <td>-0.055249</td>\n",
       "      <td>-0.217421</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-2.655837</td>\n",
       "      <td>-0.663478</td>\n",
       "      <td>-1.213852</td>\n",
       "      <td>1.694168</td>\n",
       "      <td>0.872452</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>2.680281</td>\n",
       "      <td>-1.717605</td>\n",
       "      <td>-0.397756</td>\n",
       "      <td>1.230034</td>\n",
       "      <td>1.542830</td>\n",
       "      <td>-2.151170</td>\n",
       "      <td>-0.011679</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>1.507893</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>-0.444643</td>\n",
       "      <td>-0.017503</td>\n",
       "      <td>0.094229</td>\n",
       "      <td>-0.366390</td>\n",
       "      <td>-0.828988</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.916153</td>\n",
       "      <td>-0.031538</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.072093</td>\n",
       "      <td>-0.010550</td>\n",
       "      <td>0.218245</td>\n",
       "      <td>-0.646831</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.170743</td>\n",
       "      <td>-0.014433</td>\n",
       "      <td>-0.872370</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>1.647657</td>\n",
       "      <td>-0.011455</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.027636</td>\n",
       "      <td>-0.299876</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>-2.627203</td>\n",
       "      <td>-0.463035</td>\n",
       "      <td>-1.481858</td>\n",
       "      <td>1.160423</td>\n",
       "      <td>0.739696</td>\n",
       "      <td>-0.305407</td>\n",
       "      <td>-0.020149</td>\n",
       "      <td>2.156819</td>\n",
       "      <td>-1.768456</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>0.737925</td>\n",
       "      <td>1.165595</td>\n",
       "      <td>-2.339573</td>\n",
       "      <td>-0.695650</td>\n",
       "      <td>-1.690266</td>\n",
       "      <td>1.523437</td>\n",
       "      <td>0.575731</td>\n",
       "      <td>-0.612072</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>2.062846</td>\n",
       "      <td>-0.408989</td>\n",
       "      <td>-0.658492</td>\n",
       "      <td>0.160877</td>\n",
       "      <td>1.557531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2133227983</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2120-09-22 10:15:00</td>\n",
       "      <td>2121-08-28 15:15:00</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>-1.073680</td>\n",
       "      <td>0.485253</td>\n",
       "      <td>-1.441765</td>\n",
       "      <td>0.447029</td>\n",
       "      <td>0.133026</td>\n",
       "      <td>0.235350</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>-0.389695</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.017735</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>0.161941</td>\n",
       "      <td>-0.003364</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.203561</td>\n",
       "      <td>-0.427533</td>\n",
       "      <td>0.646238</td>\n",
       "      <td>0.240893</td>\n",
       "      <td>-0.310939</td>\n",
       "      <td>-0.113208</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>0.754573</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>0.281090</td>\n",
       "      <td>-0.021139</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>-0.066404</td>\n",
       "      <td>-0.042251</td>\n",
       "      <td>-0.338743</td>\n",
       "      <td>0.659022</td>\n",
       "      <td>-0.068008</td>\n",
       "      <td>0.312356</td>\n",
       "      <td>0.763893</td>\n",
       "      <td>0.476888</td>\n",
       "      <td>1.941287</td>\n",
       "      <td>0.952761</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>-0.188968</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>-0.024020</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.041730</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>-0.730035</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.256426</td>\n",
       "      <td>-0.891030</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>-0.166709</td>\n",
       "      <td>0.670751</td>\n",
       "      <td>-0.731453</td>\n",
       "      <td>-0.011784</td>\n",
       "      <td>1.272592</td>\n",
       "      <td>-2.071733</td>\n",
       "      <td>-0.638644</td>\n",
       "      <td>0.063069</td>\n",
       "      <td>-0.119478</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.061238</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>1.143237</td>\n",
       "      <td>-0.712930</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>-0.514545</td>\n",
       "      <td>-0.017100</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>-0.014468</td>\n",
       "      <td>-0.014352</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>-0.012580</td>\n",
       "      <td>0.950606</td>\n",
       "      <td>-0.886384</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>0.068637</td>\n",
       "      <td>-0.013154</td>\n",
       "      <td>-0.659500</td>\n",
       "      <td>-0.175868</td>\n",
       "      <td>0.104515</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>-0.013936</td>\n",
       "      <td>-0.011738</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>-0.282218</td>\n",
       "      <td>2.463369</td>\n",
       "      <td>-0.469833</td>\n",
       "      <td>-0.867833</td>\n",
       "      <td>-0.191987</td>\n",
       "      <td>0.159605</td>\n",
       "      <td>0.750668</td>\n",
       "      <td>-0.891840</td>\n",
       "      <td>-0.022641</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>-0.897190</td>\n",
       "      <td>-0.373601</td>\n",
       "      <td>0.148029</td>\n",
       "      <td>0.173951</td>\n",
       "      <td>0.183603</td>\n",
       "      <td>-0.883055</td>\n",
       "      <td>0.513153</td>\n",
       "      <td>-0.498395</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>-0.749180</td>\n",
       "      <td>-0.011385</td>\n",
       "      <td>1.446727</td>\n",
       "      <td>-0.900551</td>\n",
       "      <td>-1.200746</td>\n",
       "      <td>-0.014856</td>\n",
       "      <td>-0.475707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2132499549</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2205-11-16 13:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>-0.662394</td>\n",
       "      <td>-0.127953</td>\n",
       "      <td>0.148908</td>\n",
       "      <td>0.878048</td>\n",
       "      <td>0.161190</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.007843</td>\n",
       "      <td>-0.019251</td>\n",
       "      <td>-0.072492</td>\n",
       "      <td>-0.099956</td>\n",
       "      <td>-0.183622</td>\n",
       "      <td>-0.098809</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.038396</td>\n",
       "      <td>-0.330845</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>-0.222650</td>\n",
       "      <td>-0.361032</td>\n",
       "      <td>-0.180333</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.507121</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>-0.032613</td>\n",
       "      <td>-0.041233</td>\n",
       "      <td>-0.560680</td>\n",
       "      <td>-0.134095</td>\n",
       "      <td>-0.023838</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.017158</td>\n",
       "      <td>-0.187430</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.325661</td>\n",
       "      <td>-0.113496</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>0.726492</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>-0.107092</td>\n",
       "      <td>-0.067553</td>\n",
       "      <td>1.118455</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>0.123383</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>1.393168</td>\n",
       "      <td>0.322582</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>-0.217003</td>\n",
       "      <td>0.273945</td>\n",
       "      <td>0.984810</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.939492</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>0.062941</td>\n",
       "      <td>-0.121743</td>\n",
       "      <td>-0.197396</td>\n",
       "      <td>0.362682</td>\n",
       "      <td>-0.011601</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.156544</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>-0.025130</td>\n",
       "      <td>-0.086899</td>\n",
       "      <td>-0.696023</td>\n",
       "      <td>1.220035</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.164904</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>-0.023033</td>\n",
       "      <td>-0.012630</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.343322</td>\n",
       "      <td>-0.021086</td>\n",
       "      <td>-0.108780</td>\n",
       "      <td>-0.012621</td>\n",
       "      <td>0.272497</td>\n",
       "      <td>0.315003</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.012592</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>-0.698913</td>\n",
       "      <td>-0.011672</td>\n",
       "      <td>-0.031460</td>\n",
       "      <td>-1.112750</td>\n",
       "      <td>-0.219378</td>\n",
       "      <td>1.013358</td>\n",
       "      <td>0.057419</td>\n",
       "      <td>0.130480</td>\n",
       "      <td>0.203119</td>\n",
       "      <td>-0.207427</td>\n",
       "      <td>0.379972</td>\n",
       "      <td>-0.023489</td>\n",
       "      <td>-1.351814</td>\n",
       "      <td>-0.243741</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>-0.110297</td>\n",
       "      <td>0.278954</td>\n",
       "      <td>0.814397</td>\n",
       "      <td>0.116439</td>\n",
       "      <td>-0.488402</td>\n",
       "      <td>-0.553039</td>\n",
       "      <td>0.463571</td>\n",
       "      <td>0.272386</td>\n",
       "      <td>-0.015010</td>\n",
       "      <td>-1.428493</td>\n",
       "      <td>-0.736697</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.490582</td>\n",
       "      <td>-0.508395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2142664100</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2180-08-11 04:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.922114</td>\n",
       "      <td>0.042668</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>0.478013</td>\n",
       "      <td>0.590702</td>\n",
       "      <td>0.147108</td>\n",
       "      <td>-0.911228</td>\n",
       "      <td>1.199315</td>\n",
       "      <td>0.696753</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>-0.021719</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.787906</td>\n",
       "      <td>0.176275</td>\n",
       "      <td>1.271708</td>\n",
       "      <td>0.677604</td>\n",
       "      <td>1.480574</td>\n",
       "      <td>-0.004342</td>\n",
       "      <td>-0.016273</td>\n",
       "      <td>0.860623</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.050465</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>-0.074307</td>\n",
       "      <td>-0.069785</td>\n",
       "      <td>0.021901</td>\n",
       "      <td>-1.069636</td>\n",
       "      <td>-0.299347</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>1.159680</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.144009</td>\n",
       "      <td>0.428570</td>\n",
       "      <td>1.454441</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>0.518433</td>\n",
       "      <td>1.198751</td>\n",
       "      <td>1.400973</td>\n",
       "      <td>1.020767</td>\n",
       "      <td>0.257862</td>\n",
       "      <td>-0.075527</td>\n",
       "      <td>-0.103820</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.406390</td>\n",
       "      <td>-0.435926</td>\n",
       "      <td>-0.525217</td>\n",
       "      <td>-0.367884</td>\n",
       "      <td>-0.880643</td>\n",
       "      <td>-0.593669</td>\n",
       "      <td>-0.010576</td>\n",
       "      <td>0.468198</td>\n",
       "      <td>-0.478159</td>\n",
       "      <td>-0.512178</td>\n",
       "      <td>-0.135230</td>\n",
       "      <td>-0.414490</td>\n",
       "      <td>-0.672433</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>-0.296928</td>\n",
       "      <td>-0.630374</td>\n",
       "      <td>-0.760493</td>\n",
       "      <td>-0.020095</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.696023</td>\n",
       "      <td>-0.391233</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.288525</td>\n",
       "      <td>-0.016472</td>\n",
       "      <td>-0.013880</td>\n",
       "      <td>-0.040554</td>\n",
       "      <td>-0.013052</td>\n",
       "      <td>-0.742526</td>\n",
       "      <td>-0.717218</td>\n",
       "      <td>-0.016265</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-0.012700</td>\n",
       "      <td>-0.209341</td>\n",
       "      <td>-0.086127</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>0.060371</td>\n",
       "      <td>-0.011835</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>0.316081</td>\n",
       "      <td>-0.427042</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>-0.405207</td>\n",
       "      <td>0.130480</td>\n",
       "      <td>-0.101478</td>\n",
       "      <td>-0.497942</td>\n",
       "      <td>-0.758304</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>-0.570466</td>\n",
       "      <td>-0.026771</td>\n",
       "      <td>-0.490395</td>\n",
       "      <td>-0.095195</td>\n",
       "      <td>-1.077985</td>\n",
       "      <td>-0.383308</td>\n",
       "      <td>-1.289645</td>\n",
       "      <td>-0.389107</td>\n",
       "      <td>-1.005746</td>\n",
       "      <td>-0.521972</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>0.214490</td>\n",
       "      <td>0.082574</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.718153</td>\n",
       "      <td>-0.414065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2144053271</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2139-06-14 18:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.770673</td>\n",
       "      <td>-0.309863</td>\n",
       "      <td>-1.266765</td>\n",
       "      <td>0.203759</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>-0.289426</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>-1.160983</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>-1.403987</td>\n",
       "      <td>-0.006195</td>\n",
       "      <td>-0.017626</td>\n",
       "      <td>-0.097359</td>\n",
       "      <td>-0.086823</td>\n",
       "      <td>-0.152207</td>\n",
       "      <td>-0.095138</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>-2.337273</td>\n",
       "      <td>-1.693958</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.392198</td>\n",
       "      <td>-0.085976</td>\n",
       "      <td>-0.199819</td>\n",
       "      <td>-0.157516</td>\n",
       "      <td>-0.607566</td>\n",
       "      <td>-0.704260</td>\n",
       "      <td>0.203160</td>\n",
       "      <td>-2.261975</td>\n",
       "      <td>-1.329666</td>\n",
       "      <td>-0.781980</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>-0.021687</td>\n",
       "      <td>-0.074604</td>\n",
       "      <td>0.230779</td>\n",
       "      <td>-0.051405</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>-0.524861</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>2.324226</td>\n",
       "      <td>0.171136</td>\n",
       "      <td>0.677409</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-1.033723</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.119293</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>-1.725934</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>-2.087210</td>\n",
       "      <td>-0.272192</td>\n",
       "      <td>-0.907158</td>\n",
       "      <td>-0.408705</td>\n",
       "      <td>0.672505</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>-2.086777</td>\n",
       "      <td>-1.272249</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.406390</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>-0.525217</td>\n",
       "      <td>0.436819</td>\n",
       "      <td>-0.264909</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>-0.015064</td>\n",
       "      <td>-0.738393</td>\n",
       "      <td>-0.478159</td>\n",
       "      <td>0.526649</td>\n",
       "      <td>0.214830</td>\n",
       "      <td>0.322694</td>\n",
       "      <td>-0.672433</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>-0.679547</td>\n",
       "      <td>-0.154442</td>\n",
       "      <td>0.201483</td>\n",
       "      <td>0.676810</td>\n",
       "      <td>-0.023983</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>-0.586146</td>\n",
       "      <td>-0.074734</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.188810</td>\n",
       "      <td>-0.017731</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>-0.053070</td>\n",
       "      <td>-0.012299</td>\n",
       "      <td>0.139068</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>-0.020678</td>\n",
       "      <td>-0.006364</td>\n",
       "      <td>-0.012291</td>\n",
       "      <td>0.406005</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>0.265825</td>\n",
       "      <td>-0.011921</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.108793</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>3.064577</td>\n",
       "      <td>-0.380575</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>1.618781</td>\n",
       "      <td>-0.836923</td>\n",
       "      <td>-0.188505</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>1.442229</td>\n",
       "      <td>-0.022292</td>\n",
       "      <td>-0.572118</td>\n",
       "      <td>-0.134833</td>\n",
       "      <td>-0.099116</td>\n",
       "      <td>0.159315</td>\n",
       "      <td>-0.189184</td>\n",
       "      <td>-1.077985</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>-0.488402</td>\n",
       "      <td>0.594487</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>-0.013456</td>\n",
       "      <td>1.446727</td>\n",
       "      <td>-0.081281</td>\n",
       "      <td>-0.438956</td>\n",
       "      <td>-0.033435</td>\n",
       "      <td>0.564168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2144497079</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2150-04-26 14:47:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.019612</td>\n",
       "      <td>0.512710</td>\n",
       "      <td>-0.565958</td>\n",
       "      <td>0.094057</td>\n",
       "      <td>0.590702</td>\n",
       "      <td>0.076699</td>\n",
       "      <td>-0.256040</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.024741</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.514026</td>\n",
       "      <td>-0.057963</td>\n",
       "      <td>-0.091467</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.518790</td>\n",
       "      <td>0.179749</td>\n",
       "      <td>-0.911257</td>\n",
       "      <td>0.063392</td>\n",
       "      <td>-0.454063</td>\n",
       "      <td>-0.207270</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0.779046</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.022060</td>\n",
       "      <td>-0.031759</td>\n",
       "      <td>-0.065296</td>\n",
       "      <td>0.342646</td>\n",
       "      <td>-0.375325</td>\n",
       "      <td>-0.118352</td>\n",
       "      <td>-0.037418</td>\n",
       "      <td>-0.441552</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-2.229614</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>-0.272089</td>\n",
       "      <td>-0.781604</td>\n",
       "      <td>-0.552279</td>\n",
       "      <td>-0.113496</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.022521</td>\n",
       "      <td>-0.390614</td>\n",
       "      <td>-1.011931</td>\n",
       "      <td>-0.546413</td>\n",
       "      <td>-0.459299</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-1.606095</td>\n",
       "      <td>1.232790</td>\n",
       "      <td>-1.730329</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>-0.683765</td>\n",
       "      <td>0.512624</td>\n",
       "      <td>-0.011180</td>\n",
       "      <td>-1.341689</td>\n",
       "      <td>-0.301095</td>\n",
       "      <td>1.896696</td>\n",
       "      <td>-0.401998</td>\n",
       "      <td>0.279656</td>\n",
       "      <td>-1.855423</td>\n",
       "      <td>-0.011238</td>\n",
       "      <td>-1.420333</td>\n",
       "      <td>1.127931</td>\n",
       "      <td>-0.764876</td>\n",
       "      <td>2.620960</td>\n",
       "      <td>-0.017553</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>1.611406</td>\n",
       "      <td>1.663956</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>1.050925</td>\n",
       "      <td>-0.026598</td>\n",
       "      <td>-0.011229</td>\n",
       "      <td>-0.112234</td>\n",
       "      <td>-0.011756</td>\n",
       "      <td>-0.688077</td>\n",
       "      <td>2.200226</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.050189</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>1.899387</td>\n",
       "      <td>-0.263500</td>\n",
       "      <td>0.504531</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>0.503888</td>\n",
       "      <td>-0.011802</td>\n",
       "      <td>-0.026767</td>\n",
       "      <td>1.913836</td>\n",
       "      <td>1.704332</td>\n",
       "      <td>-1.683354</td>\n",
       "      <td>1.792265</td>\n",
       "      <td>-1.643092</td>\n",
       "      <td>1.203937</td>\n",
       "      <td>-0.637141</td>\n",
       "      <td>2.378993</td>\n",
       "      <td>-0.018703</td>\n",
       "      <td>-0.961966</td>\n",
       "      <td>2.043330</td>\n",
       "      <td>2.101017</td>\n",
       "      <td>-0.185685</td>\n",
       "      <td>1.126822</td>\n",
       "      <td>-1.866477</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>-1.289645</td>\n",
       "      <td>0.867708</td>\n",
       "      <td>-0.538783</td>\n",
       "      <td>0.261505</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.737990</td>\n",
       "      <td>1.598340</td>\n",
       "      <td>-0.298061</td>\n",
       "      <td>0.631974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2144648302</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2143-12-22 17:48:00</td>\n",
       "      <td>2143-12-24 05:35:00</td>\n",
       "      <td>-3.459217</td>\n",
       "      <td>-3.247620</td>\n",
       "      <td>-1.704770</td>\n",
       "      <td>-1.935422</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>-0.021873</td>\n",
       "      <td>-0.911228</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.031704</td>\n",
       "      <td>-0.086702</td>\n",
       "      <td>-0.122939</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>-0.128177</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.678164</td>\n",
       "      <td>-1.085512</td>\n",
       "      <td>-0.395568</td>\n",
       "      <td>-0.793937</td>\n",
       "      <td>-0.022948</td>\n",
       "      <td>-0.587398</td>\n",
       "      <td>-1.195107</td>\n",
       "      <td>0.012219</td>\n",
       "      <td>-0.539297</td>\n",
       "      <td>0.097823</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.079971</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>-0.115571</td>\n",
       "      <td>0.078197</td>\n",
       "      <td>-0.095112</td>\n",
       "      <td>1.301948</td>\n",
       "      <td>-0.164944</td>\n",
       "      <td>0.830165</td>\n",
       "      <td>-0.100946</td>\n",
       "      <td>0.108344</td>\n",
       "      <td>0.680689</td>\n",
       "      <td>-1.053958</td>\n",
       "      <td>-0.439401</td>\n",
       "      <td>-0.138311</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-3.559525</td>\n",
       "      <td>-3.529610</td>\n",
       "      <td>-2.459673</td>\n",
       "      <td>-2.723052</td>\n",
       "      <td>-2.897648</td>\n",
       "      <td>-0.109323</td>\n",
       "      <td>-0.899028</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>-0.730035</td>\n",
       "      <td>-0.060988</td>\n",
       "      <td>0.493389</td>\n",
       "      <td>1.612044</td>\n",
       "      <td>0.679896</td>\n",
       "      <td>2.096520</td>\n",
       "      <td>-0.831423</td>\n",
       "      <td>2.574353</td>\n",
       "      <td>-0.011180</td>\n",
       "      <td>-0.336196</td>\n",
       "      <td>2.886052</td>\n",
       "      <td>1.896696</td>\n",
       "      <td>1.065230</td>\n",
       "      <td>2.344742</td>\n",
       "      <td>0.066935</td>\n",
       "      <td>-0.011420</td>\n",
       "      <td>-0.309154</td>\n",
       "      <td>1.080435</td>\n",
       "      <td>-1.184207</td>\n",
       "      <td>1.840625</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>-0.052399</td>\n",
       "      <td>1.171896</td>\n",
       "      <td>0.636361</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.332044</td>\n",
       "      <td>-0.010381</td>\n",
       "      <td>-0.012015</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.010586</td>\n",
       "      <td>-1.028378</td>\n",
       "      <td>2.287762</td>\n",
       "      <td>-0.019127</td>\n",
       "      <td>-0.060986</td>\n",
       "      <td>-0.006756</td>\n",
       "      <td>1.328147</td>\n",
       "      <td>0.299922</td>\n",
       "      <td>2.027906</td>\n",
       "      <td>-0.011878</td>\n",
       "      <td>-0.011485</td>\n",
       "      <td>-1.443223</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.031491</td>\n",
       "      <td>-0.790454</td>\n",
       "      <td>-0.482464</td>\n",
       "      <td>0.204345</td>\n",
       "      <td>1.271811</td>\n",
       "      <td>0.291714</td>\n",
       "      <td>1.160423</td>\n",
       "      <td>-1.128429</td>\n",
       "      <td>2.177884</td>\n",
       "      <td>-0.021893</td>\n",
       "      <td>-0.377194</td>\n",
       "      <td>1.607697</td>\n",
       "      <td>1.037123</td>\n",
       "      <td>0.299594</td>\n",
       "      <td>1.307862</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>1.178401</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>1.960590</td>\n",
       "      <td>-0.897985</td>\n",
       "      <td>2.046090</td>\n",
       "      <td>-0.013629</td>\n",
       "      <td>-1.017747</td>\n",
       "      <td>2.048824</td>\n",
       "      <td>0.939732</td>\n",
       "      <td>0.841330</td>\n",
       "      <td>2.294428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2145490054</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2125-12-23 17:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523811</td>\n",
       "      <td>-1.367455</td>\n",
       "      <td>-0.215554</td>\n",
       "      <td>-0.289898</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>-0.010345</td>\n",
       "      <td>-1.160983</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>-1.403987</td>\n",
       "      <td>-0.011965</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>-0.024439</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>0.081068</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.550603</td>\n",
       "      <td>-0.378605</td>\n",
       "      <td>-0.638406</td>\n",
       "      <td>-0.728598</td>\n",
       "      <td>-0.689851</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>-0.046749</td>\n",
       "      <td>-0.465008</td>\n",
       "      <td>-0.551646</td>\n",
       "      <td>0.132859</td>\n",
       "      <td>-0.029741</td>\n",
       "      <td>-0.026670</td>\n",
       "      <td>-0.053370</td>\n",
       "      <td>-0.074738</td>\n",
       "      <td>-0.481953</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>-0.024507</td>\n",
       "      <td>0.720678</td>\n",
       "      <td>1.904832</td>\n",
       "      <td>1.520399</td>\n",
       "      <td>0.265283</td>\n",
       "      <td>-0.360398</td>\n",
       "      <td>-0.176981</td>\n",
       "      <td>-0.781604</td>\n",
       "      <td>-0.176019</td>\n",
       "      <td>0.677988</td>\n",
       "      <td>-0.022306</td>\n",
       "      <td>-0.089238</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>1.225833</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>-0.408705</td>\n",
       "      <td>-0.328749</td>\n",
       "      <td>-0.459299</td>\n",
       "      <td>0.188087</td>\n",
       "      <td>-0.103820</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>0.354394</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-3.855542</td>\n",
       "      <td>-0.587627</td>\n",
       "      <td>-1.902488</td>\n",
       "      <td>-1.273176</td>\n",
       "      <td>-0.280167</td>\n",
       "      <td>-0.945672</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.669296</td>\n",
       "      <td>-1.717605</td>\n",
       "      <td>0.391150</td>\n",
       "      <td>0.131539</td>\n",
       "      <td>-1.403649</td>\n",
       "      <td>-1.707549</td>\n",
       "      <td>-0.011635</td>\n",
       "      <td>-1.420333</td>\n",
       "      <td>-1.199338</td>\n",
       "      <td>-0.440488</td>\n",
       "      <td>-1.020605</td>\n",
       "      <td>-0.022388</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.256513</td>\n",
       "      <td>1.458437</td>\n",
       "      <td>-0.023798</td>\n",
       "      <td>-1.231100</td>\n",
       "      <td>-0.025813</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.092389</td>\n",
       "      <td>-0.013832</td>\n",
       "      <td>-0.335299</td>\n",
       "      <td>-1.015465</td>\n",
       "      <td>-0.019289</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>-0.013398</td>\n",
       "      <td>0.793368</td>\n",
       "      <td>-0.004147</td>\n",
       "      <td>-1.206194</td>\n",
       "      <td>-0.010893</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.102045</td>\n",
       "      <td>-0.011892</td>\n",
       "      <td>-0.030286</td>\n",
       "      <td>-0.634064</td>\n",
       "      <td>0.404345</td>\n",
       "      <td>-3.705888</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>-2.126793</td>\n",
       "      <td>-1.015268</td>\n",
       "      <td>-0.301427</td>\n",
       "      <td>-0.959413</td>\n",
       "      <td>-0.020348</td>\n",
       "      <td>0.987275</td>\n",
       "      <td>-1.659547</td>\n",
       "      <td>1.888238</td>\n",
       "      <td>0.062597</td>\n",
       "      <td>-1.151258</td>\n",
       "      <td>-2.181874</td>\n",
       "      <td>-0.570713</td>\n",
       "      <td>-1.690266</td>\n",
       "      <td>-0.607683</td>\n",
       "      <td>-0.314282</td>\n",
       "      <td>-0.826657</td>\n",
       "      <td>-0.015010</td>\n",
       "      <td>0.625235</td>\n",
       "      <td>-0.572843</td>\n",
       "      <td>0.720196</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>-0.600858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows  140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id   age  gender  ethnicity_WHITE  ethnicity_BLACK  \\\n",
       "0    -2144679073  82.0       0                0                0   \n",
       "1    -2142084288  84.0       1                1                0   \n",
       "2    -2133944014  50.0       1                1                0   \n",
       "3    -2133227983  52.0       0                1                0   \n",
       "4    -2132499549  68.0       0                1                0   \n",
       "...          ...   ...     ...              ...              ...   \n",
       "2966  2142664100  65.0       1                1                0   \n",
       "2967  2144053271  71.0       0                1                0   \n",
       "2968  2144497079  65.0       1                1                0   \n",
       "2969  2144648302  91.0       0                1                0   \n",
       "2970  2145490054  33.0       0                1                0   \n",
       "\n",
       "      ethnicity_UNKNOWN  ethnicity_OTHER  ethnicity_HISPANIC  ethnicity_ASIAN  \\\n",
       "0                     0                1                   0                0   \n",
       "1                     0                0                   0                0   \n",
       "2                     0                0                   0                0   \n",
       "3                     0                0                   0                0   \n",
       "4                     0                0                   0                0   \n",
       "...                 ...              ...                 ...              ...   \n",
       "2966                  0                0                   0                0   \n",
       "2967                  0                0                   0                0   \n",
       "2968                  0                0                   0                0   \n",
       "2969                  0                0                   0                0   \n",
       "2970                  0                0                   0                0   \n",
       "\n",
       "      ethnicity_UNABLE_TO_OBTAIN  ethnicity_AMERICAN_INDIAN  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "...                          ...                        ...   \n",
       "2966                           0                          0   \n",
       "2967                           0                          0   \n",
       "2968                           0                          0   \n",
       "2969                           0                          0   \n",
       "2970                           0                          0   \n",
       "\n",
       "              anchor_time       death_datetime  heartrate_min  sysbp_min  \\\n",
       "0     2190-01-30 19:22:00  2194-04-23 19:27:00      -0.272794   1.217771   \n",
       "1     2161-07-10 08:07:00                  NaN      -0.073643  -0.427373   \n",
       "2     2141-03-25 16:45:00                  NaN      -0.173219   0.630220   \n",
       "3     2120-09-22 10:15:00  2121-08-28 15:15:00       0.025933  -1.073680   \n",
       "4     2205-11-16 13:07:00                  NaN       0.274872  -0.662394   \n",
       "...                   ...                  ...            ...        ...   \n",
       "2966  2180-08-11 04:23:00                  NaN       0.922114   0.042668   \n",
       "2967  2139-06-14 18:06:00                  NaN      -0.770673  -0.309863   \n",
       "2968  2150-04-26 14:47:00                  NaN      -1.019612   0.512710   \n",
       "2969  2143-12-22 17:48:00  2143-12-24 05:35:00      -3.459217  -3.247620   \n",
       "2970  2125-12-23 17:37:00                  NaN       0.523811  -1.367455   \n",
       "\n",
       "      diabp_min  meanbp_min  resprate_min  tempc_min  spo2_min  gcseye_min  \\\n",
       "0      0.923258    0.861968      0.878048   0.189353  0.317249    0.412549   \n",
       "1      0.222451   -1.935422      1.165394   0.217516 -0.256040    1.199315   \n",
       "2      0.572854    0.478013     -0.989699   0.147108 -0.419837   -0.374217   \n",
       "3      0.485253   -1.441765      0.447029   0.133026  0.235350    0.412549   \n",
       "4     -0.127953    0.148908      0.878048   0.161190  0.153452    0.412549   \n",
       "...         ...         ...           ...        ...       ...         ...   \n",
       "2966   0.923258    0.478013      0.590702   0.147108 -0.911228    1.199315   \n",
       "2967  -1.266765    0.203759     -0.989699  -0.289426  0.153452   -1.160983   \n",
       "2968  -0.565958    0.094057      0.590702   0.076699 -0.256040    0.412549   \n",
       "2969  -1.704770   -1.935422     -0.989699  -0.021873 -0.911228    0.412549   \n",
       "2970  -0.215554   -0.289898     -0.989699   0.287925 -0.010345   -1.160983   \n",
       "\n",
       "      gcsverbal_min  gcsmotor_min  heartrate_max  sysbp_max  diabp_max  \\\n",
       "0          1.239978      0.878154      -0.030099  -0.001925   0.069606   \n",
       "1          1.239978      0.878154      -0.004134  -0.014919  -0.026310   \n",
       "2         -0.932920      0.421726      -0.020620  -0.006257  -0.012100   \n",
       "3         -0.389695      0.421726      -0.017735  -0.020334  -0.008548   \n",
       "4          1.239978      0.878154      -0.007843  -0.019251  -0.072492   \n",
       "...             ...           ...            ...        ...        ...   \n",
       "2966       0.696753      0.878154       0.005757   0.012152   0.066053   \n",
       "2967      -0.932920     -1.403987      -0.006195  -0.017626  -0.097359   \n",
       "2968       1.239978      0.878154      -0.024741  -0.018709   0.009214   \n",
       "2969      -0.932920      0.421726      -0.005371  -0.031704  -0.086702   \n",
       "2970      -0.932920     -1.403987      -0.011965  -0.014919   0.012767   \n",
       "\n",
       "      meanbp_max  resprate_max  tempc_max  spo2_max  gcseye_max  \\\n",
       "0       0.021527     -0.309282  -0.058429 -0.021341    0.370578   \n",
       "1      -0.053989     -0.057963  -0.040074 -0.021341    0.370578   \n",
       "2      -0.044139     -0.215037  -0.080454 -0.030567    0.370578   \n",
       "3      -0.040856      0.161941  -0.003364 -0.021341    0.370578   \n",
       "4      -0.099956     -0.183622  -0.098809 -0.021341    0.370578   \n",
       "...          ...           ...        ...       ...         ...   \n",
       "2966    0.005111      0.193356  -0.021719 -0.021341    0.370578   \n",
       "2967   -0.086823     -0.152207  -0.095138 -0.021341   -2.337273   \n",
       "2968    0.514026     -0.057963  -0.091467 -0.021341    0.370578   \n",
       "2969   -0.122939     -0.120793  -0.128177 -0.021341    0.370578   \n",
       "2970   -0.024439     -0.120793   0.081068 -0.021341    0.370578   \n",
       "\n",
       "      gcsverbal_max  gcsmotor_max  heartrate_avg  sysbp_avg  diabp_avg  \\\n",
       "0          0.669108      0.341538      -0.671766   0.838925   0.734657   \n",
       "1          0.669108      0.341538      -0.134094  -0.066312   0.750897   \n",
       "2          0.669108      0.341538      -0.322070   0.427622   0.130176   \n",
       "3          0.669108      0.341538      -0.203561  -0.427533   0.646238   \n",
       "4          0.669108      0.341538      -0.038396  -0.330845   0.125592   \n",
       "...             ...           ...            ...        ...        ...   \n",
       "2966       0.669108      0.341538       0.787906   0.176275   1.271708   \n",
       "2967      -1.693958      0.341538      -0.392198  -0.085976  -0.199819   \n",
       "2968       0.669108      0.341538      -0.518790   0.179749  -0.911257   \n",
       "2969       0.078342      0.341538       0.678164  -1.085512  -0.395568   \n",
       "2970       0.669108      0.341538       0.550603  -0.378605  -0.638406   \n",
       "\n",
       "      meanbp_avg  resprate_avg  tempc_avg  spo2_avg  gcseye_avg  \\\n",
       "0       0.755136      0.000510  -0.003616 -0.100585    0.595497   \n",
       "1       0.395390      0.617088   0.086249 -0.167731    0.860623   \n",
       "2       0.083759     -0.701402  -0.062385 -0.402458    0.571394   \n",
       "3       0.240893     -0.310939  -0.113208 -0.015195    0.754573   \n",
       "4      -0.222650     -0.361032  -0.180333  0.001048    0.507121   \n",
       "...          ...           ...        ...       ...         ...   \n",
       "2966    0.677604      1.480574  -0.004342 -0.016273    0.860623   \n",
       "2967   -0.157516     -0.607566  -0.704260  0.203160   -2.261975   \n",
       "2968    0.063392     -0.454063  -0.207270  0.026637    0.779046   \n",
       "2969   -0.793937     -0.022948  -0.587398 -1.195107    0.012219   \n",
       "2970   -0.728598     -0.689851   0.706637 -0.046749   -0.465008   \n",
       "\n",
       "      gcsverbal_avg  gcsmotor_avg  heartrate_stddev  sysbp_stddev  \\\n",
       "0          1.041441      0.658405         -0.047481     -0.000154   \n",
       "1          1.041441      0.658405         -0.001199      0.007246   \n",
       "2          0.394775      0.594702         -0.024181     -0.001278   \n",
       "3         -0.007318      0.281090         -0.021139     -0.007731   \n",
       "4          1.041441      0.658405         -0.010829     -0.007087   \n",
       "...             ...           ...               ...           ...   \n",
       "2966       0.995843      0.658405          0.008134      0.010750   \n",
       "2967      -1.329666     -0.781980          0.027312      0.004955   \n",
       "2968       1.041441      0.658405         -0.022060     -0.031759   \n",
       "2969      -0.539297      0.097823          0.065100      0.016414   \n",
       "2970      -0.551646      0.132859         -0.029741     -0.026670   \n",
       "\n",
       "      diabp_stddev  meanbp_stddev  resprate_stddev  tempc_stddev  spo2_stddev  \\\n",
       "0         0.026722      -0.025099        -0.700168     -0.113932    -0.042762   \n",
       "1         0.014587       0.037638        -0.347862     -0.101546    -0.018473   \n",
       "2        -0.048238      -0.064594        -0.313192     -0.119714    -0.001438   \n",
       "3         0.012835       0.008907        -0.018688     -0.066404    -0.042251   \n",
       "4        -0.032613      -0.041233        -0.560680     -0.134095    -0.023838   \n",
       "...            ...            ...              ...           ...          ...   \n",
       "2966      0.050465       0.005370        -0.074307     -0.069785     0.021901   \n",
       "2967     -0.021687      -0.074604         0.230779     -0.051405    -0.022380   \n",
       "2968     -0.065296       0.342646        -0.375325     -0.118352    -0.037418   \n",
       "2969      0.021569       0.079971         0.223881     -0.115571     0.078197   \n",
       "2970     -0.053370      -0.074738        -0.481953      0.021343    -0.024507   \n",
       "\n",
       "      gcseye_stddev  gcsverbal_stddev  gcsmotor_stddev  heartrate_first  \\\n",
       "0         -0.054623         -0.696918        -0.769890        -1.241070   \n",
       "1         -1.069636         -0.696918        -0.769890        -0.299599   \n",
       "2          0.388982          1.970708        -0.371864        -0.770334   \n",
       "3         -0.338743          0.659022        -0.068008         0.312356   \n",
       "4          0.051502         -0.696918        -0.769890        -0.017158   \n",
       "...             ...               ...              ...              ...   \n",
       "2966      -1.069636         -0.299347        -0.769890         1.159680   \n",
       "2967      -0.524861         -0.696918         2.324226         0.171136   \n",
       "2968      -0.441552         -0.696918        -0.769890        -2.229614   \n",
       "2969      -0.095112          1.301948        -0.164944         0.830165   \n",
       "2970       0.720678          1.904832         1.520399         0.265283   \n",
       "\n",
       "      sysbp_first  diabp_first  meanbp_first  resprate_first  tempc_first  \\\n",
       "0       -0.100946    -0.093761     -0.277365       -0.176019    -0.090217   \n",
       "1        0.244989     0.060789      0.378146        0.701921     0.305525   \n",
       "2        0.201747    -0.117538     -0.327789       -0.803119     0.165851   \n",
       "3        0.763893     0.476888      1.941287        0.952761     0.212409   \n",
       "4       -0.187430     0.048901      0.075602        0.325661    -0.113496   \n",
       "...           ...          ...           ...             ...          ...   \n",
       "2966     0.028780     0.144009      0.428570        1.454441     0.212409   \n",
       "2967     0.677409    -0.117538     -1.033723        0.701921     0.119293   \n",
       "2968     0.201747    -0.272089     -0.781604       -0.552279    -0.113496   \n",
       "2969    -0.100946     0.108344      0.680689       -1.053958    -0.439401   \n",
       "2970    -0.360398    -0.176981     -0.781604       -0.176019     0.677988   \n",
       "\n",
       "      spo2_first  gcseye_first  gcsverbal_first  gcsmotor_first  \\\n",
       "0      -0.015482      0.729111         0.910102        0.608975   \n",
       "1      -0.056425      0.729111         0.910102        0.608975   \n",
       "2      -0.008658     -0.907586        -1.251107        0.069738   \n",
       "3      -0.008658      0.729111         0.369800        0.069738   \n",
       "4      -0.008658      0.729111         0.910102        0.608975   \n",
       "...          ...           ...              ...             ...   \n",
       "2966    0.004989      0.729111         0.910102        0.608975   \n",
       "2967   -0.042777     -1.725934        -1.251107       -2.087210   \n",
       "2968   -0.042777      0.729111         0.910102        0.608975   \n",
       "2969   -0.138311      0.729111         0.369800        0.608975   \n",
       "2970   -0.022306     -0.089238        -1.251107        0.069738   \n",
       "\n",
       "      heartrate_last  sysbp_last  diabp_last  meanbp_last  resprate_last  \\\n",
       "0          -0.521863    1.715295    0.616779     0.846636      -0.029003   \n",
       "1          -0.313804    0.682207    1.280328     1.020767       1.692185   \n",
       "2          -0.230580    0.086196   -0.227737    -0.198151      -0.315867   \n",
       "3          -0.188968    0.046461   -0.348382    -0.024020      -0.029003   \n",
       "4           0.726492    0.006727   -0.107092    -0.067553       1.118455   \n",
       "...              ...         ...         ...          ...            ...   \n",
       "2966        0.518433    1.198751    1.400973     1.020767       0.257862   \n",
       "2967       -0.272192   -0.907158   -0.408705     0.672505      -0.029003   \n",
       "2968       -0.022521   -0.390614   -1.011931    -0.546413      -0.459299   \n",
       "2969       -3.559525   -3.529610   -2.459673    -2.723052      -2.897648   \n",
       "2970        1.225833    0.006727   -0.408705    -0.328749      -0.459299   \n",
       "\n",
       "      tempc_last  spo2_last  gcseye_last  gcsverbal_last  gcsmotor_last  \\\n",
       "0      -0.048489   0.009782     0.659401        0.896608       0.536315   \n",
       "1      -0.021452   0.236984     0.659401        0.896608       0.536315   \n",
       "2      -0.055249  -0.217421     0.659401        0.896608       0.536315   \n",
       "3      -0.041730   0.577788     0.659401       -0.730035       0.536315   \n",
       "4      -0.001174   0.123383    -0.255992        0.896608       0.536315   \n",
       "...          ...        ...          ...             ...            ...   \n",
       "2966   -0.075527  -0.103820     0.659401        0.896608       0.536315   \n",
       "2967   -0.048489   0.577788    -2.086777       -1.272249       0.536315   \n",
       "2968    0.012345   0.009782     0.659401        0.896608       0.536315   \n",
       "2969   -0.109323  -0.899028    -0.255992       -0.730035      -0.060988   \n",
       "2970    0.188087  -0.103820    -0.255992        0.354394       0.536315   \n",
       "\n",
       "      chloride_serum_min  creatinine_min  sodium_serum_min  hemoglobin_min  \\\n",
       "0               1.093242       -0.663478          0.163419        0.285937   \n",
       "1               0.793315       -0.435926          0.507737        0.487113   \n",
       "2              -2.655837       -0.663478         -1.213852        1.694168   \n",
       "3              -0.256426       -0.891030          0.163419       -0.166709   \n",
       "4               1.393168        0.322582          0.163419       -0.217003   \n",
       "...                  ...             ...               ...             ...   \n",
       "2966           -0.406390       -0.435926         -0.525217       -0.367884   \n",
       "2967           -0.406390        0.246731         -0.525217        0.436819   \n",
       "2968           -1.606095        1.232790         -1.730329        0.587701   \n",
       "2969            0.493389        1.612044          0.679896        2.096520   \n",
       "2970           -3.855542       -0.587627         -1.902488       -1.273176   \n",
       "\n",
       "      platelet_count_min  urea_nitrogen_min  glucose_serum_min  \\\n",
       "0               0.076969          -0.734973          -0.012647   \n",
       "1              -0.000699          -0.477509          -0.012129   \n",
       "2               0.872452          -0.476000          -0.007468   \n",
       "3               0.670751          -0.731453          -0.011784   \n",
       "4               0.273945           0.984810          -0.013252   \n",
       "...                  ...                ...                ...   \n",
       "2966           -0.880643          -0.593669          -0.010576   \n",
       "2967           -0.264909           0.821883          -0.015064   \n",
       "2968           -0.683765           0.512624          -0.011180   \n",
       "2969           -0.831423           2.574353          -0.011180   \n",
       "2970           -0.280167          -0.945672          -0.012561   \n",
       "\n",
       "      bicarbonate_min  potassium_serum_min  anion_gap_min  \\\n",
       "0            0.669296            -0.124032      -0.915664   \n",
       "1            0.066001            -0.301095      -0.563366   \n",
       "2            2.680281            -1.717605      -0.397756   \n",
       "3            1.272592            -2.071733      -0.638644   \n",
       "4           -0.939492            -0.124032       0.062941   \n",
       "...               ...                  ...            ...   \n",
       "2966         0.468198            -0.478159      -0.512178   \n",
       "2967        -0.738393            -0.478159       0.526649   \n",
       "2968        -1.341689            -0.301095       1.896696   \n",
       "2969        -0.336196             2.886052       1.896696   \n",
       "2970         0.669296            -1.717605       0.391150   \n",
       "\n",
       "      leukocytes_blood_manual_min  hematocrit_min  chloride_serum_max  \\\n",
       "0                       -0.348052        0.099873            0.214809   \n",
       "1                       -0.060979        0.502304            0.510556   \n",
       "2                        1.230034        1.542830           -2.151170   \n",
       "3                        0.063069       -0.119478           -0.228812   \n",
       "4                       -0.121743       -0.197396            0.362682   \n",
       "...                           ...             ...                 ...   \n",
       "2966                    -0.135230       -0.414490           -0.672433   \n",
       "2967                     0.214830        0.322694           -0.672433   \n",
       "2968                    -0.401998        0.279656           -1.855423   \n",
       "2969                     1.065230        2.344742            0.066935   \n",
       "2970                     0.131539       -1.403649           -1.707549   \n",
       "\n",
       "      creatinine_max  sodium_serum_max  hemoglobin_max  platelet_count_max  \\\n",
       "0          -0.011713         -0.309154       -0.534404            0.297850   \n",
       "1          -0.011635          0.431631        0.320511            0.179330   \n",
       "2          -0.011679         -0.494351        1.507893            0.455851   \n",
       "3          -0.011739          0.061238       -0.011956            1.143237   \n",
       "4          -0.011601         -0.494351        0.035539            0.156544   \n",
       "...              ...               ...             ...                 ...   \n",
       "2966       -0.011670         -0.494351       -0.296928           -0.630374   \n",
       "2967       -0.011316         -0.679547       -0.154442            0.201483   \n",
       "2968       -0.011238         -1.420333        1.127931           -0.764876   \n",
       "2969       -0.011420         -0.309154        1.080435           -1.184207   \n",
       "2970       -0.011635         -1.420333       -1.199338           -0.440488   \n",
       "\n",
       "      urea_nitrogen_max  glucose_serum_max  bicarbonate_max  \\\n",
       "0             -0.994593          -0.024332        -0.000648   \n",
       "1             -0.090891          -0.021989        -0.009273   \n",
       "2             -0.444643          -0.017503         0.094229   \n",
       "3             -0.712930          -0.023036         0.033853   \n",
       "4              0.329004          -0.025130        -0.086899   \n",
       "...                 ...                ...              ...   \n",
       "2966          -0.760493          -0.020095         0.016602   \n",
       "2967           0.676810          -0.023983         0.033853   \n",
       "2968           2.620960          -0.017553        -0.000648   \n",
       "2969           1.840625          -0.023933        -0.052399   \n",
       "2970          -1.020605          -0.022388         0.007977   \n",
       "\n",
       "      potassium_serum_max  anion_gap_max  leukocytes_blood_manual_max  \\\n",
       "0               -1.025656      -0.767333                    -0.018388   \n",
       "1                0.292875      -0.091176                    -0.000665   \n",
       "2               -0.366390      -0.828988                     0.024072   \n",
       "3                0.622508      -0.514545                    -0.017100   \n",
       "4               -0.696023       1.220035                     0.012420   \n",
       "...                   ...            ...                          ...   \n",
       "2966            -0.696023      -0.391233                    -0.000369   \n",
       "2967            -0.586146      -0.074734                    -0.011540   \n",
       "2968             1.611406       1.663956                    -0.045848   \n",
       "2969             1.171896       0.636361                     0.007900   \n",
       "2970            -0.256513       1.458437                    -0.023798   \n",
       "\n",
       "      hematocrit_max  chloride_serum_avg  creatinine_avg  sodium_serum_avg  \\\n",
       "0          -0.395681           -0.007656       -0.014171         -0.015245   \n",
       "1           0.390295           -0.009259       -0.013774          0.012011   \n",
       "2           0.916153           -0.031538       -0.014085         -0.072093   \n",
       "3          -0.103317           -0.014468       -0.014352          0.003250   \n",
       "4           0.164904           -0.006054       -0.013275         -0.023033   \n",
       "...              ...                 ...             ...               ...   \n",
       "2966       -0.288525           -0.016472       -0.013880         -0.040554   \n",
       "2967       -0.188810           -0.017731       -0.012278         -0.053070   \n",
       "2968        1.050925           -0.026598       -0.011229         -0.112234   \n",
       "2969        1.332044           -0.010381       -0.012015          0.000330   \n",
       "2970       -1.231100           -0.025813       -0.013960         -0.092389   \n",
       "\n",
       "      hemoglobin_avg  platelet_count_avg  urea_nitrogen_avg  \\\n",
       "0          -0.012701            0.347919          -0.948893   \n",
       "1          -0.012045           -0.067964          -0.387671   \n",
       "2          -0.010550            0.218245          -0.646831   \n",
       "3          -0.012580            0.950606          -0.886384   \n",
       "4          -0.012630            0.006333           0.343322   \n",
       "...              ...                 ...                ...   \n",
       "2966       -0.013052           -0.742526          -0.717218   \n",
       "2967       -0.012299            0.139068           0.787500   \n",
       "2968       -0.011756           -0.688077           2.200226   \n",
       "2969       -0.010586           -1.028378           2.287762   \n",
       "2970       -0.013832           -0.335299          -1.015465   \n",
       "\n",
       "      glucose_serum_avg  bicarbonate_avg  potassium_serum_avg  anion_gap_avg  \\\n",
       "0             -0.020354         0.019154            -0.013272      -1.114836   \n",
       "1             -0.018131        -0.019468            -0.011258      -0.206481   \n",
       "2             -0.012610         0.170743            -0.014433      -0.872370   \n",
       "3             -0.018743         0.068637            -0.013154      -0.659500   \n",
       "4             -0.021086        -0.108780            -0.012621       0.272497   \n",
       "...                 ...              ...                  ...            ...   \n",
       "2966          -0.016265         0.019958            -0.012700      -0.209341   \n",
       "2967          -0.020678        -0.006364            -0.012291       0.406005   \n",
       "2968          -0.012913        -0.050189            -0.010504       1.899387   \n",
       "2969          -0.019127        -0.060986            -0.006756       1.328147   \n",
       "2970          -0.019289         0.020533            -0.013398       0.793368   \n",
       "\n",
       "      leukocytes_blood_manual_avg  hematocrit_avg  chloride_serum_stddev  \\\n",
       "0                       -0.162093       -0.233373              -0.012429   \n",
       "1                       -0.083122        0.450207              -0.012014   \n",
       "2                       -0.000619        1.647657              -0.011455   \n",
       "3                       -0.175868        0.104515              -0.011562   \n",
       "4                        0.315003       -0.175926              -0.012592   \n",
       "...                           ...             ...                    ...   \n",
       "2966                    -0.086127       -0.386152              -0.011885   \n",
       "2967                     0.082395        0.265825              -0.011921   \n",
       "2968                    -0.263500        0.504531              -0.012078   \n",
       "2969                     0.299922        2.027906              -0.011878   \n",
       "2970                    -0.004147       -1.206194              -0.010893   \n",
       "\n",
       "      creatinine_stddev  sodium_serum_stddev  hemoglobin_stddev  \\\n",
       "0             -0.011540            -0.590509          -0.011974   \n",
       "1             -0.011498            -0.343805          -0.011836   \n",
       "2             -0.011504             0.964784          -0.011819   \n",
       "3             -0.011538            -0.013936          -0.011738   \n",
       "4             -0.011538            -0.698913          -0.011672   \n",
       "...                 ...                  ...                ...   \n",
       "2966          -0.011525             0.060371          -0.011835   \n",
       "2967          -0.011205            -0.108793          -0.011934   \n",
       "2968          -0.011282             0.503888          -0.011802   \n",
       "2969          -0.011485            -1.443223          -0.011992   \n",
       "2970          -0.011497            -0.102045          -0.011892   \n",
       "\n",
       "      glucose_serum_stddev  bicarbonate_stddev  potassium_serum_stddev  \\\n",
       "0                -0.030961           -0.601701               -1.056430   \n",
       "1                -0.029291           -0.226259                0.125189   \n",
       "2                -0.027636           -0.299876                0.896400   \n",
       "3                -0.030063           -0.282218                2.463369   \n",
       "4                -0.031460           -1.112750               -0.219378   \n",
       "...                    ...                 ...                     ...   \n",
       "2966             -0.027643            0.316081               -0.427042   \n",
       "2967             -0.029347            3.064577               -0.380575   \n",
       "2968             -0.026767            1.913836                1.704332   \n",
       "2969             -0.031491           -0.790454               -0.482464   \n",
       "2970             -0.030286           -0.634064                0.404345   \n",
       "\n",
       "      chloride_serum_first  creatinine_first  sodium_serum_first  \\\n",
       "0                 0.743687         -0.694348           -0.191987   \n",
       "1                 0.474016         -0.173894            0.614182   \n",
       "2                -2.627203         -0.463035           -1.481858   \n",
       "3                -0.469833         -0.867833           -0.191987   \n",
       "4                 1.013358          0.057419            0.130480   \n",
       "...                    ...               ...                 ...   \n",
       "2966              0.069509         -0.405207            0.130480   \n",
       "2967              0.069509          1.618781           -0.836923   \n",
       "2968             -1.683354          1.792265           -1.643092   \n",
       "2969              0.204345          1.271811            0.291714   \n",
       "2970             -3.705888         -0.173894           -2.126793   \n",
       "\n",
       "      hemoglobin_first  platelet_count_first  urea_nitrogen_first  \\\n",
       "0            -0.406075              0.116251            -0.789275   \n",
       "1             0.464202             -0.020737            -0.276849   \n",
       "2             1.160423              0.739696            -0.305407   \n",
       "3             0.159605              0.750668            -0.891840   \n",
       "4             0.203119             -0.207427             0.379972   \n",
       "...                ...                   ...                  ...   \n",
       "2966         -0.101478             -0.497942            -0.758304   \n",
       "2967         -0.188505              0.068022             1.442229   \n",
       "2968          1.203937             -0.637141             2.378993   \n",
       "2969          1.160423             -1.128429             2.177884   \n",
       "2970         -1.015268             -0.301427            -0.959413   \n",
       "\n",
       "      glucose_serum_first  bicarbonate_first  potassium_serum_first  \\\n",
       "0               -0.022292           0.207578              -0.788282   \n",
       "1               -0.022242           0.012654              -0.025925   \n",
       "2               -0.020149           2.156819              -1.768456   \n",
       "3               -0.022641           0.792351              -0.897190   \n",
       "4               -0.023489          -1.351814              -0.243741   \n",
       "...                   ...                ...                    ...   \n",
       "2966            -0.019750           0.207578              -0.570466   \n",
       "2967            -0.022292          -0.572118              -0.134833   \n",
       "2968            -0.018703          -0.961966               2.043330   \n",
       "2969            -0.021893          -0.377194               1.607697   \n",
       "2970            -0.020348           0.987275              -1.659547   \n",
       "\n",
       "      anion_gap_first  leukocytes_blood_manual_first  hematocrit_first  \\\n",
       "0           -1.346000                      -0.054095         -0.572535   \n",
       "1            0.043446                      -0.216607          0.465424   \n",
       "2           -0.126777                       0.737925          1.165595   \n",
       "3           -0.373601                       0.148029          0.173951   \n",
       "4            0.017912                      -0.110297          0.278954   \n",
       "...               ...                            ...               ...   \n",
       "2966        -0.026771                      -0.490395         -0.095195   \n",
       "2967        -0.099116                       0.159315         -0.189184   \n",
       "2968         2.101017                      -0.185685          1.126822   \n",
       "2969         1.037123                       0.299594          1.307862   \n",
       "2970         1.888238                       0.062597         -1.151258   \n",
       "\n",
       "      chloride_serum_last  creatinine_last  sodium_serum_last  \\\n",
       "0                0.656699        -0.695650          -0.087780   \n",
       "1                0.183603        -0.508245           0.112531   \n",
       "2               -2.339573        -0.695650          -1.690266   \n",
       "3                0.183603        -0.883055           0.513153   \n",
       "4                0.814397         0.116439          -0.488402   \n",
       "...                   ...              ...                ...   \n",
       "2966            -1.077985        -0.383308          -1.289645   \n",
       "2967            -1.077985         0.053970          -0.488402   \n",
       "2968            -1.866477         0.866059          -1.289645   \n",
       "2969             0.499000         1.178401           0.112531   \n",
       "2970            -2.181874        -0.570713          -1.690266   \n",
       "\n",
       "      hemoglobin_last  platelet_count_last  urea_nitrogen_last  \\\n",
       "0            0.157334            -0.178773           -0.863655   \n",
       "1            0.430555             0.701722           -0.447977   \n",
       "2            1.523437             0.575731           -0.612072   \n",
       "3           -0.498395             0.946249           -0.749180   \n",
       "4           -0.553039             0.463571            0.272386   \n",
       "...               ...                  ...                 ...   \n",
       "2966        -0.389107            -1.005746           -0.521972   \n",
       "2967         0.594487            -0.032757            0.391649   \n",
       "2968         0.867708            -0.538783            0.261505   \n",
       "2969         1.960590            -0.897985            2.046090   \n",
       "2970        -0.607683            -0.314282           -0.826657   \n",
       "\n",
       "      glucose_serum_last  bicarbonate_last  potassium_serum_last  \\\n",
       "0              -0.015096          0.214490             -0.408989   \n",
       "1              -0.013025         -0.196256             -0.900551   \n",
       "2              -0.001803          2.062846             -0.408989   \n",
       "3              -0.011385          1.446727             -0.900551   \n",
       "4              -0.015010         -1.428493             -0.736697   \n",
       "...                  ...               ...                   ...   \n",
       "2966           -0.006292          0.214490              0.082574   \n",
       "2967           -0.013456          1.446727             -0.081281   \n",
       "2968           -0.005688          0.009117              0.737990   \n",
       "2969           -0.013629         -1.017747              2.048824   \n",
       "2970           -0.015010          0.625235             -0.572843   \n",
       "\n",
       "      anion_gap_last  leukocytes_blood_manual_last  hematocrit_last  \n",
       "0          -0.979015                     -0.516496         0.100735  \n",
       "1           0.024266                      0.217026         0.473387  \n",
       "2          -0.658492                      0.160877         1.557531  \n",
       "3          -1.200746                     -0.014856        -0.475707  \n",
       "4           0.140620                      0.490582        -0.508395  \n",
       "...              ...                           ...              ...  \n",
       "2966        0.061587                      0.718153        -0.414065  \n",
       "2967       -0.438956                     -0.033435         0.564168  \n",
       "2968        1.598340                     -0.298061         0.631974  \n",
       "2969        0.939732                      0.841330         2.294428  \n",
       "2970        0.720196                      0.061206        -0.600858  \n",
       "\n",
       "[2971 rows x 140 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataMatrix = pd.read_csv(dataDirName + 'data_matrix/data_matrix_standardised.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix.anchor_time = dataMatrix.anchor_time.apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S'))\n",
    "dataMatrix.death_datetime = dataMatrix.death_datetime.apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S'))\n",
    "dataMatrix['target'] = (dataMatrix['death_datetime'] < (dataMatrix['anchor_time'] + pd.Timedelta(days=7)))\n",
    "dataMatrix.target.fillna(value=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "False    2524\n",
       "True      447\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMatrix.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate positive and negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrixPositive = dataMatrix[dataMatrix.target == True]\n",
    "dataMatrixNegative = dataMatrix[dataMatrix.target == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate different data imbalances and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 07:08:09,053 - Pipeline - INFO - dirName: 65_35_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 07:08:09,054 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 07:08:09,054 - Pipeline - INFO - Reading data\n",
      "2023-09-25 07:08:09,269 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 07:08:09,276 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 07:09:36,438 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 07:09:36,439 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:09:36,463 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:09:36,464 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:10:32,200 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:10:58,134 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:11:07,106 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:11:13,831 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:12:40,084 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:12:45,101 - Pipeline - INFO - params: {'max_depth': 7, 'scale_pos_weight': 0.4, 'n_estimators': 120, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 07:12:45,102 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:12:49,306 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 07:12:49,307 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:12:49,308 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:12:49,309 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:13:26,175 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:13:37,802 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:13:41,351 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:13:43,501 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:14:12,522 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:14:15,242 - Pipeline - INFO - params: {'max_depth': 3, 'scale_pos_weight': 0.4, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 07:14:15,244 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:14:16,673 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 07:14:16,674 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:14:19,516 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:14:19,518 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:14:20,498 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 07:14:20,499 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:14:21,154 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:14:21,155 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:14:22,076 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 07:14:22,077 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:14:38,384 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:14:38,386 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:14:41,439 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 07:14:41,440 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:14:52,098 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:14:52,099 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:14:54,017 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 07:14:54,018 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:14:55,656 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:15:09,898 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 07:15:09,899 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:15:10,912 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:15:19,966 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 07:15:19,967 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 07:15:19,967 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 07:15:19,972 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 07:15:19,973 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:15:49,581 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:16:01,005 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:16:04,486 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:16:06,402 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:16:35,683 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:16:37,533 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.35, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 07:16:37,535 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 07:16:37,990 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 07:17:20,026 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 07:17:20,028 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:17:20,029 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:17:20,029 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:17:46,089 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:17:57,855 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:18:01,762 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:18:04,930 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:18:42,532 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:18:45,125 - Pipeline - INFO - params: {'max_depth': 7, 'scale_pos_weight': 0.35, 'n_estimators': 130, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.3, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 07:18:45,126 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:18:46,855 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 07:18:46,856 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:18:47,411 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:18:47,412 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.18480659, 0.18623781, 0.18504739, 0.18615246, 0.1809237 ]), 'score_time': array([0.026402  , 0.02499914, 0.02535844, 0.02492809, 0.02515149]), 'test_accuracy': array([0.86666667, 0.89583333, 0.8625    , 0.8625    , 0.85      ]), 'test_balanced_accuracy': array([0.8271046 , 0.85791574, 0.82391988, 0.82391988, 0.8021978 ]), 'test_average_precision': array([0.87842635, 0.94845205, 0.84742492, 0.87845718, 0.87094304]), 'test_f1': array([0.78378378, 0.82993197, 0.77852349, 0.77852349, 0.75      ]), 'test_roc_auc': array([0.90499578, 0.96316476, 0.89417543, 0.91405111, 0.90071734]), 'test_mccf1_score': array([0.81396559, 0.85481778, 0.80886932, 0.80886932, 0.78736097])}, 'lr': {'fit_time': array([0.02647948, 0.02763748, 0.02559352, 0.02579951, 0.02487469]), 'score_time': array([0.00964785, 0.0097959 , 0.00920749, 0.00966406, 0.00943851]), 'test_accuracy': array([0.825     , 0.90833333, 0.87916667, 0.8875    , 0.82083333]), 'test_balanced_accuracy': array([0.78106055, 0.87882741, 0.85653442, 0.86858261, 0.7742674 ]), 'test_average_precision': array([0.83749886, 0.90725165, 0.88469202, 0.89106468, 0.84132983]), 'test_f1': array([0.71621622, 0.85526316, 0.81761006, 0.83229814, 0.70748299]), 'test_roc_auc': array([0.88911058, 0.91666027, 0.92287622, 0.92594582, 0.86500305]), 'test_mccf1_score': array([0.75484275, 0.87484116, 0.8393579 , 0.85180316, 0.74835865])}, 'lgbm': {'fit_time': array([0.21585965, 0.23891878, 0.22218823, 0.21197104, 0.21584058]), 'score_time': array([0.01241755, 0.01199675, 0.01271152, 0.01201177, 0.01185107]), 'test_accuracy': array([0.86666667, 0.92916667, 0.85416667, 0.85      , 0.84583333]), 'test_balanced_accuracy': array([0.81574706, 0.89759036, 0.80619292, 0.80300821, 0.78800366]), 'test_average_precision': array([0.88535977, 0.96147605, 0.85565864, 0.87001675, 0.87048338]), 'test_f1': array([0.77142857, 0.88590604, 0.75524476, 0.75      , 0.72992701]), 'test_roc_auc': array([0.89732177, 0.97237357, 0.90146574, 0.9071445 , 0.89888584]), 'test_mccf1_score': array([0.8078021 , 0.90287638, 0.79180377, 0.78662843, 0.77478288])}, 'mlp': {'fit_time': array([1.2633121 , 1.33889151, 1.33116722, 1.31729269, 1.36049318]), 'score_time': array([0.01145148, 0.01130009, 0.01167631, 0.01140642, 0.01154041]), 'test_accuracy': array([0.8125    , 0.87083333, 0.84166667, 0.8375    , 0.8125    ]), 'test_balanced_accuracy': array([0.77434579, 0.84732561, 0.82219323, 0.81616914, 0.76785714]), 'test_average_precision': array([0.81142022, 0.88495825, 0.82846436, 0.84449722, 0.81739934]), 'test_f1': array([0.70588235, 0.80503145, 0.76829268, 0.7607362 , 0.69798658]), 'test_roc_auc': array([0.85204512, 0.89970071, 0.89145115, 0.8866549 , 0.84577228]), 'test_mccf1_score': array([0.74325393, 0.82824759, 0.79429028, 0.78786231, 0.73887674])}, 'xgb_min': {'fit_time': array([0.07007313, 0.06746912, 0.0672586 , 0.06840777, 0.06766343]), 'score_time': array([0.01396275, 0.01253009, 0.01259971, 0.01256418, 0.0124979 ]), 'test_accuracy': array([0.84583333, 0.89166667, 0.85833333, 0.8125    , 0.84166667]), 'test_balanced_accuracy': array([0.79130535, 0.85757041, 0.82641394, 0.76298826, 0.79304029]), 'test_average_precision': array([0.84108908, 0.91849551, 0.86489088, 0.8101991 , 0.84993127]), 'test_f1': array([0.73381295, 0.82666667, 0.77922078, 0.68965517, 0.73611111]), 'test_roc_auc': array([0.86869772, 0.93315939, 0.91220935, 0.87713913, 0.89239927]), 'test_mccf1_score': array([0.77574593, 0.85057843, 0.80726723, 0.73334701, 0.77523186])}, 'lr_min': {'fit_time': array([0.02225447, 0.02038097, 0.01988411, 0.02070856, 0.01812887]), 'score_time': array([0.00849628, 0.00822401, 0.00837278, 0.00796676, 0.00812721]), 'test_accuracy': array([0.80416667, 0.84583333, 0.8375    , 0.82916667, 0.79583333]), 'test_balanced_accuracy': array([0.75945822, 0.80834165, 0.81332975, 0.79560279, 0.75228938]), 'test_average_precision': array([0.81072437, 0.87552594, 0.81434788, 0.83721407, 0.83209558]), 'test_f1': array([0.68456376, 0.75496689, 0.75776398, 0.73548387, 0.67549669]), 'test_roc_auc': array([0.85012662, 0.90691428, 0.90223314, 0.90039137, 0.873779  ]), 'test_mccf1_score': array([0.72659092, 0.7872746 , 0.78583489, 0.76838691, 0.71803346])}, 'lgbm_min': {'fit_time': array([0.09904265, 0.09767699, 0.10791588, 0.19951868, 0.09029794]), 'score_time': array([0.01024365, 0.01010132, 0.01025486, 0.01071286, 0.00978684]), 'test_accuracy': array([0.83333333, 0.88333333, 0.85      , 0.8375    , 0.82916667]), 'test_balanced_accuracy': array([0.77607244, 0.84552222, 0.80300821, 0.78777531, 0.76968864]), 'test_average_precision': array([0.83875127, 0.91126722, 0.85484491, 0.83820565, 0.86081169]), 'test_f1': array([0.71014493, 0.81081081, 0.75      , 0.72727273, 0.70072993]), 'test_roc_auc': array([0.87483693, 0.92809454, 0.9071445 , 0.89494283, 0.89972527]), 'test_mccf1_score': array([0.75586824, 0.8376121 , 0.78662843, 0.76740834, 0.7493773 ])}, 'mlp_min': {'fit_time': array([0.83394527, 0.83209038, 0.83378696, 0.83193684, 0.83368015]), 'score_time': array([0.00950861, 0.00924873, 0.00936961, 0.00933719, 0.00943446]), 'test_accuracy': array([0.78333333, 0.87916667, 0.80416667, 0.82083333, 0.80833333]), 'test_balanced_accuracy': array([0.75773156, 0.86221318, 0.77365513, 0.78923337, 0.78113553]), 'test_average_precision': array([0.75808438, 0.85894375, 0.76999593, 0.80996236, 0.822309  ]), 'test_f1': array([0.68292683, 0.82208589, 0.70440252, 0.72611465, 0.71604938]), 'test_roc_auc': array([0.82280715, 0.88381552, 0.82434195, 0.87169058, 0.8640873 ]), 'test_mccf1_score': array([0.71848897, 0.84227783, 0.73936485, 0.75931507, 0.74870532])}, 'xgb_ensemble': {'fit_time': array([0.0936923 , 0.09143734, 0.08706689, 0.08869362, 0.08903313]), 'score_time': array([0.01638961, 0.01567793, 0.01550555, 0.01545477, 0.01667857]), 'test_accuracy': array([0.90833333, 0.89166667, 0.85833333, 0.875     , 0.86666667]), 'test_balanced_accuracy': array([0.87891738, 0.84662868, 0.79534663, 0.84093067, 0.82146249]), 'test_average_precision': array([0.91291966, 0.88024298, 0.84364897, 0.86726252, 0.88240737]), 'test_f1': array([0.84931507, 0.8115942 , 0.73846154, 0.79452055, 0.77142857]), 'test_roc_auc': array([0.94523583, 0.91199747, 0.88224122, 0.90756569, 0.91263058]), 'test_mccf1_score': array([0.86966618, 0.84009739, 0.7816308 , 0.8219115 , 0.80431133])}, 'lr_ensemble': {'fit_time': array([0.00561905, 0.00479531, 0.00482416, 0.00484991, 0.0048008 ]), 'score_time': array([0.00964427, 0.00926995, 0.00902939, 0.0091815 , 0.00906014]), 'test_accuracy': array([0.9       , 0.875     , 0.84166667, 0.9       , 0.875     ]), 'test_balanced_accuracy': array([0.86609687, 0.82763533, 0.77635328, 0.87274454, 0.84093067]), 'test_average_precision': array([0.93876444, 0.88195739, 0.81713998, 0.88873278, 0.88884059]), 'test_f1': array([0.83333333, 0.7826087 , 0.70769231, 0.83783784, 0.79452055]), 'test_roc_auc': array([0.96169674, 0.91674581, 0.86451409, 0.91326369, 0.91263058]), 'test_mccf1_score': array([0.85642239, 0.8149855 , 0.75508155, 0.85905724, 0.8219115 ])}}\n",
      "2023-09-25 07:18:48,191 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 07:18:48,193 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 07:18:48,384 - Pipeline - INFO - dirName: 70_30_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 07:18:48,385 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 07:18:48,386 - Pipeline - INFO - Reading data\n",
      "2023-09-25 07:18:48,629 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 07:18:48,635 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 07:20:55,460 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 07:20:55,461 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:20:55,462 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:20:55,464 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:21:51,178 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:22:14,617 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:22:21,433 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:22:25,766 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:23:20,155 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:23:23,322 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.3, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.2, 'subsample': 0.8, 'reg_alpha': 0.001}\n",
      "2023-09-25 07:23:23,323 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:23:25,361 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 07:23:25,362 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:23:25,363 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:23:25,364 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:23:57,845 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:24:13,958 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:24:16,509 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:24:18,571 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:24:42,412 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:24:44,004 - Pipeline - INFO - params: {'max_depth': 6, 'scale_pos_weight': 0.35, 'n_estimators': 50, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 07:24:44,005 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:24:45,526 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 07:24:45,527 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:24:48,162 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:24:48,164 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:24:49,113 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 07:24:49,114 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:24:49,784 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:24:49,785 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:24:50,867 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 07:24:50,868 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:25:06,425 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:25:06,426 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:25:08,971 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 07:25:08,973 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:25:17,544 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:25:17,545 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:25:19,618 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 07:25:19,619 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:25:21,316 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:25:35,630 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 07:25:35,631 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:25:36,675 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:25:46,023 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 07:25:46,024 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 07:25:46,025 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 07:25:46,031 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 07:25:46,032 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:26:15,562 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:26:22,275 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:26:25,756 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:26:27,773 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:27:01,924 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:27:03,966 - Pipeline - INFO - params: {'max_depth': 1, 'scale_pos_weight': 0.4, 'n_estimators': 180, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.1, 'reg_alpha': 0}\n",
      "2023-09-25 07:27:03,968 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 07:27:04,409 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 07:27:46,791 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 07:27:46,792 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:27:46,793 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:27:46,794 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:28:13,658 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:28:24,061 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:28:26,923 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:28:29,004 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:28:57,066 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:28:58,959 - Pipeline - INFO - params: {'max_depth': 3, 'scale_pos_weight': 0.15, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.7, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 07:28:58,960 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:29:00,486 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 07:29:00,488 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:29:01,095 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:29:01,096 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.11857653, 0.1165483 , 0.11544538, 0.1182642 , 0.11688995]), 'score_time': array([0.02470565, 0.02407074, 0.02421594, 0.02480149, 0.02481675]), 'test_accuracy': array([0.83333333, 0.8875    , 0.875     , 0.86666667, 0.90416667]), 'test_balanced_accuracy': array([0.75793651, 0.8343612 , 0.82548546, 0.79506626, 0.84619552]), 'test_average_precision': array([0.83749543, 0.87273482, 0.84109629, 0.83676797, 0.88815464]), 'test_f1': array([0.67213115, 0.78740157, 0.76923077, 0.73333333, 0.81300813]), 'test_roc_auc': array([0.89674272, 0.90082507, 0.90865905, 0.88799067, 0.91507626]), 'test_mccf1_score': array([0.72508466, 0.82031924, 0.8034363 , 0.77792603, 0.8442304 ])}, 'lr': {'fit_time': array([0.02313161, 0.02152801, 0.0218792 , 0.02057791, 0.02123165]), 'score_time': array([0.01015949, 0.00910163, 0.00906801, 0.00910163, 0.00913429]), 'test_accuracy': array([0.8625    , 0.87083333, 0.9       , 0.83333333, 0.88333333]), 'test_balanced_accuracy': array([0.7906746 , 0.82252688, 0.85548796, 0.74689557, 0.81506792]), 'test_average_precision': array([0.84815309, 0.85961185, 0.87736444, 0.81428749, 0.8743754 ]), 'test_f1': array([0.72727273, 0.76335878, 0.81538462, 0.65517241, 0.76666667]), 'test_roc_auc': array([0.90277778, 0.9031586 , 0.92816068, 0.8748229 , 0.91782649]), 'test_mccf1_score': array([0.77292575, 0.79799482, 0.84306603, 0.71403724, 0.80639541])}, 'lgbm': {'fit_time': array([0.15734482, 0.15339565, 0.14300156, 0.15173602, 0.24362493]), 'score_time': array([0.01172662, 0.01194549, 0.01170492, 0.01158142, 0.01166797]), 'test_accuracy': array([0.84166667, 0.89166667, 0.89166667, 0.83333333, 0.8875    ]), 'test_balanced_accuracy': array([0.75992063, 0.84140345, 0.83731978, 0.74689557, 0.82619385]), 'test_average_precision': array([0.82902793, 0.87008129, 0.85601042, 0.83174689, 0.87800139]), 'test_f1': array([0.6779661 , 0.796875  , 0.79365079, 0.65517241, 0.7804878 ]), 'test_roc_auc': array([0.87905093, 0.90349196, 0.92216018, 0.89482457, 0.91540962]), 'test_mccf1_score': array([0.73291478, 0.82799501, 0.82614175, 0.71403724, 0.81642402])}, 'mlp': {'fit_time': array([1.32949471, 1.30896497, 1.32684135, 1.31477857, 1.42423749]), 'score_time': array([0.01171684, 0.01167774, 0.01149273, 0.01158547, 0.01152658]), 'test_accuracy': array([0.82916667, 0.85416667, 0.87083333, 0.81666667, 0.84166667]), 'test_balanced_accuracy': array([0.77876984, 0.83111093, 0.83069422, 0.76364697, 0.7895658 ]), 'test_average_precision': array([0.79542164, 0.81051661, 0.8416559 , 0.75695466, 0.82480674]), 'test_f1': array([0.6962963 , 0.75862069, 0.77037037, 0.67164179, 0.71212121]), 'test_roc_auc': array([0.85408399, 0.86082174, 0.89915826, 0.8255688 , 0.86665555]), 'test_mccf1_score': array([0.73904747, 0.79011021, 0.8026281 , 0.71793018, 0.753558  ])}, 'xgb_min': {'fit_time': array([0.06462622, 0.06083035, 0.06106162, 0.05941963, 0.06344414]), 'score_time': array([0.01330876, 0.01255894, 0.01213741, 0.01223564, 0.01335478]), 'test_accuracy': array([0.84583333, 0.86666667, 0.87916667, 0.84166667, 0.86666667]), 'test_balanced_accuracy': array([0.76686508, 0.8195683 , 0.84069506, 0.75281273, 0.79914993]), 'test_average_precision': array([0.80473125, 0.82971522, 0.86055744, 0.7810869 , 0.84347427]), 'test_f1': array([0.68907563, 0.75757576, 0.78518519, 0.66666667, 0.73770492]), 'test_roc_auc': array([0.87152778, 0.86707226, 0.90857571, 0.85732144, 0.90040837]), 'test_mccf1_score': array([0.74166479, 0.79264219, 0.81539557, 0.72544864, 0.78041904])}, 'lr_min': {'fit_time': array([0.01920152, 0.16230178, 0.03810906, 0.02089214, 0.01817083]), 'score_time': array([0.00825667, 0.00810289, 0.00798154, 0.00817895, 0.00797367]), 'test_accuracy': array([0.8375    , 0.85416667, 0.86666667, 0.84166667, 0.8625    ]), 'test_balanced_accuracy': array([0.76884921, 0.80660888, 0.8195683 , 0.76914743, 0.80844237]), 'test_average_precision': array([0.8406939 , 0.85152533, 0.85445778, 0.80431273, 0.83875273]), 'test_f1': array([0.688     , 0.73684211, 0.75757576, 0.68852459, 0.74418605]), 'test_roc_auc': array([0.89616402, 0.89524127, 0.91840987, 0.87498958, 0.90257521]), 'test_mccf1_score': array([0.73679952, 0.77443644, 0.79264219, 0.73837108, 0.78236113])}, 'lgbm_min': {'fit_time': array([0.13245845, 0.12995315, 0.12739873, 0.1299479 , 0.12680101]), 'score_time': array([0.00996041, 0.00991106, 0.01045346, 0.0107615 , 0.00960851]), 'test_accuracy': array([0.84583333, 0.87083333, 0.8875    , 0.81666667, 0.875     ]), 'test_balanced_accuracy': array([0.76289683, 0.81435953, 0.83844487, 0.71872656, 0.81323444]), 'test_average_precision': array([0.79841668, 0.82746919, 0.8497066 , 0.76433748, 0.82887133]), 'test_f1': array([0.68376068, 0.75590551, 0.79069767, 0.60714286, 0.75806452]), 'test_roc_auc': array([0.85896164, 0.86173848, 0.89665805, 0.84173681, 0.88482374]), 'test_mccf1_score': array([0.73864041, 0.7933256 , 0.82227286, 0.67639203, 0.79669584])}, 'mlp_min': {'fit_time': array([0.85541773, 0.85621595, 0.85237098, 0.85573244, 0.87344193]), 'score_time': array([0.00945234, 0.00937462, 0.00940752, 0.00967431, 0.00961018]), 'test_accuracy': array([0.82083333, 0.85416667, 0.86666667, 0.77916667, 0.79166667]), 'test_balanced_accuracy': array([0.77678571, 0.82294358, 0.82365197, 0.69209934, 0.7295608 ]), 'test_average_precision': array([0.77391802, 0.81688517, 0.81530898, 0.68436819, 0.73636402]), 'test_f1': array([0.69064748, 0.75177305, 0.76119403, 0.56198347, 0.62121212]), 'test_roc_auc': array([0.8349041 , 0.85115426, 0.87515626, 0.76148012, 0.81373448]), 'test_mccf1_score': array([0.7327023 , 0.78495037, 0.79504637, 0.63082807, 0.67538892])}, 'xgb_ensemble': {'fit_time': array([0.06973362, 0.06709099, 0.06757212, 0.0680759 , 0.07051134]), 'score_time': array([0.01637006, 0.01535821, 0.01559758, 0.01850271, 0.01726317]), 'test_accuracy': array([0.85      , 0.875     , 0.88333333, 0.85833333, 0.83333333]), 'test_balanced_accuracy': array([0.78968254, 0.8234127 , 0.81349206, 0.81150794, 0.7394958 ]), 'test_average_precision': array([0.82049063, 0.85652056, 0.84832119, 0.81706034, 0.79936702]), 'test_f1': array([0.71875   , 0.76923077, 0.76666667, 0.74626866, 0.64285714]), 'test_roc_auc': array([0.8776455 , 0.90079365, 0.88657407, 0.85185185, 0.85579832]), 'test_mccf1_score': array([0.76151677, 0.80390234, 0.80727858, 0.78250047, 0.70577541])}, 'lr_ensemble': {'fit_time': array([0.00478721, 0.0047636 , 0.00758481, 0.00493169, 0.00474858]), 'score_time': array([0.00948   , 0.00921822, 0.01004148, 0.00921202, 0.00918198]), 'test_accuracy': array([0.85      , 0.85833333, 0.875     , 0.84166667, 0.875     ]), 'test_balanced_accuracy': array([0.78174603, 0.81150794, 0.79960317, 0.79960317, 0.80252101]), 'test_average_precision': array([0.84151017, 0.85149177, 0.86951383, 0.82637024, 0.85979508]), 'test_f1': array([0.70967742, 0.74626866, 0.74576271, 0.72463768, 0.74576271]), 'test_roc_auc': array([0.90608466, 0.89054233, 0.89748677, 0.89021164, 0.90722689]), 'test_mccf1_score': array([0.75596414, 0.78250047, 0.79084054, 0.76242126, 0.78899416])}}\n",
      "2023-09-25 07:29:01,907 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 07:29:01,910 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 07:29:02,099 - Pipeline - INFO - dirName: 75_25_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 07:29:02,100 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 07:29:02,101 - Pipeline - INFO - Reading data\n",
      "2023-09-25 07:29:02,340 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 07:29:02,348 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 07:31:00,388 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 07:31:00,390 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:31:00,390 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:31:00,390 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:31:55,629 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:32:20,096 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:32:30,632 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:32:38,532 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:34:07,856 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:34:13,022 - Pipeline - INFO - params: {'max_depth': 5, 'scale_pos_weight': 0.25, 'n_estimators': 170, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.1, 'subsample': 0.6, 'reg_alpha': 0.001}\n",
      "2023-09-25 07:34:13,027 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:34:16,084 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 07:34:16,086 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:34:16,087 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:34:16,088 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:34:47,501 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:35:03,525 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:35:10,121 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:35:15,589 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:36:19,369 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:36:23,667 - Pipeline - INFO - params: {'max_depth': 7, 'scale_pos_weight': 0.2, 'n_estimators': 180, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 07:36:23,670 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:36:26,404 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 07:36:26,406 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:36:29,041 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:36:29,044 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:36:29,988 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 07:36:29,991 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:36:30,571 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:36:30,573 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:36:31,359 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 07:36:31,362 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:36:46,919 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:36:46,925 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:36:49,765 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 07:36:49,767 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:36:59,763 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:36:59,764 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:37:01,855 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 07:37:01,856 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:37:03,448 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:37:17,482 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 07:37:17,483 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:37:18,542 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:37:27,806 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 07:37:27,807 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 07:37:27,808 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 07:37:27,814 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 07:37:27,815 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:37:57,156 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:38:05,165 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:38:10,338 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:38:13,115 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:38:58,880 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:39:01,640 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 210, 'min_child_weight': 4, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.9, 'reg_alpha': 0.001}\n",
      "2023-09-25 07:39:01,641 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 07:39:02,142 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 07:39:45,096 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 07:39:45,097 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:39:45,098 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:39:45,099 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:40:11,946 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:40:23,487 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:40:25,861 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:40:27,675 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:40:50,325 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:40:51,871 - Pipeline - INFO - params: {'max_depth': 5, 'scale_pos_weight': 0.35, 'n_estimators': 60, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.9, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 07:40:51,873 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:40:53,362 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 07:40:53,364 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:40:53,947 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:40:53,949 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.19111705, 0.19631028, 0.19455743, 0.19135857, 0.29395032]), 'score_time': array([0.02706313, 0.02629352, 0.02643061, 0.02531266, 0.02624559]), 'test_accuracy': array([0.875     , 0.9       , 0.90833333, 0.8875    , 0.88333333]), 'test_balanced_accuracy': array([0.77777778, 0.80803446, 0.82498361, 0.79403502, 0.7798483 ]), 'test_average_precision': array([0.80731882, 0.83452653, 0.86551601, 0.81002438, 0.81557616]), 'test_f1': array([0.7       , 0.75510204, 0.78      , 0.72727273, 0.70833333]), 'test_roc_auc': array([0.87842593, 0.89455942, 0.93295252, 0.89530855, 0.87920217]), 'test_mccf1_score': array([0.75360798, 0.80036654, 0.81995073, 0.77631464, 0.76258737])}, 'lr': {'fit_time': array([0.02030325, 0.01977754, 0.01963186, 0.02194881, 0.01902056]), 'score_time': array([0.01135087, 0.00898814, 0.00896597, 0.00887394, 0.00885177]), 'test_accuracy': array([0.85      , 0.86666667, 0.8875    , 0.89583333, 0.875     ]), 'test_balanced_accuracy': array([0.75555556, 0.7973593 , 0.82259575, 0.81669632, 0.78003558]), 'test_average_precision': array([0.77969435, 0.82277512, 0.82472148, 0.77464943, 0.79381952]), 'test_f1': array([0.65384615, 0.70909091, 0.75229358, 0.75728155, 0.7       ]), 'test_roc_auc': array([0.85925926, 0.91487967, 0.92059182, 0.88201142, 0.87489465]), 'test_mccf1_score': array([0.71222837, 0.75545886, 0.79225796, 0.79913477, 0.75275037])}, 'lgbm': {'fit_time': array([0.21371126, 0.20529723, 0.20983648, 0.20598507, 0.21566892]), 'score_time': array([0.01180124, 0.01163483, 0.01127219, 0.01135111, 0.01156616]), 'test_accuracy': array([0.87083333, 0.9       , 0.9       , 0.875     , 0.8875    ]), 'test_balanced_accuracy': array([0.75833333, 0.81945875, 0.8251709 , 0.76289915, 0.79974717]), 'test_average_precision': array([0.77754786, 0.86309687, 0.87856218, 0.81326131, 0.82858046]), 'test_f1': array([0.67368421, 0.76470588, 0.76923077, 0.68085106, 0.73267327]), 'test_roc_auc': array([0.85509259, 0.91974904, 0.94372132, 0.89643225, 0.88247963]), 'test_mccf1_score': array([0.73543261, 0.80592094, 0.80866915, 0.74116344, 0.77958244])}, 'mlp': {'fit_time': array([1.30472279, 1.33828998, 1.40240359, 1.33693624, 1.28830028]), 'score_time': array([0.01158333, 0.01161623, 0.01483297, 0.0114758 , 0.01139688]), 'test_accuracy': array([0.8375    , 0.86666667, 0.85833333, 0.85833333, 0.84166667]), 'test_balanced_accuracy': array([0.76944444, 0.82020788, 0.79754659, 0.77469801, 0.7407997 ]), 'test_average_precision': array([0.76503017, 0.80207035, 0.79529509, 0.71574485, 0.74947428]), 'test_f1': array([0.66086957, 0.72881356, 0.70175439, 0.67924528, 0.62745098]), 'test_roc_auc': array([0.85064815, 0.89484034, 0.89427849, 0.81936511, 0.84708306]), 'test_mccf1_score': array([0.71323111, 0.76992687, 0.74796523, 0.73198297, 0.69054562])}, 'xgb_min': {'fit_time': array([0.17809415, 0.27610326, 0.17551136, 0.17187834, 0.17552662]), 'score_time': array([0.01439238, 0.01414633, 0.01321745, 0.01371622, 0.01315093]), 'test_accuracy': array([0.85416667, 0.88333333, 0.88333333, 0.86666667, 0.86666667]), 'test_balanced_accuracy': array([0.74722222, 0.79698474, 0.7798483 , 0.75166214, 0.74595   ]), 'test_average_precision': array([0.7381264 , 0.81613323, 0.81966122, 0.70001094, 0.76196951]), 'test_f1': array([0.64646465, 0.7254902 , 0.70833333, 0.65957447, 0.65217391]), 'test_roc_auc': array([0.84083333, 0.90729469, 0.88538253, 0.82161251, 0.87405188]), 'test_mccf1_score': array([0.7093015 , 0.77296015, 0.76258737, 0.72329681, 0.71890174])}, 'lr_min': {'fit_time': array([0.00477457, 0.00437808, 0.00449896, 0.0041604 , 0.00421882]), 'score_time': array([0.00897861, 0.01105523, 0.00825071, 0.00787711, 0.00789952]), 'test_accuracy': array([0.85416667, 0.87916667, 0.875     , 0.85833333, 0.88333333]), 'test_balanced_accuracy': array([0.74722222, 0.79422231, 0.76289915, 0.74613728, 0.7798483 ]), 'test_average_precision': array([0.75919542, 0.79790855, 0.81143478, 0.70437122, 0.76584214]), 'test_f1': array([0.64646465, 0.7184466 , 0.68085106, 0.64583333, 0.70833333]), 'test_roc_auc': array([0.83759259, 0.90879296, 0.87732934, 0.8505478 , 0.85541717]), 'test_mccf1_score': array([0.7093015 , 0.7664823 , 0.74116344, 0.71010324, 0.76258737])}, 'lgbm_min': {'fit_time': array([0.13450193, 0.12409854, 0.12884569, 0.13248825, 0.13087583]), 'score_time': array([0.01054835, 0.0096252 , 0.00968099, 0.00979543, 0.00960231]), 'test_accuracy': array([0.85      , 0.88333333, 0.86666667, 0.875     , 0.88333333]), 'test_balanced_accuracy': array([0.74444444, 0.80269688, 0.75166214, 0.76861129, 0.77413616]), 'test_average_precision': array([0.76819793, 0.83246329, 0.79935963, 0.72883251, 0.77715148]), 'test_f1': array([0.64      , 0.73076923, 0.65957447, 0.6875    , 0.70212766]), 'test_roc_auc': array([0.85064815, 0.92293286, 0.89418485, 0.84792584, 0.86459406]), 'test_mccf1_score': array([0.70314323, 0.77631951, 0.72329681, 0.74509546, 0.7590255 ])}, 'mlp_min': {'fit_time': array([0.86501193, 0.86204171, 0.86702323, 0.86107826, 0.84428477]), 'score_time': array([0.00965357, 0.00958014, 0.00951242, 0.00936365, 0.00925303]), 'test_accuracy': array([0.80833333, 0.87083333, 0.85      , 0.81666667, 0.85416667]), 'test_balanced_accuracy': array([0.72777778, 0.82297032, 0.77488529, 0.72993726, 0.77193557]), 'test_average_precision': array([0.69604265, 0.80717975, 0.72486454, 0.68646448, 0.73564541]), 'test_f1': array([0.59649123, 0.73504274, 0.67272727, 0.6       , 0.6728972 ]), 'test_roc_auc': array([0.80944444, 0.89502762, 0.8166495 , 0.82282985, 0.82105066]), 'test_mccf1_score': array([0.65910952, 0.77541027, 0.72478442, 0.66343533, 0.72617607])}, 'xgb_ensemble': {'fit_time': array([0.0576756 , 0.05516911, 0.05538321, 0.05527139, 0.05428505]), 'score_time': array([0.01757884, 0.01620007, 0.01592422, 0.01596498, 0.01643276]), 'test_accuracy': array([0.86666667, 0.85833333, 0.90833333, 0.89166667, 0.875     ]), 'test_balanced_accuracy': array([0.7839797 , 0.76785067, 0.84360275, 0.82185574, 0.80010874]), 'test_average_precision': array([0.81620532, 0.71004209, 0.84952822, 0.84733153, 0.82848418]), 'test_f1': array([0.7037037 , 0.67924528, 0.8       , 0.76363636, 0.72727273]), 'test_roc_auc': array([0.89923885, 0.83109822, 0.88546575, 0.89054005, 0.88691555]), 'test_mccf1_score': array([0.75330099, 0.73383074, 0.83360398, 0.80288196, 0.77215784])}, 'lr_ensemble': {'fit_time': array([0.0100596 , 0.01124692, 0.01010656, 0.00983739, 0.00990033]), 'score_time': array([0.00943589, 0.00933385, 0.00912189, 0.00906682, 0.00913715]), 'test_accuracy': array([0.86666667, 0.83333333, 0.90833333, 0.925     , 0.90833333]), 'test_balanced_accuracy': array([0.7839797 , 0.72997463, 0.85411381, 0.87586082, 0.85411381]), 'test_average_precision': array([0.82368981, 0.77900989, 0.86649638, 0.89097492, 0.82437636]), 'test_f1': array([0.7037037 , 0.61538462, 0.80701754, 0.84210526, 0.80701754]), 'test_roc_auc': array([0.90938746, 0.87169264, 0.90612541, 0.93294672, 0.89561435]), 'test_mccf1_score': array([0.75330099, 0.68126214, 0.83789187, 0.8675964 , 0.83789187])}}\n",
      "2023-09-25 07:40:54,811 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 07:40:54,813 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 07:40:55,007 - Pipeline - INFO - dirName: 80_20_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 07:40:55,008 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 07:40:55,009 - Pipeline - INFO - Reading data\n",
      "2023-09-25 07:40:55,258 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 07:40:55,266 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 07:42:57,088 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 07:42:57,090 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:42:57,090 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:42:57,091 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:43:51,702 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:44:06,855 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:44:12,136 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:44:15,005 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:44:58,186 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:45:01,150 - Pipeline - INFO - params: {'max_depth': 1, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 07:45:01,151 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:45:03,115 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 07:45:03,116 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:45:03,117 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:45:03,117 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:45:33,949 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:45:49,228 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:45:52,872 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:45:55,600 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:46:28,110 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:46:30,633 - Pipeline - INFO - params: {'max_depth': 9, 'scale_pos_weight': 0.25, 'n_estimators': 80, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 07:46:30,634 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:46:32,546 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 07:46:32,548 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:46:35,268 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:46:35,269 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:46:36,232 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 07:46:36,233 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:46:36,779 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:46:36,780 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:46:37,669 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 07:46:37,670 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:46:53,021 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:46:53,022 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:46:55,103 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 07:46:55,105 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:47:05,219 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:47:05,220 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:47:07,551 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 07:47:07,552 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:47:09,247 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:47:23,793 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 07:47:23,795 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:47:24,853 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:47:34,117 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 07:47:34,118 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 07:47:34,119 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 07:47:34,125 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 07:47:34,126 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:48:02,726 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:48:16,224 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:48:18,594 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:48:20,207 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:48:42,019 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:48:43,362 - Pipeline - INFO - params: {'max_depth': 5, 'scale_pos_weight': 0.3, 'n_estimators': 60, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.2, 'subsample': 0.5, 'reg_alpha': 0}\n",
      "2023-09-25 07:48:43,364 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 07:48:43,904 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 07:49:25,407 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 07:49:25,409 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:49:25,410 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:49:25,411 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:49:50,060 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:50:00,356 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:50:03,967 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:50:06,754 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:50:41,194 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:50:43,414 - Pipeline - INFO - params: {'max_depth': 5, 'scale_pos_weight': 0.15, 'n_estimators': 140, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.5, 'reg_alpha': 0.1}\n",
      "2023-09-25 07:50:43,416 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:50:45,188 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 07:50:45,191 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:50:45,745 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:50:45,746 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.09364414, 0.09212732, 0.19365191, 0.10759163, 0.09318161]), 'score_time': array([0.02541709, 0.02502346, 0.0254693 , 0.02502489, 0.02466011]), 'test_accuracy': array([0.925     , 0.925     , 0.9       , 0.9125    , 0.91666667]), 'test_balanced_accuracy': array([0.828125  , 0.8125    , 0.765625  , 0.79269099, 0.79528167]), 'test_average_precision': array([0.88493127, 0.88588954, 0.7590453 , 0.81182266, 0.84920405]), 'test_f1': array([0.7804878 , 0.76923077, 0.68421053, 0.72727273, 0.73684211]), 'test_roc_auc': array([0.94520399, 0.9391276 , 0.8625217 , 0.90089296, 0.91798038]), 'test_mccf1_score': array([0.82186359, 0.81540977, 0.74672846, 0.78031992, 0.78906574])}, 'lr': {'fit_time': array([0.0225966 , 0.02222371, 0.02131987, 0.01908612, 0.01961064]), 'score_time': array([0.00976181, 0.00880647, 0.00877619, 0.00880313, 0.00876474]), 'test_accuracy': array([0.93333333, 0.89583333, 0.89583333, 0.9       , 0.90833333]), 'test_balanced_accuracy': array([0.85677083, 0.79427083, 0.78645833, 0.80101422, 0.83838607]), 'test_average_precision': array([0.80213109, 0.84743682, 0.73359297, 0.79550083, 0.81696355]), 'test_f1': array([0.81395349, 0.70588235, 0.69879518, 0.71428571, 0.75555556]), 'test_roc_auc': array([0.91959635, 0.93815104, 0.8375651 , 0.90089296, 0.89670378]), 'test_mccf1_score': array([0.8475029 , 0.75834556, 0.75355497, 0.7652009 , 0.79726419])}, 'lgbm': {'fit_time': array([0.13542008, 0.12955785, 0.13565564, 0.13865399, 0.13629127]), 'score_time': array([0.01135063, 0.01107645, 0.01168561, 0.0167706 , 0.01135874]), 'test_accuracy': array([0.93333333, 0.925     , 0.8875    , 0.89583333, 0.925     ]), 'test_balanced_accuracy': array([0.84895833, 0.8125    , 0.75      , 0.76623305, 0.82460589]), 'test_average_precision': array([0.88461815, 0.89905646, 0.78545941, 0.81587702, 0.8722806 ]), 'test_f1': array([0.80952381, 0.76923077, 0.64935065, 0.67532468, 0.775     ]), 'test_roc_auc': array([0.93804253, 0.94715712, 0.87597656, 0.91158637, 0.93286297]), 'test_mccf1_score': array([0.84478809, 0.81540977, 0.71691262, 0.73731386, 0.8176737 ])}, 'mlp': {'fit_time': array([1.40399671, 1.43408394, 1.39507985, 1.29651237, 1.32273912]), 'score_time': array([0.01127267, 0.01103592, 0.01149988, 0.01143885, 0.01108527]), 'test_accuracy': array([0.9125    , 0.9125    , 0.87083333, 0.875     , 0.88333333]), 'test_balanced_accuracy': array([0.828125  , 0.8359375 , 0.74739583, 0.77742256, 0.8147944 ]), 'test_average_precision': array([0.78371003, 0.8652062 , 0.68012438, 0.74786676, 0.7956425 ]), 'test_f1': array([0.75862069, 0.76404494, 0.62650602, 0.65909091, 0.70212766]), 'test_roc_auc': array([0.87413194, 0.94010417, 0.80978733, 0.8437879 , 0.88942785]), 'test_mccf1_score': array([0.80117383, 0.80491839, 0.69362678, 0.7178048 , 0.75197879])}, 'xgb_min': {'fit_time': array([0.09448266, 0.09664702, 0.0935688 , 0.09243536, 0.09251881]), 'score_time': array([0.01414371, 0.01557732, 0.01345897, 0.01375651, 0.01341414]), 'test_accuracy': array([0.91666667, 0.925     , 0.88333333, 0.89583333, 0.91666667]), 'test_balanced_accuracy': array([0.80729167, 0.8203125 , 0.73177083, 0.76623305, 0.82747216]), 'test_average_precision': array([0.82651041, 0.88404813, 0.74887775, 0.7908243 , 0.81035338]), 'test_f1': array([0.75      , 0.775     , 0.62162162, 0.67532468, 0.76190476]), 'test_roc_auc': array([0.91417101, 0.94835069, 0.86197917, 0.90188513, 0.89482968]), 'test_mccf1_score': array([0.79793866, 0.81864954, 0.69680226, 0.73731386, 0.804649  ])}, 'lr_min': {'fit_time': array([0.0116508 , 0.01033044, 0.00945807, 0.00977349, 0.00990653]), 'score_time': array([0.00819921, 0.0080781 , 0.00801921, 0.00785041, 0.00785613]), 'test_accuracy': array([0.89583333, 0.90833333, 0.88333333, 0.9125    , 0.90833333]), 'test_balanced_accuracy': array([0.75520833, 0.80989583, 0.76302083, 0.79269099, 0.82229082]), 'test_average_precision': array([0.80775872, 0.83879835, 0.73596353, 0.79358629, 0.77972632]), 'test_f1': array([0.66666667, 0.73809524, 0.65853659, 0.72727273, 0.74418605]), 'test_roc_auc': array([0.89040799, 0.92556424, 0.84950087, 0.90243634, 0.88005733]), 'test_mccf1_score': array([0.7331518 , 0.78557475, 0.72078989, 0.78031992, 0.7891164 ])}, 'lgbm_min': {'fit_time': array([0.15883207, 0.15730405, 0.1545217 , 0.1594348 , 0.15938711]), 'score_time': array([0.00982976, 0.01029706, 0.01002359, 0.01014519, 0.0098567 ]), 'test_accuracy': array([0.90833333, 0.92083333, 0.89166667, 0.9       , 0.92083333]), 'test_balanced_accuracy': array([0.79427083, 0.81770833, 0.75260417, 0.76882372, 0.83811046]), 'test_average_precision': array([0.84216241, 0.87938486, 0.77449313, 0.78330748, 0.80863178]), 'test_f1': array([0.725     , 0.7654321 , 0.65789474, 0.68421053, 0.77647059]), 'test_roc_auc': array([0.92285156, 0.94976128, 0.87022569, 0.8938375 , 0.89273509]), 'test_mccf1_score': array([0.77722358, 0.81003142, 0.72490563, 0.74549464, 0.81627753])}, 'mlp_min': {'fit_time': array([0.86581993, 0.86453176, 0.86842084, 0.84706974, 0.84442568]), 'score_time': array([0.00903845, 0.00874877, 0.00940037, 0.00847149, 0.0085845 ]), 'test_accuracy': array([0.90833333, 0.89583333, 0.88333333, 0.8625    , 0.87083333]), 'test_balanced_accuracy': array([0.82552083, 0.83333333, 0.77083333, 0.76160291, 0.79897475]), 'test_average_precision': array([0.77629551, 0.82014246, 0.69891526, 0.73495429, 0.7670253 ]), 'test_f1': array([0.75      , 0.73684211, 0.66666667, 0.62921348, 0.67368421]), 'test_roc_auc': array([0.84038628, 0.89832899, 0.81651476, 0.86859222, 0.852056  ]), 'test_mccf1_score': array([0.79362087, 0.78073719, 0.72635331, 0.69266331, 0.72811025])}, 'xgb_ensemble': {'fit_time': array([0.08013487, 0.07333875, 0.07866764, 0.07748818, 0.08490038]), 'score_time': array([0.01823545, 0.01629734, 0.01739144, 0.08933377, 0.01674581]), 'test_accuracy': array([0.91666667, 0.875     , 0.95833333, 0.91666667, 0.91666667]), 'test_balanced_accuracy': array([0.77272727, 0.70708203, 0.90788884, 0.81577768, 0.79919319]), 'test_average_precision': array([0.86160743, 0.70238382, 0.93304382, 0.88501379, 0.84169381]), 'test_f1': array([0.70588235, 0.57142857, 0.88372093, 0.75      , 0.73684211]), 'test_roc_auc': array([0.94016698, 0.85611833, 0.96548633, 0.94576423, 0.88346033]), 'test_mccf1_score': array([0.76710589, 0.65663842, 0.90431997, 0.7961507 , 0.78791296])}, 'lr_ensemble': {'fit_time': array([0.00647116, 0.00627756, 0.00618052, 0.00635386, 0.00666618]), 'score_time': array([0.00959992, 0.00943112, 0.00952315, 0.00936437, 0.00949597]), 'test_accuracy': array([0.90833333, 0.875     , 0.95833333, 0.90833333, 0.91666667]), 'test_balanced_accuracy': array([0.78525046, 0.72366652, 0.94105782, 0.84379202, 0.79919319]), 'test_average_precision': array([0.78573054, 0.74317434, 0.941265  , 0.87096703, 0.77291292]), 'test_f1': array([0.7027027 , 0.59459459, 0.89361702, 0.75555556, 0.73684211]), 'test_roc_auc': array([0.90445269, 0.88121918, 0.96996862, 0.95383236, 0.87673689]), 'test_mccf1_score': array([0.75913955, 0.67188397, 0.91148038, 0.79709979, 0.78791296])}}\n",
      "2023-09-25 07:50:46,543 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 07:50:46,545 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 07:50:46,750 - Pipeline - INFO - dirName: 85_15_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 07:50:46,751 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 07:50:46,752 - Pipeline - INFO - Reading data\n",
      "2023-09-25 07:50:47,001 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 07:50:47,009 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 07:53:01,831 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 07:53:01,833 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:53:01,833 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:53:01,834 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:53:53,281 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:54:16,677 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:54:21,991 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:54:25,889 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:55:10,950 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:55:14,136 - Pipeline - INFO - params: {'max_depth': 9, 'scale_pos_weight': 0.3, 'n_estimators': 70, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 07:55:14,138 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:55:16,301 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 07:55:16,302 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:55:16,303 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:55:16,304 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:55:45,497 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:56:00,323 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:56:04,118 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:56:07,384 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:56:45,671 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:56:48,051 - Pipeline - INFO - params: {'max_depth': 9, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.4, 'reg_alpha': 0}\n",
      "2023-09-25 07:56:48,053 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:56:49,797 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 07:56:49,798 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:56:52,421 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:56:52,422 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:56:53,366 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 07:56:53,367 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:56:53,950 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:56:53,951 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:56:54,981 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 07:56:54,982 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:57:10,803 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:57:10,805 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:57:13,924 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 07:57:13,925 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:57:24,572 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:57:24,574 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:57:26,864 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 07:57:26,866 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:57:28,343 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:57:42,065 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 07:57:42,067 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:57:43,128 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 07:57:52,495 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 07:57:52,496 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 07:57:52,497 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 07:57:52,503 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 07:57:52,504 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 07:58:20,498 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 07:58:30,009 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 07:58:33,177 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 07:58:35,240 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 07:59:06,337 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 07:59:08,450 - Pipeline - INFO - params: {'max_depth': 3, 'scale_pos_weight': 0.15, 'n_estimators': 120, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.9, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 07:59:08,452 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 07:59:08,990 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 07:59:49,978 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 07:59:49,982 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 07:59:49,983 - Pipeline - INFO - Building the model\n",
      "2023-09-25 07:59:49,984 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:00:13,710 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:00:21,639 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:00:24,531 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:00:26,228 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:00:53,333 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:00:55,067 - Pipeline - INFO - params: {'max_depth': 1, 'scale_pos_weight': 0.25, 'n_estimators': 130, 'min_child_weight': 3, 'gamma': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 08:00:55,069 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:00:56,487 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 08:00:56,489 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:00:57,039 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:00:57,041 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.11869645, 0.11750102, 0.12038374, 0.11731791, 0.11786509]), 'score_time': array([0.02547908, 0.02445698, 0.02484727, 0.02500224, 0.02458239]), 'test_accuracy': array([0.92916667, 0.92916667, 0.94166667, 0.90833333, 0.92916667]), 'test_balanced_accuracy': array([0.76898955, 0.78083624, 0.82369338, 0.71732026, 0.78676471]), 'test_average_precision': array([0.81201942, 0.74255147, 0.89558872, 0.71916066, 0.79134811]), 'test_f1': array([0.69090909, 0.70175439, 0.76666667, 0.59259259, 0.71186441]), 'test_roc_auc': array([0.9041115 , 0.89365854, 0.97031359, 0.87445534, 0.90100763]), 'test_mccf1_score': array([0.75501928, 0.76183698, 0.81248476, 0.67738251, 0.76959794])}, 'lr': {'fit_time': array([0.02280188, 0.01893282, 0.02202106, 0.01905489, 0.02279687]), 'score_time': array([0.00958824, 0.00888729, 0.00895214, 0.0088675 , 0.00884414]), 'test_accuracy': array([0.92083333, 0.925     , 0.94166667, 0.91666667, 0.91666667]), 'test_balanced_accuracy': array([0.77595819, 0.7902439 , 0.84738676, 0.75653595, 0.77941176]), 'test_average_precision': array([0.80327855, 0.81947089, 0.87810527, 0.74774264, 0.65800441]), 'test_f1': array([0.6779661 , 0.7       , 0.78125   , 0.65517241, 0.67741935]), 'test_roc_auc': array([0.91163763, 0.93296167, 0.95289199, 0.87472767, 0.87581699]), 'test_mccf1_score': array([0.74072043, 0.75801544, 0.82225655, 0.72410993, 0.7391399 ])}, 'lgbm': {'fit_time': array([0.23394632, 0.23172259, 0.23407745, 0.23160672, 0.24204993]), 'score_time': array([0.01188087, 0.01186514, 0.01170635, 0.01240039, 0.01164389]), 'test_accuracy': array([0.925     , 0.92083333, 0.94166667, 0.92083333, 0.93333333]), 'test_balanced_accuracy': array([0.76655052, 0.75226481, 0.8       , 0.74754902, 0.78921569]), 'test_average_precision': array([0.77790195, 0.74943827, 0.8951141 , 0.74940878, 0.78205459]), 'test_f1': array([0.67857143, 0.65454545, 0.75      , 0.65454545, 0.72413793]), 'test_roc_auc': array([0.89212544, 0.91289199, 0.95944251, 0.89624183, 0.89692266]), 'test_mccf1_score': array([0.74384847, 0.7252511 , 0.80226728, 0.7269287 , 0.7805742 ])}, 'mlp': {'fit_time': array([1.38566875, 1.31468129, 1.27872229, 1.1744771 , 1.16760659]), 'score_time': array([0.01170874, 0.01170969, 0.0118587 , 0.01161194, 0.01200914]), 'test_accuracy': array([0.9375    , 0.90416667, 0.925     , 0.89583333, 0.87916667]), 'test_balanced_accuracy': array([0.82125436, 0.7543554 , 0.81393728, 0.73284314, 0.72303922]), 'test_average_precision': array([0.78413645, 0.76490501, 0.80694138, 0.66344149, 0.6193028 ]), 'test_f1': array([0.75409836, 0.62295082, 0.71875   , 0.59016393, 0.55384615]), 'test_roc_auc': array([0.87470383, 0.89783972, 0.92055749, 0.79575163, 0.86206427]), 'test_mccf1_score': array([0.80157618, 0.69442321, 0.77117919, 0.668434  , 0.63639883])}, 'xgb_min': {'fit_time': array([0.08609319, 0.08202434, 0.08523297, 0.08461976, 0.18733931]), 'score_time': array([0.0133636 , 0.01238394, 0.01241994, 0.01228356, 0.01382065]), 'test_accuracy': array([0.91666667, 0.91666667, 0.9375    , 0.9125    , 0.90833333]), 'test_balanced_accuracy': array([0.78536585, 0.76167247, 0.82125436, 0.73120915, 0.7630719 ]), 'test_average_precision': array([0.78188461, 0.73586405, 0.8149547 , 0.71955621, 0.70049241]), 'test_f1': array([0.67741935, 0.65517241, 0.75409836, 0.61818182, 0.64516129]), 'test_roc_auc': array([0.90982578, 0.90648084, 0.93783972, 0.87200436, 0.86029412]), 'test_mccf1_score': array([0.73835883, 0.7228742 , 0.80157618, 0.69708958, 0.71275374])}, 'lr_min': {'fit_time': array([0.01142383, 0.00945663, 0.19464231, 0.01453876, 0.00939989]), 'score_time': array([0.00819182, 0.00864673, 0.00923324, 0.02673697, 0.00804496]), 'test_accuracy': array([0.91666667, 0.8875    , 0.94166667, 0.91666667, 0.90833333]), 'test_balanced_accuracy': array([0.76167247, 0.68536585, 0.83554007, 0.74509804, 0.72875817]), 'test_average_precision': array([0.7882108 , 0.69207096, 0.89415417, 0.72230511, 0.66226872]), 'test_f1': array([0.65517241, 0.50909091, 0.77419355, 0.64285714, 0.60714286]), 'test_roc_auc': array([0.92836237, 0.88947735, 0.96292683, 0.86614924, 0.87867647]), 'test_mccf1_score': array([0.7228742 , 0.60610026, 0.81742531, 0.71612666, 0.68683828])}, 'lgbm_min': {'fit_time': array([0.1463356 , 0.13983059, 0.14101148, 0.14591503, 0.1479094 ]), 'score_time': array([0.01062608, 0.01027727, 0.01074409, 0.0100956 , 0.01067209]), 'test_accuracy': array([0.9125    , 0.9125    , 0.94166667, 0.90833333, 0.92083333]), 'test_balanced_accuracy': array([0.74738676, 0.73554007, 0.8       , 0.74019608, 0.78186275]), 'test_average_precision': array([0.75929291, 0.7232487 , 0.88384486, 0.7028262 , 0.73188896]), 'test_f1': array([0.63157895, 0.61818182, 0.75      , 0.62068966, 0.68852459]), 'test_roc_auc': array([0.90425087, 0.9071777 , 0.96111498, 0.8880719 , 0.89256536]), 'test_mccf1_score': array([0.70444405, 0.69547282, 0.80226728, 0.69586844, 0.7489047 ])}, 'mlp_min': {'fit_time': array([0.86553502, 0.86451364, 0.86222076, 0.86068344, 0.8545239 ]), 'score_time': array([0.00905633, 0.00868416, 0.00845551, 0.00858855, 0.0083158 ]), 'test_accuracy': array([0.9       , 0.8875    , 0.9       , 0.88333333, 0.87916667]), 'test_balanced_accuracy': array([0.81114983, 0.70905923, 0.74006969, 0.75980392, 0.72303922]), 'test_average_precision': array([0.72925921, 0.61240644, 0.66890079, 0.66804716, 0.55362245]), 'test_f1': array([0.66666667, 0.54237288, 0.6       , 0.6       , 0.55384615]), 'test_roc_auc': array([0.87149826, 0.82578397, 0.85170732, 0.80664488, 0.84858388]), 'test_mccf1_score': array([0.7266104 , 0.62988941, 0.67629933, 0.67232671, 0.63639883])}, 'xgb_ensemble': {'fit_time': array([0.06259179, 0.05947161, 0.06011558, 0.0594542 , 0.0595777 ]), 'score_time': array([0.01608443, 0.01585627, 0.01590896, 0.01596522, 0.01559567]), 'test_accuracy': array([0.95      , 0.9       , 0.94166667, 0.91666667, 0.95      ]), 'test_balanced_accuracy': array([0.83333333, 0.7124183 , 0.85130719, 0.74509804, 0.87908497]), 'test_average_precision': array([0.86401078, 0.71660627, 0.89360387, 0.70489633, 0.88160054]), 'test_f1': array([0.8       , 0.57142857, 0.78787879, 0.64285714, 0.82352941]), 'test_roc_auc': array([0.91394336, 0.8496732 , 0.97058824, 0.88453159, 0.95642702]), 'test_mccf1_score': array([0.84084381, 0.65754183, 0.8274256 , 0.71612666, 0.85594091])}, 'lr_ensemble': {'fit_time': array([0.01027584, 0.01149344, 0.01008892, 0.00983524, 0.00982237]), 'score_time': array([0.00982594, 0.00960517, 0.01007271, 0.0101614 , 0.00973082]), 'test_accuracy': array([0.95833333, 0.925     , 0.91666667, 0.89166667, 0.90833333]), 'test_balanced_accuracy': array([0.86111111, 0.77287582, 0.76797386, 0.70751634, 0.7630719 ]), 'test_average_precision': array([0.85246915, 0.76413998, 0.84647214, 0.73935799, 0.77418224]), 'test_f1': array([0.83870968, 0.68965517, 0.66666667, 0.55172414, 0.64516129]), 'test_roc_auc': array([0.90196078, 0.89106754, 0.94444444, 0.89978214, 0.92810458]), 'test_mccf1_score': array([0.87103988, 0.75234589, 0.73177506, 0.6393741 , 0.71275374])}}\n",
      "2023-09-25 08:00:57,905 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 08:00:57,907 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 08:00:58,100 - Pipeline - INFO - dirName: 90_10_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 08:00:58,101 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 08:00:58,102 - Pipeline - INFO - Reading data\n",
      "2023-09-25 08:00:58,357 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 08:00:58,365 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 08:02:38,260 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 08:02:38,261 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:02:38,262 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:02:38,263 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:03:28,488 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:03:50,341 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:03:55,123 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:03:58,338 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:04:37,543 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:04:40,132 - Pipeline - INFO - params: {'max_depth': 6, 'scale_pos_weight': 0.3, 'n_estimators': 60, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 08:04:40,138 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:04:41,966 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 08:04:41,967 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:04:41,967 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:04:41,968 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:05:09,852 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:05:23,131 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:05:26,447 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:05:28,974 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:05:59,697 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:06:01,884 - Pipeline - INFO - params: {'max_depth': 5, 'scale_pos_weight': 0.3, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 08:06:01,887 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:03,603 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 08:06:03,604 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:06:06,129 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:06,131 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:07,133 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 08:06:07,135 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:06:07,685 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:07,686 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:08,483 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 08:06:08,484 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:06:24,613 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:24,614 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:27,549 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 08:06:27,550 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:06:37,745 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:37,746 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:40,095 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 08:06:40,097 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:41,503 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:06:54,355 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 08:06:54,356 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:06:55,387 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:07:04,638 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 08:07:04,640 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 08:07:04,640 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 08:07:04,645 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 08:07:04,646 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:07:30,623 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:07:38,749 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:07:41,271 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:07:42,794 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:08:06,355 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:08:07,733 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.3, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.1, 'subsample': 0.5, 'reg_alpha': 0}\n",
      "2023-09-25 08:08:07,734 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 08:08:08,170 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 08:08:46,645 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 08:08:46,647 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:08:46,648 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:08:46,648 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:09:09,461 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:09:18,264 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:09:20,315 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:09:21,658 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:09:40,825 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:09:42,042 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.2, 'n_estimators': 70, 'min_child_weight': 1, 'gamma': 0.1, 'colsample_bytree': 0.8, 'subsample': 0.5, 'reg_alpha': 0}\n",
      "2023-09-25 08:09:42,043 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:09:43,274 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 08:09:43,275 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:09:43,812 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:09:43,814 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.09598446, 0.09342217, 0.09493947, 0.09255219, 0.09396815]), 'score_time': array([0.02478576, 0.02470064, 0.02509117, 0.02482772, 0.02503753]), 'test_accuracy': array([0.94583333, 0.94166667, 0.9625    , 0.92083333, 0.9375    ]), 'test_balanced_accuracy': array([0.74768519, 0.72685185, 0.83101852, 0.60416667, 0.70601852]), 'test_average_precision': array([0.74628551, 0.64533727, 0.80230129, 0.57344332, 0.71276864]), 'test_f1': array([0.64864865, 0.61111111, 0.7804878 , 0.34482759, 0.57142857]), 'test_roc_auc': array([0.88445216, 0.85725309, 0.91975309, 0.7810571 , 0.92033179]), 'test_mccf1_score': array([0.72347277, 0.69464712, 0.82545045, 0.49585431, 0.66423593])}, 'lr': {'fit_time': array([0.02347875, 0.02209425, 0.0243082 , 0.0241766 , 0.02310205]), 'score_time': array([0.00948071, 0.00913668, 0.01202273, 0.00916672, 0.00918508]), 'test_accuracy': array([0.9625    , 0.94166667, 0.9375    , 0.92916667, 0.95833333]), 'test_balanced_accuracy': array([0.83101852, 0.72685185, 0.83564815, 0.68287037, 0.81018519]), 'test_average_precision': array([0.83716132, 0.65496437, 0.73704571, 0.62884974, 0.7183664 ]), 'test_f1': array([0.7804878 , 0.61111111, 0.69387755, 0.51428571, 0.75      ]), 'test_roc_auc': array([0.91840278, 0.82986111, 0.95119599, 0.83873457, 0.84760802]), 'test_mccf1_score': array([0.82545045, 0.69464712, 0.75227365, 0.61763798, 0.80173785])}, 'lgbm': {'fit_time': array([0.21994519, 0.21956253, 0.20952773, 0.2197957 , 0.21574306]), 'score_time': array([0.01159859, 0.01159811, 0.01129389, 0.0118022 , 0.01211119]), 'test_accuracy': array([0.94583333, 0.94166667, 0.94583333, 0.91666667, 0.94166667]), 'test_balanced_accuracy': array([0.74768519, 0.72685185, 0.7662037 , 0.58333333, 0.72685185]), 'test_average_precision': array([0.74262392, 0.66486543, 0.84189485, 0.5548979 , 0.73405987]), 'test_f1': array([0.64864865, 0.61111111, 0.66666667, 0.28571429, 0.61111111]), 'test_roc_auc': array([0.89602623, 0.86496914, 0.9537037 , 0.79436728, 0.89891975]), 'test_mccf1_score': array([0.72347277, 0.69464712, 0.73538892, 0.45088421, 0.69464712])}, 'mlp': {'fit_time': array([1.17851734, 1.24364662, 1.33167505, 1.1474576 , 1.1667521 ]), 'score_time': array([0.01133037, 0.01136971, 0.01148963, 0.01163888, 0.01171398]), 'test_accuracy': array([0.95      , 0.93333333, 0.92916667, 0.93333333, 0.92083333]), 'test_balanced_accuracy': array([0.82407407, 0.72222222, 0.77546296, 0.68518519, 0.75231481]), 'test_average_precision': array([0.7772813 , 0.62559399, 0.75176578, 0.61790021, 0.64089365]), 'test_f1': array([0.72727273, 0.57894737, 0.62222222, 0.52941176, 0.57777778]), 'test_roc_auc': array([0.86323302, 0.78317901, 0.94444444, 0.86863426, 0.76176698]), 'test_mccf1_score': array([0.78050706, 0.66552406, 0.69521352, 0.63208102, 0.65930192])}, 'xgb_min': {'fit_time': array([0.08602166, 0.08107424, 0.08161688, 0.0786283 , 0.0815258 ]), 'score_time': array([0.01362514, 0.01271868, 0.01297641, 0.01246452, 0.01304221]), 'test_accuracy': array([0.94583333, 0.93333333, 0.95833333, 0.9125    , 0.94166667]), 'test_balanced_accuracy': array([0.7662037 , 0.72222222, 0.79166667, 0.5625    , 0.74537037]), 'test_average_precision': array([0.67279344, 0.63762352, 0.82204692, 0.39486161, 0.69531468]), 'test_f1': array([0.66666667, 0.57894737, 0.73684211, 0.22222222, 0.63157895]), 'test_roc_auc': array([0.81693673, 0.84741512, 0.93981481, 0.78549383, 0.91184414]), 'test_mccf1_score': array([0.73538892, 0.66552406, 0.79348658, 0.40223077, 0.7081941 ])}, 'lr_min': {'fit_time': array([0.00443053, 0.00419497, 0.00419593, 0.00501251, 0.00424385]), 'score_time': array([0.0082531 , 0.00804687, 0.00880361, 0.00814271, 0.00887442]), 'test_accuracy': array([0.94166667, 0.925     , 0.9375    , 0.9125    , 0.93333333]), 'test_balanced_accuracy': array([0.72685185, 0.68055556, 0.70601852, 0.5625    , 0.7037037 ]), 'test_average_precision': array([0.6828204 , 0.51866892, 0.7435911 , 0.40340452, 0.65161157]), 'test_f1': array([0.61111111, 0.5       , 0.57142857, 0.22222222, 0.55555556]), 'test_roc_auc': array([0.89274691, 0.77199074, 0.93537809, 0.79822531, 0.85320216]), 'test_mccf1_score': array([0.69464712, 0.60425052, 0.66423593, 0.40223077, 0.64946017])}, 'lgbm_min': {'fit_time': array([0.36626887, 0.12682104, 0.13086772, 0.1305902 , 0.16255713]), 'score_time': array([0.01095748, 0.01000118, 0.01007462, 0.01110816, 0.01028419]), 'test_accuracy': array([0.94583333, 0.94166667, 0.95      , 0.9125    , 0.95416667]), 'test_balanced_accuracy': array([0.72916667, 0.74537037, 0.76851852, 0.5625    , 0.78935185]), 'test_average_precision': array([0.71084275, 0.69332313, 0.80482886, 0.46604557, 0.75709655]), 'test_f1': array([0.62857143, 0.63157895, 0.68421053, 0.22222222, 0.71794872]), 'test_roc_auc': array([0.85320216, 0.85339506, 0.95158179, 0.81751543, 0.93248457]), 'test_mccf1_score': array([0.71079014, 0.7081941 , 0.75085099, 0.40223077, 0.77690341])}, 'mlp_min': {'fit_time': array([0.84501648, 0.85372233, 0.85832834, 0.84982777, 0.85311246]), 'score_time': array([0.00932693, 0.00960875, 0.00944066, 0.0092833 , 0.00919557]), 'test_accuracy': array([0.92083333, 0.91666667, 0.89583333, 0.9       , 0.91666667]), 'test_balanced_accuracy': array([0.71527778, 0.67592593, 0.70138889, 0.55555556, 0.73148148]), 'test_average_precision': array([0.59903354, 0.47154885, 0.58957938, 0.36305677, 0.61672239]), 'test_f1': array([0.53658537, 0.47368421, 0.46808511, 0.2       , 0.54545455]), 'test_roc_auc': array([0.81076389, 0.72280093, 0.84587191, 0.76331019, 0.77989969]), 'test_mccf1_score': array([0.62825721, 0.58016058, 0.56999215, 0.3696652 , 0.63360989])}, 'xgb_ensemble': {'fit_time': array([0.0439527 , 0.04157853, 0.0418098 , 0.04106236, 0.0416646 ]), 'score_time': array([0.01643872, 0.01573992, 0.01567936, 0.0161438 , 0.01531529]), 'test_accuracy': array([0.94166667, 0.95      , 0.95      , 0.925     , 0.96666667]), 'test_balanced_accuracy': array([0.70833333, 0.75      , 0.75      , 0.66203704, 0.84615385]), 'test_average_precision': array([0.71614704, 0.69418644, 0.72853081, 0.57573103, 0.87746795]), 'test_f1': array([0.58823529, 0.66666667, 0.66666667, 0.47058824, 0.81818182]), 'test_roc_auc': array([0.86342593, 0.90817901, 0.87037037, 0.85416667, 0.97196262]), 'test_mccf1_score': array([0.68015266, 0.73979954, 0.73979954, 0.58395388, 0.85606018])}, 'lr_ensemble': {'fit_time': array([0.0092411 , 0.00939107, 0.01885104, 0.00931549, 0.00910115]), 'score_time': array([0.00951481, 0.00921893, 0.00923944, 0.00918961, 0.00907516]), 'test_accuracy': array([0.94166667, 0.94166667, 0.94166667, 0.93333333, 0.95833333]), 'test_balanced_accuracy': array([0.74537037, 0.70833333, 0.74537037, 0.7037037 , 0.80769231]), 'test_average_precision': array([0.7282777 , 0.66883176, 0.72306079, 0.57700656, 0.94585799]), 'test_f1': array([0.63157895, 0.58823529, 0.63157895, 0.55555556, 0.76190476]), 'test_roc_auc': array([0.88425926, 0.89583333, 0.89891975, 0.86111111, 0.99137311]), 'test_mccf1_score': array([0.7081941 , 0.68015266, 0.7081941 , 0.64946017, 0.81252969])}}\n",
      "2023-09-25 08:09:44,681 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 08:09:44,684 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 08:09:44,881 - Pipeline - INFO - dirName: 95_5_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 08:09:44,883 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 08:09:44,883 - Pipeline - INFO - Reading data\n",
      "2023-09-25 08:09:45,125 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 08:09:45,132 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 08:11:36,430 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 08:11:36,432 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:11:36,432 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:11:36,433 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:12:20,487 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:12:37,705 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:12:43,040 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:12:46,396 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:13:33,166 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:13:35,990 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.35, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.3, 'colsample_bytree': 0.2, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 08:13:35,991 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:13:38,175 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 08:13:38,177 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:13:38,177 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:13:38,178 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:14:02,420 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:14:13,825 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:14:16,975 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:14:19,570 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:14:50,391 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:14:52,403 - Pipeline - INFO - params: {'max_depth': 6, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 08:14:52,406 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:14:53,995 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 08:14:53,997 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:14:56,156 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:14:56,158 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:14:57,129 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 08:14:57,130 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:14:57,656 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:14:57,657 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:14:58,476 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 08:14:58,477 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:15:14,921 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:15:14,923 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:15:18,014 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 08:15:18,016 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:15:26,901 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:15:26,904 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:15:28,638 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 08:15:28,641 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:15:30,111 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:15:42,683 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 08:15:42,684 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:15:43,718 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:15:52,968 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 08:15:52,970 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 08:15:52,970 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 08:15:52,976 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 08:15:52,977 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:16:15,377 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:16:23,536 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:16:25,993 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:16:27,444 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:16:51,133 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:16:52,589 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 08:16:52,591 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 08:16:53,021 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 08:17:29,858 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 08:17:29,860 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:17:29,860 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:17:29,861 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 08:17:49,523 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 08:17:57,794 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 08:17:59,684 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 08:18:00,870 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 08:18:16,337 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 08:18:17,379 - Pipeline - INFO - params: {'max_depth': 3, 'scale_pos_weight': 0.3, 'n_estimators': 50, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 08:18:17,380 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 08:18:18,584 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 08:18:18,585 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 08:18:19,224 - Pipeline - INFO - Building the model\n",
      "2023-09-25 08:18:19,226 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.10303497, 0.20976686, 0.0990591 , 0.09786892, 0.0987525 ]), 'score_time': array([0.0270164 , 0.02510905, 0.02359128, 0.02374339, 0.02374196]), 'test_accuracy': array([0.975     , 0.97083333, 0.97916667, 0.95833333, 0.97083333]), 'test_balanced_accuracy': array([0.75      , 0.70833333, 0.79166667, 0.58333333, 0.70833333]), 'test_average_precision': array([0.72470169, 0.71272568, 0.73310175, 0.59125275, 0.64353197]), 'test_f1': array([0.66666667, 0.58823529, 0.73684211, 0.28571429, 0.58823529]), 'test_roc_auc': array([0.92361111, 0.95102339, 0.91666667, 0.89692982, 0.90570175]), 'test_mccf1_score': array([0.74123876, 0.68163808, 0.79482411, 0.45212673, 0.68163808])}, 'lr': {'fit_time': array([0.02088284, 0.02090669, 0.0205555 , 0.01952863, 0.02022195]), 'score_time': array([0.01017904, 0.00906181, 0.00898027, 0.00913978, 0.00903869]), 'test_accuracy': array([0.97916667, 0.975     , 0.97916667, 0.96666667, 0.96666667]), 'test_balanced_accuracy': array([0.79166667, 0.82894737, 0.79166667, 0.70614035, 0.74561404]), 'test_average_precision': array([0.69991877, 0.79116151, 0.73543999, 0.46688291, 0.58381627]), 'test_f1': array([0.73684211, 0.72727273, 0.73684211, 0.55555556, 0.6       ]), 'test_roc_auc': array([0.87134503, 0.96454678, 0.8870614 , 0.82711988, 0.86111111]), 'test_mccf1_score': array([0.79482411, 0.78283066, 0.79482411, 0.65173667, 0.68320417])}, 'lgbm': {'fit_time': array([0.22512603, 0.23267317, 0.2218411 , 0.2276268 , 0.21594596]), 'score_time': array([0.01208496, 0.0119524 , 0.01146483, 0.0115118 , 0.01178527]), 'test_accuracy': array([0.975     , 0.97083333, 0.97916667, 0.95833333, 0.9625    ]), 'test_balanced_accuracy': array([0.75      , 0.70833333, 0.79166667, 0.58333333, 0.66447368]), 'test_average_precision': array([0.68116932, 0.62639569, 0.71538942, 0.62074637, 0.6354515 ]), 'test_f1': array([0.66666667, 0.58823529, 0.73684211, 0.28571429, 0.47058824]), 'test_roc_auc': array([0.90533626, 0.87353801, 0.8994883 , 0.91374269, 0.8622076 ]), 'test_mccf1_score': array([0.74123876, 0.68163808, 0.79482411, 0.45212673, 0.58630397])}, 'mlp': {'fit_time': array([1.13495755, 1.17565107, 1.13599586, 1.20079184, 1.11773467]), 'score_time': array([0.01183367, 0.01187015, 0.01156831, 0.01153302, 0.01161146]), 'test_accuracy': array([0.97083333, 0.96666667, 0.96666667, 0.96666667, 0.9625    ]), 'test_balanced_accuracy': array([0.74780702, 0.78508772, 0.70614035, 0.66666667, 0.70394737]), 'test_average_precision': array([0.66923586, 0.72296361, 0.6574069 , 0.51370211, 0.58286089]), 'test_f1': array([0.63157895, 0.63636364, 0.55555556, 0.5       , 0.52631579]), 'test_roc_auc': array([0.88596491, 0.8874269 , 0.90862573, 0.81980994, 0.91812865]), 'test_mccf1_score': array([0.71035276, 0.71019303, 0.65173667, 0.61479335, 0.62583268])}, 'xgb_min': {'fit_time': array([0.07987928, 0.07742119, 0.07702565, 0.07554078, 0.07608533]), 'score_time': array([0.01351976, 0.01238036, 0.0125885 , 0.01222134, 0.01398063]), 'test_accuracy': array([0.975     , 0.96666667, 0.975     , 0.97083333, 0.96666667]), 'test_balanced_accuracy': array([0.75      , 0.66666667, 0.75      , 0.70833333, 0.70614035]), 'test_average_precision': array([0.63289821, 0.60545596, 0.62672892, 0.62703134, 0.58639479]), 'test_f1': array([0.66666667, 0.5       , 0.66666667, 0.58823529, 0.55555556]), 'test_roc_auc': array([0.88304094, 0.82931287, 0.86622807, 0.87573099, 0.81615497]), 'test_mccf1_score': array([0.74123876, 0.61479335, 0.74123876, 0.68163808, 0.65173667])}, 'lr_min': {'fit_time': array([0.0034132 , 0.00340343, 0.00520325, 0.00370169, 0.00327921]), 'score_time': array([0.0091269 , 0.00818992, 0.00809813, 0.00810599, 0.00802112]), 'test_accuracy': array([0.975 , 0.975 , 0.975 , 0.9625, 0.9625]), 'test_balanced_accuracy': array([0.75      , 0.75      , 0.78947368, 0.625     , 0.70394737]), 'test_average_precision': array([0.73494119, 0.69083959, 0.68907405, 0.51088614, 0.56647197]), 'test_f1': array([0.66666667, 0.66666667, 0.7       , 0.4       , 0.52631579]), 'test_roc_auc': array([0.84722222, 0.94480994, 0.86549708, 0.92872807, 0.83040936]), 'test_mccf1_score': array([0.74123876, 0.74123876, 0.76328964, 0.53906651, 0.62583268])}, 'lgbm_min': {'fit_time': array([0.0788126 , 0.08022547, 0.07180548, 0.07526827, 0.17719555]), 'score_time': array([0.01008677, 0.00930738, 0.00936818, 0.01070738, 0.0105679 ]), 'test_accuracy': array([0.9625    , 0.96666667, 0.97916667, 0.9625    , 0.97083333]), 'test_balanced_accuracy': array([0.66447368, 0.70614035, 0.79166667, 0.625     , 0.74780702]), 'test_average_precision': array([0.57527768, 0.60298624, 0.67810315, 0.63020833, 0.59017211]), 'test_f1': array([0.47058824, 0.55555556, 0.73684211, 0.4       , 0.63157895]), 'test_roc_auc': array([0.85599415, 0.79385965, 0.87171053, 0.92105263, 0.81615497]), 'test_mccf1_score': array([0.58630397, 0.65173667, 0.79482411, 0.53906651, 0.71035276])}, 'mlp_min': {'fit_time': array([0.86578631, 0.86062169, 0.84177327, 0.86330009, 0.80554128]), 'score_time': array([0.00951076, 0.00973868, 0.00969338, 0.00957274, 0.00934744]), 'test_accuracy': array([0.96666667, 0.9625    , 0.9625    , 0.9625    , 0.9625    ]), 'test_balanced_accuracy': array([0.66666667, 0.74342105, 0.74342105, 0.70394737, 0.78289474]), 'test_average_precision': array([0.486692  , 0.64297042, 0.547534  , 0.41308428, 0.49894704]), 'test_f1': array([0.5       , 0.57142857, 0.57142857, 0.52631579, 0.60869565]), 'test_roc_auc': array([0.81688596, 0.89181287, 0.83881579, 0.65679825, 0.86330409]), 'test_mccf1_score': array([0.61479335, 0.65911495, 0.65911495, 0.62583268, 0.68757832])}, 'xgb_ensemble': {'fit_time': array([0.03747082, 0.03398585, 0.03405833, 0.03363252, 0.03442979]), 'score_time': array([0.01668167, 0.01533198, 0.01745462, 0.01632595, 0.01610684]), 'test_accuracy': array([0.99166667, 0.98333333, 0.96666667, 0.975     , 0.99166667]), 'test_balanced_accuracy': array([0.875, 0.75 , 0.6  , 0.7  , 0.9  ]), 'test_average_precision': array([0.77564103, 0.68703704, 0.5225    , 0.75263158, 0.89090909]), 'test_f1': array([0.85714286, 0.66666667, 0.33333333, 0.57142857, 0.88888889]), 'test_roc_auc': array([0.92456897, 0.94612069, 0.96      , 0.96869565, 0.98956522]), 'test_mccf1_score': array([0.8878676 , 0.74169002, 0.48865511, 0.66913065, 0.91242214])}, 'lr_ensemble': {'fit_time': array([0.01897216, 0.01004744, 0.00955653, 0.00992727, 0.01065397]), 'score_time': array([0.01291466, 0.00933695, 0.00920963, 0.0091083 , 0.009166  ]), 'test_accuracy': array([0.99166667, 0.98333333, 0.96666667, 0.98333333, 0.975     ]), 'test_balanced_accuracy': array([0.875     , 0.75      , 0.6       , 0.8       , 0.79565217]), 'test_average_precision': array([0.78571429, 0.62084149, 0.58611111, 0.94285714, 0.77090909]), 'test_f1': array([0.85714286, 0.66666667, 0.33333333, 0.75      , 0.66666667]), 'test_roc_auc': array([0.94827586, 0.84267241, 0.9373913 , 0.99652174, 0.97913043]), 'test_mccf1_score': array([0.8878676 , 0.74169002, 0.48865511, 0.80511276, 0.73513151])}}\n",
      "2023-09-25 08:18:20,122 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 08:18:20,124 - Pipeline - INFO - Completed !!!\n"
     ]
    }
   ],
   "source": [
    "totalSamples = 1200\n",
    "for proportion in [65, 70, 75, 80, 85, 90, 95]:\n",
    "    negativeSize = int(totalSamples * proportion / 100)\n",
    "    positiveSize = int(totalSamples - (totalSamples * proportion / 100))\n",
    "    sampledDataMatrix = pd.concat([dataMatrixPositive.sample(n=positiveSize), dataMatrixNegative.sample(n=negativeSize)]).sample(frac=1).reset_index(drop=True)\n",
    "    sampledDataMatrix.to_csv(dataDirName + 'data_matrix.csv', index=False)\n",
    "    pm.runPredictionsForAllTargets(\n",
    "        label=str(proportion) + '_' + str(100 - proportion) + '_samples',\n",
    "        dirPath = dataDirName,\n",
    "        vitalsBefore = 0,\n",
    "        vitalsAfter = 72,\n",
    "        labsBefore = 0,\n",
    "        labsAfter = 72,\n",
    "        targetList = [7],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the data matrix file from working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.system(\n",
    "    '''rm ''' + dataDirName + '''data_matrix.csv'''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
