{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(\"Pipeline\")\n",
    "log.setLevel(logging.INFO)\n",
    "format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(format)\n",
    "log.addHandler(ch)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import predict_mortality as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directory\n",
    "\n",
    "A top level directory to store all the data for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirName = '/home/yram0006/phd/chapter_2/workspace/mortality_data/imbalance_experiment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity_WHITE</th>\n",
       "      <th>ethnicity_BLACK</th>\n",
       "      <th>ethnicity_UNKNOWN</th>\n",
       "      <th>ethnicity_OTHER</th>\n",
       "      <th>ethnicity_HISPANIC</th>\n",
       "      <th>ethnicity_ASIAN</th>\n",
       "      <th>ethnicity_UNABLE_TO_OBTAIN</th>\n",
       "      <th>ethnicity_AMERICAN_INDIAN</th>\n",
       "      <th>anchor_time</th>\n",
       "      <th>death_datetime</th>\n",
       "      <th>heartrate_min</th>\n",
       "      <th>sysbp_min</th>\n",
       "      <th>diabp_min</th>\n",
       "      <th>meanbp_min</th>\n",
       "      <th>resprate_min</th>\n",
       "      <th>tempc_min</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>gcseye_min</th>\n",
       "      <th>gcsverbal_min</th>\n",
       "      <th>gcsmotor_min</th>\n",
       "      <th>heartrate_max</th>\n",
       "      <th>sysbp_max</th>\n",
       "      <th>diabp_max</th>\n",
       "      <th>meanbp_max</th>\n",
       "      <th>resprate_max</th>\n",
       "      <th>tempc_max</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>gcseye_max</th>\n",
       "      <th>gcsverbal_max</th>\n",
       "      <th>gcsmotor_max</th>\n",
       "      <th>heartrate_avg</th>\n",
       "      <th>sysbp_avg</th>\n",
       "      <th>diabp_avg</th>\n",
       "      <th>meanbp_avg</th>\n",
       "      <th>resprate_avg</th>\n",
       "      <th>tempc_avg</th>\n",
       "      <th>spo2_avg</th>\n",
       "      <th>gcseye_avg</th>\n",
       "      <th>gcsverbal_avg</th>\n",
       "      <th>gcsmotor_avg</th>\n",
       "      <th>heartrate_stddev</th>\n",
       "      <th>sysbp_stddev</th>\n",
       "      <th>diabp_stddev</th>\n",
       "      <th>meanbp_stddev</th>\n",
       "      <th>resprate_stddev</th>\n",
       "      <th>tempc_stddev</th>\n",
       "      <th>spo2_stddev</th>\n",
       "      <th>gcseye_stddev</th>\n",
       "      <th>gcsverbal_stddev</th>\n",
       "      <th>gcsmotor_stddev</th>\n",
       "      <th>heartrate_first</th>\n",
       "      <th>sysbp_first</th>\n",
       "      <th>diabp_first</th>\n",
       "      <th>meanbp_first</th>\n",
       "      <th>resprate_first</th>\n",
       "      <th>tempc_first</th>\n",
       "      <th>spo2_first</th>\n",
       "      <th>gcseye_first</th>\n",
       "      <th>gcsverbal_first</th>\n",
       "      <th>gcsmotor_first</th>\n",
       "      <th>heartrate_last</th>\n",
       "      <th>sysbp_last</th>\n",
       "      <th>diabp_last</th>\n",
       "      <th>meanbp_last</th>\n",
       "      <th>resprate_last</th>\n",
       "      <th>tempc_last</th>\n",
       "      <th>spo2_last</th>\n",
       "      <th>gcseye_last</th>\n",
       "      <th>gcsverbal_last</th>\n",
       "      <th>gcsmotor_last</th>\n",
       "      <th>chloride_serum_min</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>sodium_serum_min</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>platelet_count_min</th>\n",
       "      <th>urea_nitrogen_min</th>\n",
       "      <th>glucose_serum_min</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>potassium_serum_min</th>\n",
       "      <th>anion_gap_min</th>\n",
       "      <th>leukocytes_blood_manual_min</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>chloride_serum_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>sodium_serum_max</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelet_count_max</th>\n",
       "      <th>urea_nitrogen_max</th>\n",
       "      <th>glucose_serum_max</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>potassium_serum_max</th>\n",
       "      <th>anion_gap_max</th>\n",
       "      <th>leukocytes_blood_manual_max</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>chloride_serum_avg</th>\n",
       "      <th>creatinine_avg</th>\n",
       "      <th>sodium_serum_avg</th>\n",
       "      <th>hemoglobin_avg</th>\n",
       "      <th>platelet_count_avg</th>\n",
       "      <th>urea_nitrogen_avg</th>\n",
       "      <th>glucose_serum_avg</th>\n",
       "      <th>bicarbonate_avg</th>\n",
       "      <th>potassium_serum_avg</th>\n",
       "      <th>anion_gap_avg</th>\n",
       "      <th>leukocytes_blood_manual_avg</th>\n",
       "      <th>hematocrit_avg</th>\n",
       "      <th>chloride_serum_stddev</th>\n",
       "      <th>creatinine_stddev</th>\n",
       "      <th>sodium_serum_stddev</th>\n",
       "      <th>hemoglobin_stddev</th>\n",
       "      <th>glucose_serum_stddev</th>\n",
       "      <th>bicarbonate_stddev</th>\n",
       "      <th>potassium_serum_stddev</th>\n",
       "      <th>chloride_serum_first</th>\n",
       "      <th>creatinine_first</th>\n",
       "      <th>sodium_serum_first</th>\n",
       "      <th>hemoglobin_first</th>\n",
       "      <th>platelet_count_first</th>\n",
       "      <th>urea_nitrogen_first</th>\n",
       "      <th>glucose_serum_first</th>\n",
       "      <th>bicarbonate_first</th>\n",
       "      <th>potassium_serum_first</th>\n",
       "      <th>anion_gap_first</th>\n",
       "      <th>leukocytes_blood_manual_first</th>\n",
       "      <th>hematocrit_first</th>\n",
       "      <th>chloride_serum_last</th>\n",
       "      <th>creatinine_last</th>\n",
       "      <th>sodium_serum_last</th>\n",
       "      <th>hemoglobin_last</th>\n",
       "      <th>platelet_count_last</th>\n",
       "      <th>urea_nitrogen_last</th>\n",
       "      <th>glucose_serum_last</th>\n",
       "      <th>bicarbonate_last</th>\n",
       "      <th>potassium_serum_last</th>\n",
       "      <th>anion_gap_last</th>\n",
       "      <th>leukocytes_blood_manual_last</th>\n",
       "      <th>hematocrit_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2144679073</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2190-01-30 19:22:00</td>\n",
       "      <td>2194-04-23 19:27:00</td>\n",
       "      <td>-0.272794</td>\n",
       "      <td>1.217771</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>0.861968</td>\n",
       "      <td>0.878048</td>\n",
       "      <td>0.189353</td>\n",
       "      <td>0.317249</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.030099</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>0.069606</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>-0.309282</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.671766</td>\n",
       "      <td>0.838925</td>\n",
       "      <td>0.734657</td>\n",
       "      <td>0.755136</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>0.595497</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.047481</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>-0.025099</td>\n",
       "      <td>-0.700168</td>\n",
       "      <td>-0.113932</td>\n",
       "      <td>-0.042762</td>\n",
       "      <td>-0.054623</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-1.241070</td>\n",
       "      <td>-0.100946</td>\n",
       "      <td>-0.093761</td>\n",
       "      <td>-0.277365</td>\n",
       "      <td>-0.176019</td>\n",
       "      <td>-0.090217</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.521863</td>\n",
       "      <td>1.715295</td>\n",
       "      <td>0.616779</td>\n",
       "      <td>0.846636</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>1.093242</td>\n",
       "      <td>-0.663478</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>0.285937</td>\n",
       "      <td>0.076969</td>\n",
       "      <td>-0.734973</td>\n",
       "      <td>-0.012647</td>\n",
       "      <td>0.669296</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.915664</td>\n",
       "      <td>-0.348052</td>\n",
       "      <td>0.099873</td>\n",
       "      <td>0.214809</td>\n",
       "      <td>-0.011713</td>\n",
       "      <td>-0.309154</td>\n",
       "      <td>-0.534404</td>\n",
       "      <td>0.297850</td>\n",
       "      <td>-0.994593</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-1.025656</td>\n",
       "      <td>-0.767333</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>-0.395681</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>-0.014171</td>\n",
       "      <td>-0.015245</td>\n",
       "      <td>-0.012701</td>\n",
       "      <td>0.347919</td>\n",
       "      <td>-0.948893</td>\n",
       "      <td>-0.020354</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>-0.013272</td>\n",
       "      <td>-1.114836</td>\n",
       "      <td>-0.162093</td>\n",
       "      <td>-0.233373</td>\n",
       "      <td>-0.012429</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.590509</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>-0.030961</td>\n",
       "      <td>-0.601701</td>\n",
       "      <td>-1.056430</td>\n",
       "      <td>0.743687</td>\n",
       "      <td>-0.694348</td>\n",
       "      <td>-0.191987</td>\n",
       "      <td>-0.406075</td>\n",
       "      <td>0.116251</td>\n",
       "      <td>-0.789275</td>\n",
       "      <td>-0.022292</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>-0.788282</td>\n",
       "      <td>-1.346000</td>\n",
       "      <td>-0.054095</td>\n",
       "      <td>-0.572535</td>\n",
       "      <td>0.656699</td>\n",
       "      <td>-0.695650</td>\n",
       "      <td>-0.087780</td>\n",
       "      <td>0.157334</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.863655</td>\n",
       "      <td>-0.015096</td>\n",
       "      <td>0.214490</td>\n",
       "      <td>-0.408989</td>\n",
       "      <td>-0.979015</td>\n",
       "      <td>-0.516496</td>\n",
       "      <td>0.100735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2142084288</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2161-07-10 08:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073643</td>\n",
       "      <td>-0.427373</td>\n",
       "      <td>0.222451</td>\n",
       "      <td>-1.935422</td>\n",
       "      <td>1.165394</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>-0.256040</td>\n",
       "      <td>1.199315</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>-0.026310</td>\n",
       "      <td>-0.053989</td>\n",
       "      <td>-0.057963</td>\n",
       "      <td>-0.040074</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.134094</td>\n",
       "      <td>-0.066312</td>\n",
       "      <td>0.750897</td>\n",
       "      <td>0.395390</td>\n",
       "      <td>0.617088</td>\n",
       "      <td>0.086249</td>\n",
       "      <td>-0.167731</td>\n",
       "      <td>0.860623</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>-0.347862</td>\n",
       "      <td>-0.101546</td>\n",
       "      <td>-0.018473</td>\n",
       "      <td>-1.069636</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.299599</td>\n",
       "      <td>0.244989</td>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.378146</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.305525</td>\n",
       "      <td>-0.056425</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.313804</td>\n",
       "      <td>0.682207</td>\n",
       "      <td>1.280328</td>\n",
       "      <td>1.020767</td>\n",
       "      <td>1.692185</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>0.793315</td>\n",
       "      <td>-0.435926</td>\n",
       "      <td>0.507737</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.477509</td>\n",
       "      <td>-0.012129</td>\n",
       "      <td>0.066001</td>\n",
       "      <td>-0.301095</td>\n",
       "      <td>-0.563366</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>0.502304</td>\n",
       "      <td>0.510556</td>\n",
       "      <td>-0.011635</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.320511</td>\n",
       "      <td>0.179330</td>\n",
       "      <td>-0.090891</td>\n",
       "      <td>-0.021989</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.292875</td>\n",
       "      <td>-0.091176</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.390295</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>0.012011</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>-0.067964</td>\n",
       "      <td>-0.387671</td>\n",
       "      <td>-0.018131</td>\n",
       "      <td>-0.019468</td>\n",
       "      <td>-0.011258</td>\n",
       "      <td>-0.206481</td>\n",
       "      <td>-0.083122</td>\n",
       "      <td>0.450207</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.011498</td>\n",
       "      <td>-0.343805</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.029291</td>\n",
       "      <td>-0.226259</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.474016</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>0.614182</td>\n",
       "      <td>0.464202</td>\n",
       "      <td>-0.020737</td>\n",
       "      <td>-0.276849</td>\n",
       "      <td>-0.022242</td>\n",
       "      <td>0.012654</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>-0.216607</td>\n",
       "      <td>0.465424</td>\n",
       "      <td>0.183603</td>\n",
       "      <td>-0.508245</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>0.430555</td>\n",
       "      <td>0.701722</td>\n",
       "      <td>-0.447977</td>\n",
       "      <td>-0.013025</td>\n",
       "      <td>-0.196256</td>\n",
       "      <td>-0.900551</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.217026</td>\n",
       "      <td>0.473387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2133944014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141-03-25 16:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.173219</td>\n",
       "      <td>0.630220</td>\n",
       "      <td>0.572854</td>\n",
       "      <td>0.478013</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>0.147108</td>\n",
       "      <td>-0.419837</td>\n",
       "      <td>-0.374217</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.020620</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>-0.012100</td>\n",
       "      <td>-0.044139</td>\n",
       "      <td>-0.215037</td>\n",
       "      <td>-0.080454</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.322070</td>\n",
       "      <td>0.427622</td>\n",
       "      <td>0.130176</td>\n",
       "      <td>0.083759</td>\n",
       "      <td>-0.701402</td>\n",
       "      <td>-0.062385</td>\n",
       "      <td>-0.402458</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>0.394775</td>\n",
       "      <td>0.594702</td>\n",
       "      <td>-0.024181</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.048238</td>\n",
       "      <td>-0.064594</td>\n",
       "      <td>-0.313192</td>\n",
       "      <td>-0.119714</td>\n",
       "      <td>-0.001438</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>1.970708</td>\n",
       "      <td>-0.371864</td>\n",
       "      <td>-0.770334</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-0.327789</td>\n",
       "      <td>-0.803119</td>\n",
       "      <td>0.165851</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>-0.907586</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>-0.230580</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>-0.227737</td>\n",
       "      <td>-0.198151</td>\n",
       "      <td>-0.315867</td>\n",
       "      <td>-0.055249</td>\n",
       "      <td>-0.217421</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-2.655837</td>\n",
       "      <td>-0.663478</td>\n",
       "      <td>-1.213852</td>\n",
       "      <td>1.694168</td>\n",
       "      <td>0.872452</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>2.680281</td>\n",
       "      <td>-1.717605</td>\n",
       "      <td>-0.397756</td>\n",
       "      <td>1.230034</td>\n",
       "      <td>1.542830</td>\n",
       "      <td>-2.151170</td>\n",
       "      <td>-0.011679</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>1.507893</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>-0.444643</td>\n",
       "      <td>-0.017503</td>\n",
       "      <td>0.094229</td>\n",
       "      <td>-0.366390</td>\n",
       "      <td>-0.828988</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.916153</td>\n",
       "      <td>-0.031538</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.072093</td>\n",
       "      <td>-0.010550</td>\n",
       "      <td>0.218245</td>\n",
       "      <td>-0.646831</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.170743</td>\n",
       "      <td>-0.014433</td>\n",
       "      <td>-0.872370</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>1.647657</td>\n",
       "      <td>-0.011455</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.027636</td>\n",
       "      <td>-0.299876</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>-2.627203</td>\n",
       "      <td>-0.463035</td>\n",
       "      <td>-1.481858</td>\n",
       "      <td>1.160423</td>\n",
       "      <td>0.739696</td>\n",
       "      <td>-0.305407</td>\n",
       "      <td>-0.020149</td>\n",
       "      <td>2.156819</td>\n",
       "      <td>-1.768456</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>0.737925</td>\n",
       "      <td>1.165595</td>\n",
       "      <td>-2.339573</td>\n",
       "      <td>-0.695650</td>\n",
       "      <td>-1.690266</td>\n",
       "      <td>1.523437</td>\n",
       "      <td>0.575731</td>\n",
       "      <td>-0.612072</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>2.062846</td>\n",
       "      <td>-0.408989</td>\n",
       "      <td>-0.658492</td>\n",
       "      <td>0.160877</td>\n",
       "      <td>1.557531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2133227983</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2120-09-22 10:15:00</td>\n",
       "      <td>2121-08-28 15:15:00</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>-1.073680</td>\n",
       "      <td>0.485253</td>\n",
       "      <td>-1.441765</td>\n",
       "      <td>0.447029</td>\n",
       "      <td>0.133026</td>\n",
       "      <td>0.235350</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>-0.389695</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.017735</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>0.161941</td>\n",
       "      <td>-0.003364</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.203561</td>\n",
       "      <td>-0.427533</td>\n",
       "      <td>0.646238</td>\n",
       "      <td>0.240893</td>\n",
       "      <td>-0.310939</td>\n",
       "      <td>-0.113208</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>0.754573</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>0.281090</td>\n",
       "      <td>-0.021139</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>-0.066404</td>\n",
       "      <td>-0.042251</td>\n",
       "      <td>-0.338743</td>\n",
       "      <td>0.659022</td>\n",
       "      <td>-0.068008</td>\n",
       "      <td>0.312356</td>\n",
       "      <td>0.763893</td>\n",
       "      <td>0.476888</td>\n",
       "      <td>1.941287</td>\n",
       "      <td>0.952761</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>-0.188968</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>-0.024020</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.041730</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>-0.730035</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.256426</td>\n",
       "      <td>-0.891030</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>-0.166709</td>\n",
       "      <td>0.670751</td>\n",
       "      <td>-0.731453</td>\n",
       "      <td>-0.011784</td>\n",
       "      <td>1.272592</td>\n",
       "      <td>-2.071733</td>\n",
       "      <td>-0.638644</td>\n",
       "      <td>0.063069</td>\n",
       "      <td>-0.119478</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.061238</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>1.143237</td>\n",
       "      <td>-0.712930</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>-0.514545</td>\n",
       "      <td>-0.017100</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>-0.014468</td>\n",
       "      <td>-0.014352</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>-0.012580</td>\n",
       "      <td>0.950606</td>\n",
       "      <td>-0.886384</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>0.068637</td>\n",
       "      <td>-0.013154</td>\n",
       "      <td>-0.659500</td>\n",
       "      <td>-0.175868</td>\n",
       "      <td>0.104515</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>-0.013936</td>\n",
       "      <td>-0.011738</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>-0.282218</td>\n",
       "      <td>2.463369</td>\n",
       "      <td>-0.469833</td>\n",
       "      <td>-0.867833</td>\n",
       "      <td>-0.191987</td>\n",
       "      <td>0.159605</td>\n",
       "      <td>0.750668</td>\n",
       "      <td>-0.891840</td>\n",
       "      <td>-0.022641</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>-0.897190</td>\n",
       "      <td>-0.373601</td>\n",
       "      <td>0.148029</td>\n",
       "      <td>0.173951</td>\n",
       "      <td>0.183603</td>\n",
       "      <td>-0.883055</td>\n",
       "      <td>0.513153</td>\n",
       "      <td>-0.498395</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>-0.749180</td>\n",
       "      <td>-0.011385</td>\n",
       "      <td>1.446727</td>\n",
       "      <td>-0.900551</td>\n",
       "      <td>-1.200746</td>\n",
       "      <td>-0.014856</td>\n",
       "      <td>-0.475707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2132499549</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2205-11-16 13:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>-0.662394</td>\n",
       "      <td>-0.127953</td>\n",
       "      <td>0.148908</td>\n",
       "      <td>0.878048</td>\n",
       "      <td>0.161190</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.007843</td>\n",
       "      <td>-0.019251</td>\n",
       "      <td>-0.072492</td>\n",
       "      <td>-0.099956</td>\n",
       "      <td>-0.183622</td>\n",
       "      <td>-0.098809</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.038396</td>\n",
       "      <td>-0.330845</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>-0.222650</td>\n",
       "      <td>-0.361032</td>\n",
       "      <td>-0.180333</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.507121</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>-0.032613</td>\n",
       "      <td>-0.041233</td>\n",
       "      <td>-0.560680</td>\n",
       "      <td>-0.134095</td>\n",
       "      <td>-0.023838</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.017158</td>\n",
       "      <td>-0.187430</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.325661</td>\n",
       "      <td>-0.113496</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>0.726492</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>-0.107092</td>\n",
       "      <td>-0.067553</td>\n",
       "      <td>1.118455</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>0.123383</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>1.393168</td>\n",
       "      <td>0.322582</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>-0.217003</td>\n",
       "      <td>0.273945</td>\n",
       "      <td>0.984810</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.939492</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>0.062941</td>\n",
       "      <td>-0.121743</td>\n",
       "      <td>-0.197396</td>\n",
       "      <td>0.362682</td>\n",
       "      <td>-0.011601</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.156544</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>-0.025130</td>\n",
       "      <td>-0.086899</td>\n",
       "      <td>-0.696023</td>\n",
       "      <td>1.220035</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.164904</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>-0.023033</td>\n",
       "      <td>-0.012630</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.343322</td>\n",
       "      <td>-0.021086</td>\n",
       "      <td>-0.108780</td>\n",
       "      <td>-0.012621</td>\n",
       "      <td>0.272497</td>\n",
       "      <td>0.315003</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.012592</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>-0.698913</td>\n",
       "      <td>-0.011672</td>\n",
       "      <td>-0.031460</td>\n",
       "      <td>-1.112750</td>\n",
       "      <td>-0.219378</td>\n",
       "      <td>1.013358</td>\n",
       "      <td>0.057419</td>\n",
       "      <td>0.130480</td>\n",
       "      <td>0.203119</td>\n",
       "      <td>-0.207427</td>\n",
       "      <td>0.379972</td>\n",
       "      <td>-0.023489</td>\n",
       "      <td>-1.351814</td>\n",
       "      <td>-0.243741</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>-0.110297</td>\n",
       "      <td>0.278954</td>\n",
       "      <td>0.814397</td>\n",
       "      <td>0.116439</td>\n",
       "      <td>-0.488402</td>\n",
       "      <td>-0.553039</td>\n",
       "      <td>0.463571</td>\n",
       "      <td>0.272386</td>\n",
       "      <td>-0.015010</td>\n",
       "      <td>-1.428493</td>\n",
       "      <td>-0.736697</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.490582</td>\n",
       "      <td>-0.508395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2142664100</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2180-08-11 04:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.922114</td>\n",
       "      <td>0.042668</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>0.478013</td>\n",
       "      <td>0.590702</td>\n",
       "      <td>0.147108</td>\n",
       "      <td>-0.911228</td>\n",
       "      <td>1.199315</td>\n",
       "      <td>0.696753</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>-0.021719</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.787906</td>\n",
       "      <td>0.176275</td>\n",
       "      <td>1.271708</td>\n",
       "      <td>0.677604</td>\n",
       "      <td>1.480574</td>\n",
       "      <td>-0.004342</td>\n",
       "      <td>-0.016273</td>\n",
       "      <td>0.860623</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.050465</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>-0.074307</td>\n",
       "      <td>-0.069785</td>\n",
       "      <td>0.021901</td>\n",
       "      <td>-1.069636</td>\n",
       "      <td>-0.299347</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>1.159680</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.144009</td>\n",
       "      <td>0.428570</td>\n",
       "      <td>1.454441</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>0.518433</td>\n",
       "      <td>1.198751</td>\n",
       "      <td>1.400973</td>\n",
       "      <td>1.020767</td>\n",
       "      <td>0.257862</td>\n",
       "      <td>-0.075527</td>\n",
       "      <td>-0.103820</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.406390</td>\n",
       "      <td>-0.435926</td>\n",
       "      <td>-0.525217</td>\n",
       "      <td>-0.367884</td>\n",
       "      <td>-0.880643</td>\n",
       "      <td>-0.593669</td>\n",
       "      <td>-0.010576</td>\n",
       "      <td>0.468198</td>\n",
       "      <td>-0.478159</td>\n",
       "      <td>-0.512178</td>\n",
       "      <td>-0.135230</td>\n",
       "      <td>-0.414490</td>\n",
       "      <td>-0.672433</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>-0.296928</td>\n",
       "      <td>-0.630374</td>\n",
       "      <td>-0.760493</td>\n",
       "      <td>-0.020095</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.696023</td>\n",
       "      <td>-0.391233</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.288525</td>\n",
       "      <td>-0.016472</td>\n",
       "      <td>-0.013880</td>\n",
       "      <td>-0.040554</td>\n",
       "      <td>-0.013052</td>\n",
       "      <td>-0.742526</td>\n",
       "      <td>-0.717218</td>\n",
       "      <td>-0.016265</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-0.012700</td>\n",
       "      <td>-0.209341</td>\n",
       "      <td>-0.086127</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>0.060371</td>\n",
       "      <td>-0.011835</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>0.316081</td>\n",
       "      <td>-0.427042</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>-0.405207</td>\n",
       "      <td>0.130480</td>\n",
       "      <td>-0.101478</td>\n",
       "      <td>-0.497942</td>\n",
       "      <td>-0.758304</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>-0.570466</td>\n",
       "      <td>-0.026771</td>\n",
       "      <td>-0.490395</td>\n",
       "      <td>-0.095195</td>\n",
       "      <td>-1.077985</td>\n",
       "      <td>-0.383308</td>\n",
       "      <td>-1.289645</td>\n",
       "      <td>-0.389107</td>\n",
       "      <td>-1.005746</td>\n",
       "      <td>-0.521972</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>0.214490</td>\n",
       "      <td>0.082574</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.718153</td>\n",
       "      <td>-0.414065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2144053271</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2139-06-14 18:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.770673</td>\n",
       "      <td>-0.309863</td>\n",
       "      <td>-1.266765</td>\n",
       "      <td>0.203759</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>-0.289426</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>-1.160983</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>-1.403987</td>\n",
       "      <td>-0.006195</td>\n",
       "      <td>-0.017626</td>\n",
       "      <td>-0.097359</td>\n",
       "      <td>-0.086823</td>\n",
       "      <td>-0.152207</td>\n",
       "      <td>-0.095138</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>-2.337273</td>\n",
       "      <td>-1.693958</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.392198</td>\n",
       "      <td>-0.085976</td>\n",
       "      <td>-0.199819</td>\n",
       "      <td>-0.157516</td>\n",
       "      <td>-0.607566</td>\n",
       "      <td>-0.704260</td>\n",
       "      <td>0.203160</td>\n",
       "      <td>-2.261975</td>\n",
       "      <td>-1.329666</td>\n",
       "      <td>-0.781980</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>-0.021687</td>\n",
       "      <td>-0.074604</td>\n",
       "      <td>0.230779</td>\n",
       "      <td>-0.051405</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>-0.524861</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>2.324226</td>\n",
       "      <td>0.171136</td>\n",
       "      <td>0.677409</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-1.033723</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.119293</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>-1.725934</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>-2.087210</td>\n",
       "      <td>-0.272192</td>\n",
       "      <td>-0.907158</td>\n",
       "      <td>-0.408705</td>\n",
       "      <td>0.672505</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>-2.086777</td>\n",
       "      <td>-1.272249</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-0.406390</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>-0.525217</td>\n",
       "      <td>0.436819</td>\n",
       "      <td>-0.264909</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>-0.015064</td>\n",
       "      <td>-0.738393</td>\n",
       "      <td>-0.478159</td>\n",
       "      <td>0.526649</td>\n",
       "      <td>0.214830</td>\n",
       "      <td>0.322694</td>\n",
       "      <td>-0.672433</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>-0.679547</td>\n",
       "      <td>-0.154442</td>\n",
       "      <td>0.201483</td>\n",
       "      <td>0.676810</td>\n",
       "      <td>-0.023983</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>-0.586146</td>\n",
       "      <td>-0.074734</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.188810</td>\n",
       "      <td>-0.017731</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>-0.053070</td>\n",
       "      <td>-0.012299</td>\n",
       "      <td>0.139068</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>-0.020678</td>\n",
       "      <td>-0.006364</td>\n",
       "      <td>-0.012291</td>\n",
       "      <td>0.406005</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>0.265825</td>\n",
       "      <td>-0.011921</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.108793</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>3.064577</td>\n",
       "      <td>-0.380575</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>1.618781</td>\n",
       "      <td>-0.836923</td>\n",
       "      <td>-0.188505</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>1.442229</td>\n",
       "      <td>-0.022292</td>\n",
       "      <td>-0.572118</td>\n",
       "      <td>-0.134833</td>\n",
       "      <td>-0.099116</td>\n",
       "      <td>0.159315</td>\n",
       "      <td>-0.189184</td>\n",
       "      <td>-1.077985</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>-0.488402</td>\n",
       "      <td>0.594487</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>-0.013456</td>\n",
       "      <td>1.446727</td>\n",
       "      <td>-0.081281</td>\n",
       "      <td>-0.438956</td>\n",
       "      <td>-0.033435</td>\n",
       "      <td>0.564168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2144497079</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2150-04-26 14:47:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.019612</td>\n",
       "      <td>0.512710</td>\n",
       "      <td>-0.565958</td>\n",
       "      <td>0.094057</td>\n",
       "      <td>0.590702</td>\n",
       "      <td>0.076699</td>\n",
       "      <td>-0.256040</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>1.239978</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>-0.024741</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.514026</td>\n",
       "      <td>-0.057963</td>\n",
       "      <td>-0.091467</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>-0.518790</td>\n",
       "      <td>0.179749</td>\n",
       "      <td>-0.911257</td>\n",
       "      <td>0.063392</td>\n",
       "      <td>-0.454063</td>\n",
       "      <td>-0.207270</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0.779046</td>\n",
       "      <td>1.041441</td>\n",
       "      <td>0.658405</td>\n",
       "      <td>-0.022060</td>\n",
       "      <td>-0.031759</td>\n",
       "      <td>-0.065296</td>\n",
       "      <td>0.342646</td>\n",
       "      <td>-0.375325</td>\n",
       "      <td>-0.118352</td>\n",
       "      <td>-0.037418</td>\n",
       "      <td>-0.441552</td>\n",
       "      <td>-0.696918</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-2.229614</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>-0.272089</td>\n",
       "      <td>-0.781604</td>\n",
       "      <td>-0.552279</td>\n",
       "      <td>-0.113496</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-0.022521</td>\n",
       "      <td>-0.390614</td>\n",
       "      <td>-1.011931</td>\n",
       "      <td>-0.546413</td>\n",
       "      <td>-0.459299</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-1.606095</td>\n",
       "      <td>1.232790</td>\n",
       "      <td>-1.730329</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>-0.683765</td>\n",
       "      <td>0.512624</td>\n",
       "      <td>-0.011180</td>\n",
       "      <td>-1.341689</td>\n",
       "      <td>-0.301095</td>\n",
       "      <td>1.896696</td>\n",
       "      <td>-0.401998</td>\n",
       "      <td>0.279656</td>\n",
       "      <td>-1.855423</td>\n",
       "      <td>-0.011238</td>\n",
       "      <td>-1.420333</td>\n",
       "      <td>1.127931</td>\n",
       "      <td>-0.764876</td>\n",
       "      <td>2.620960</td>\n",
       "      <td>-0.017553</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>1.611406</td>\n",
       "      <td>1.663956</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>1.050925</td>\n",
       "      <td>-0.026598</td>\n",
       "      <td>-0.011229</td>\n",
       "      <td>-0.112234</td>\n",
       "      <td>-0.011756</td>\n",
       "      <td>-0.688077</td>\n",
       "      <td>2.200226</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.050189</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>1.899387</td>\n",
       "      <td>-0.263500</td>\n",
       "      <td>0.504531</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>0.503888</td>\n",
       "      <td>-0.011802</td>\n",
       "      <td>-0.026767</td>\n",
       "      <td>1.913836</td>\n",
       "      <td>1.704332</td>\n",
       "      <td>-1.683354</td>\n",
       "      <td>1.792265</td>\n",
       "      <td>-1.643092</td>\n",
       "      <td>1.203937</td>\n",
       "      <td>-0.637141</td>\n",
       "      <td>2.378993</td>\n",
       "      <td>-0.018703</td>\n",
       "      <td>-0.961966</td>\n",
       "      <td>2.043330</td>\n",
       "      <td>2.101017</td>\n",
       "      <td>-0.185685</td>\n",
       "      <td>1.126822</td>\n",
       "      <td>-1.866477</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>-1.289645</td>\n",
       "      <td>0.867708</td>\n",
       "      <td>-0.538783</td>\n",
       "      <td>0.261505</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.737990</td>\n",
       "      <td>1.598340</td>\n",
       "      <td>-0.298061</td>\n",
       "      <td>0.631974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2144648302</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2143-12-22 17:48:00</td>\n",
       "      <td>2143-12-24 05:35:00</td>\n",
       "      <td>-3.459217</td>\n",
       "      <td>-3.247620</td>\n",
       "      <td>-1.704770</td>\n",
       "      <td>-1.935422</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>-0.021873</td>\n",
       "      <td>-0.911228</td>\n",
       "      <td>0.412549</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>0.421726</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.031704</td>\n",
       "      <td>-0.086702</td>\n",
       "      <td>-0.122939</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>-0.128177</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.678164</td>\n",
       "      <td>-1.085512</td>\n",
       "      <td>-0.395568</td>\n",
       "      <td>-0.793937</td>\n",
       "      <td>-0.022948</td>\n",
       "      <td>-0.587398</td>\n",
       "      <td>-1.195107</td>\n",
       "      <td>0.012219</td>\n",
       "      <td>-0.539297</td>\n",
       "      <td>0.097823</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.079971</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>-0.115571</td>\n",
       "      <td>0.078197</td>\n",
       "      <td>-0.095112</td>\n",
       "      <td>1.301948</td>\n",
       "      <td>-0.164944</td>\n",
       "      <td>0.830165</td>\n",
       "      <td>-0.100946</td>\n",
       "      <td>0.108344</td>\n",
       "      <td>0.680689</td>\n",
       "      <td>-1.053958</td>\n",
       "      <td>-0.439401</td>\n",
       "      <td>-0.138311</td>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.608975</td>\n",
       "      <td>-3.559525</td>\n",
       "      <td>-3.529610</td>\n",
       "      <td>-2.459673</td>\n",
       "      <td>-2.723052</td>\n",
       "      <td>-2.897648</td>\n",
       "      <td>-0.109323</td>\n",
       "      <td>-0.899028</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>-0.730035</td>\n",
       "      <td>-0.060988</td>\n",
       "      <td>0.493389</td>\n",
       "      <td>1.612044</td>\n",
       "      <td>0.679896</td>\n",
       "      <td>2.096520</td>\n",
       "      <td>-0.831423</td>\n",
       "      <td>2.574353</td>\n",
       "      <td>-0.011180</td>\n",
       "      <td>-0.336196</td>\n",
       "      <td>2.886052</td>\n",
       "      <td>1.896696</td>\n",
       "      <td>1.065230</td>\n",
       "      <td>2.344742</td>\n",
       "      <td>0.066935</td>\n",
       "      <td>-0.011420</td>\n",
       "      <td>-0.309154</td>\n",
       "      <td>1.080435</td>\n",
       "      <td>-1.184207</td>\n",
       "      <td>1.840625</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>-0.052399</td>\n",
       "      <td>1.171896</td>\n",
       "      <td>0.636361</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.332044</td>\n",
       "      <td>-0.010381</td>\n",
       "      <td>-0.012015</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.010586</td>\n",
       "      <td>-1.028378</td>\n",
       "      <td>2.287762</td>\n",
       "      <td>-0.019127</td>\n",
       "      <td>-0.060986</td>\n",
       "      <td>-0.006756</td>\n",
       "      <td>1.328147</td>\n",
       "      <td>0.299922</td>\n",
       "      <td>2.027906</td>\n",
       "      <td>-0.011878</td>\n",
       "      <td>-0.011485</td>\n",
       "      <td>-1.443223</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.031491</td>\n",
       "      <td>-0.790454</td>\n",
       "      <td>-0.482464</td>\n",
       "      <td>0.204345</td>\n",
       "      <td>1.271811</td>\n",
       "      <td>0.291714</td>\n",
       "      <td>1.160423</td>\n",
       "      <td>-1.128429</td>\n",
       "      <td>2.177884</td>\n",
       "      <td>-0.021893</td>\n",
       "      <td>-0.377194</td>\n",
       "      <td>1.607697</td>\n",
       "      <td>1.037123</td>\n",
       "      <td>0.299594</td>\n",
       "      <td>1.307862</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>1.178401</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>1.960590</td>\n",
       "      <td>-0.897985</td>\n",
       "      <td>2.046090</td>\n",
       "      <td>-0.013629</td>\n",
       "      <td>-1.017747</td>\n",
       "      <td>2.048824</td>\n",
       "      <td>0.939732</td>\n",
       "      <td>0.841330</td>\n",
       "      <td>2.294428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2145490054</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2125-12-23 17:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523811</td>\n",
       "      <td>-1.367455</td>\n",
       "      <td>-0.215554</td>\n",
       "      <td>-0.289898</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>-0.010345</td>\n",
       "      <td>-1.160983</td>\n",
       "      <td>-0.932920</td>\n",
       "      <td>-1.403987</td>\n",
       "      <td>-0.011965</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>-0.024439</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>0.081068</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.669108</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.550603</td>\n",
       "      <td>-0.378605</td>\n",
       "      <td>-0.638406</td>\n",
       "      <td>-0.728598</td>\n",
       "      <td>-0.689851</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>-0.046749</td>\n",
       "      <td>-0.465008</td>\n",
       "      <td>-0.551646</td>\n",
       "      <td>0.132859</td>\n",
       "      <td>-0.029741</td>\n",
       "      <td>-0.026670</td>\n",
       "      <td>-0.053370</td>\n",
       "      <td>-0.074738</td>\n",
       "      <td>-0.481953</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>-0.024507</td>\n",
       "      <td>0.720678</td>\n",
       "      <td>1.904832</td>\n",
       "      <td>1.520399</td>\n",
       "      <td>0.265283</td>\n",
       "      <td>-0.360398</td>\n",
       "      <td>-0.176981</td>\n",
       "      <td>-0.781604</td>\n",
       "      <td>-0.176019</td>\n",
       "      <td>0.677988</td>\n",
       "      <td>-0.022306</td>\n",
       "      <td>-0.089238</td>\n",
       "      <td>-1.251107</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>1.225833</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>-0.408705</td>\n",
       "      <td>-0.328749</td>\n",
       "      <td>-0.459299</td>\n",
       "      <td>0.188087</td>\n",
       "      <td>-0.103820</td>\n",
       "      <td>-0.255992</td>\n",
       "      <td>0.354394</td>\n",
       "      <td>0.536315</td>\n",
       "      <td>-3.855542</td>\n",
       "      <td>-0.587627</td>\n",
       "      <td>-1.902488</td>\n",
       "      <td>-1.273176</td>\n",
       "      <td>-0.280167</td>\n",
       "      <td>-0.945672</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.669296</td>\n",
       "      <td>-1.717605</td>\n",
       "      <td>0.391150</td>\n",
       "      <td>0.131539</td>\n",
       "      <td>-1.403649</td>\n",
       "      <td>-1.707549</td>\n",
       "      <td>-0.011635</td>\n",
       "      <td>-1.420333</td>\n",
       "      <td>-1.199338</td>\n",
       "      <td>-0.440488</td>\n",
       "      <td>-1.020605</td>\n",
       "      <td>-0.022388</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.256513</td>\n",
       "      <td>1.458437</td>\n",
       "      <td>-0.023798</td>\n",
       "      <td>-1.231100</td>\n",
       "      <td>-0.025813</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.092389</td>\n",
       "      <td>-0.013832</td>\n",
       "      <td>-0.335299</td>\n",
       "      <td>-1.015465</td>\n",
       "      <td>-0.019289</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>-0.013398</td>\n",
       "      <td>0.793368</td>\n",
       "      <td>-0.004147</td>\n",
       "      <td>-1.206194</td>\n",
       "      <td>-0.010893</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.102045</td>\n",
       "      <td>-0.011892</td>\n",
       "      <td>-0.030286</td>\n",
       "      <td>-0.634064</td>\n",
       "      <td>0.404345</td>\n",
       "      <td>-3.705888</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>-2.126793</td>\n",
       "      <td>-1.015268</td>\n",
       "      <td>-0.301427</td>\n",
       "      <td>-0.959413</td>\n",
       "      <td>-0.020348</td>\n",
       "      <td>0.987275</td>\n",
       "      <td>-1.659547</td>\n",
       "      <td>1.888238</td>\n",
       "      <td>0.062597</td>\n",
       "      <td>-1.151258</td>\n",
       "      <td>-2.181874</td>\n",
       "      <td>-0.570713</td>\n",
       "      <td>-1.690266</td>\n",
       "      <td>-0.607683</td>\n",
       "      <td>-0.314282</td>\n",
       "      <td>-0.826657</td>\n",
       "      <td>-0.015010</td>\n",
       "      <td>0.625235</td>\n",
       "      <td>-0.572843</td>\n",
       "      <td>0.720196</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>-0.600858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows  140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id   age  gender  ethnicity_WHITE  ethnicity_BLACK  \\\n",
       "0    -2144679073  82.0       0                0                0   \n",
       "1    -2142084288  84.0       1                1                0   \n",
       "2    -2133944014  50.0       1                1                0   \n",
       "3    -2133227983  52.0       0                1                0   \n",
       "4    -2132499549  68.0       0                1                0   \n",
       "...          ...   ...     ...              ...              ...   \n",
       "2966  2142664100  65.0       1                1                0   \n",
       "2967  2144053271  71.0       0                1                0   \n",
       "2968  2144497079  65.0       1                1                0   \n",
       "2969  2144648302  91.0       0                1                0   \n",
       "2970  2145490054  33.0       0                1                0   \n",
       "\n",
       "      ethnicity_UNKNOWN  ethnicity_OTHER  ethnicity_HISPANIC  ethnicity_ASIAN  \\\n",
       "0                     0                1                   0                0   \n",
       "1                     0                0                   0                0   \n",
       "2                     0                0                   0                0   \n",
       "3                     0                0                   0                0   \n",
       "4                     0                0                   0                0   \n",
       "...                 ...              ...                 ...              ...   \n",
       "2966                  0                0                   0                0   \n",
       "2967                  0                0                   0                0   \n",
       "2968                  0                0                   0                0   \n",
       "2969                  0                0                   0                0   \n",
       "2970                  0                0                   0                0   \n",
       "\n",
       "      ethnicity_UNABLE_TO_OBTAIN  ethnicity_AMERICAN_INDIAN  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "...                          ...                        ...   \n",
       "2966                           0                          0   \n",
       "2967                           0                          0   \n",
       "2968                           0                          0   \n",
       "2969                           0                          0   \n",
       "2970                           0                          0   \n",
       "\n",
       "              anchor_time       death_datetime  heartrate_min  sysbp_min  \\\n",
       "0     2190-01-30 19:22:00  2194-04-23 19:27:00      -0.272794   1.217771   \n",
       "1     2161-07-10 08:07:00                  NaN      -0.073643  -0.427373   \n",
       "2     2141-03-25 16:45:00                  NaN      -0.173219   0.630220   \n",
       "3     2120-09-22 10:15:00  2121-08-28 15:15:00       0.025933  -1.073680   \n",
       "4     2205-11-16 13:07:00                  NaN       0.274872  -0.662394   \n",
       "...                   ...                  ...            ...        ...   \n",
       "2966  2180-08-11 04:23:00                  NaN       0.922114   0.042668   \n",
       "2967  2139-06-14 18:06:00                  NaN      -0.770673  -0.309863   \n",
       "2968  2150-04-26 14:47:00                  NaN      -1.019612   0.512710   \n",
       "2969  2143-12-22 17:48:00  2143-12-24 05:35:00      -3.459217  -3.247620   \n",
       "2970  2125-12-23 17:37:00                  NaN       0.523811  -1.367455   \n",
       "\n",
       "      diabp_min  meanbp_min  resprate_min  tempc_min  spo2_min  gcseye_min  \\\n",
       "0      0.923258    0.861968      0.878048   0.189353  0.317249    0.412549   \n",
       "1      0.222451   -1.935422      1.165394   0.217516 -0.256040    1.199315   \n",
       "2      0.572854    0.478013     -0.989699   0.147108 -0.419837   -0.374217   \n",
       "3      0.485253   -1.441765      0.447029   0.133026  0.235350    0.412549   \n",
       "4     -0.127953    0.148908      0.878048   0.161190  0.153452    0.412549   \n",
       "...         ...         ...           ...        ...       ...         ...   \n",
       "2966   0.923258    0.478013      0.590702   0.147108 -0.911228    1.199315   \n",
       "2967  -1.266765    0.203759     -0.989699  -0.289426  0.153452   -1.160983   \n",
       "2968  -0.565958    0.094057      0.590702   0.076699 -0.256040    0.412549   \n",
       "2969  -1.704770   -1.935422     -0.989699  -0.021873 -0.911228    0.412549   \n",
       "2970  -0.215554   -0.289898     -0.989699   0.287925 -0.010345   -1.160983   \n",
       "\n",
       "      gcsverbal_min  gcsmotor_min  heartrate_max  sysbp_max  diabp_max  \\\n",
       "0          1.239978      0.878154      -0.030099  -0.001925   0.069606   \n",
       "1          1.239978      0.878154      -0.004134  -0.014919  -0.026310   \n",
       "2         -0.932920      0.421726      -0.020620  -0.006257  -0.012100   \n",
       "3         -0.389695      0.421726      -0.017735  -0.020334  -0.008548   \n",
       "4          1.239978      0.878154      -0.007843  -0.019251  -0.072492   \n",
       "...             ...           ...            ...        ...        ...   \n",
       "2966       0.696753      0.878154       0.005757   0.012152   0.066053   \n",
       "2967      -0.932920     -1.403987      -0.006195  -0.017626  -0.097359   \n",
       "2968       1.239978      0.878154      -0.024741  -0.018709   0.009214   \n",
       "2969      -0.932920      0.421726      -0.005371  -0.031704  -0.086702   \n",
       "2970      -0.932920     -1.403987      -0.011965  -0.014919   0.012767   \n",
       "\n",
       "      meanbp_max  resprate_max  tempc_max  spo2_max  gcseye_max  \\\n",
       "0       0.021527     -0.309282  -0.058429 -0.021341    0.370578   \n",
       "1      -0.053989     -0.057963  -0.040074 -0.021341    0.370578   \n",
       "2      -0.044139     -0.215037  -0.080454 -0.030567    0.370578   \n",
       "3      -0.040856      0.161941  -0.003364 -0.021341    0.370578   \n",
       "4      -0.099956     -0.183622  -0.098809 -0.021341    0.370578   \n",
       "...          ...           ...        ...       ...         ...   \n",
       "2966    0.005111      0.193356  -0.021719 -0.021341    0.370578   \n",
       "2967   -0.086823     -0.152207  -0.095138 -0.021341   -2.337273   \n",
       "2968    0.514026     -0.057963  -0.091467 -0.021341    0.370578   \n",
       "2969   -0.122939     -0.120793  -0.128177 -0.021341    0.370578   \n",
       "2970   -0.024439     -0.120793   0.081068 -0.021341    0.370578   \n",
       "\n",
       "      gcsverbal_max  gcsmotor_max  heartrate_avg  sysbp_avg  diabp_avg  \\\n",
       "0          0.669108      0.341538      -0.671766   0.838925   0.734657   \n",
       "1          0.669108      0.341538      -0.134094  -0.066312   0.750897   \n",
       "2          0.669108      0.341538      -0.322070   0.427622   0.130176   \n",
       "3          0.669108      0.341538      -0.203561  -0.427533   0.646238   \n",
       "4          0.669108      0.341538      -0.038396  -0.330845   0.125592   \n",
       "...             ...           ...            ...        ...        ...   \n",
       "2966       0.669108      0.341538       0.787906   0.176275   1.271708   \n",
       "2967      -1.693958      0.341538      -0.392198  -0.085976  -0.199819   \n",
       "2968       0.669108      0.341538      -0.518790   0.179749  -0.911257   \n",
       "2969       0.078342      0.341538       0.678164  -1.085512  -0.395568   \n",
       "2970       0.669108      0.341538       0.550603  -0.378605  -0.638406   \n",
       "\n",
       "      meanbp_avg  resprate_avg  tempc_avg  spo2_avg  gcseye_avg  \\\n",
       "0       0.755136      0.000510  -0.003616 -0.100585    0.595497   \n",
       "1       0.395390      0.617088   0.086249 -0.167731    0.860623   \n",
       "2       0.083759     -0.701402  -0.062385 -0.402458    0.571394   \n",
       "3       0.240893     -0.310939  -0.113208 -0.015195    0.754573   \n",
       "4      -0.222650     -0.361032  -0.180333  0.001048    0.507121   \n",
       "...          ...           ...        ...       ...         ...   \n",
       "2966    0.677604      1.480574  -0.004342 -0.016273    0.860623   \n",
       "2967   -0.157516     -0.607566  -0.704260  0.203160   -2.261975   \n",
       "2968    0.063392     -0.454063  -0.207270  0.026637    0.779046   \n",
       "2969   -0.793937     -0.022948  -0.587398 -1.195107    0.012219   \n",
       "2970   -0.728598     -0.689851   0.706637 -0.046749   -0.465008   \n",
       "\n",
       "      gcsverbal_avg  gcsmotor_avg  heartrate_stddev  sysbp_stddev  \\\n",
       "0          1.041441      0.658405         -0.047481     -0.000154   \n",
       "1          1.041441      0.658405         -0.001199      0.007246   \n",
       "2          0.394775      0.594702         -0.024181     -0.001278   \n",
       "3         -0.007318      0.281090         -0.021139     -0.007731   \n",
       "4          1.041441      0.658405         -0.010829     -0.007087   \n",
       "...             ...           ...               ...           ...   \n",
       "2966       0.995843      0.658405          0.008134      0.010750   \n",
       "2967      -1.329666     -0.781980          0.027312      0.004955   \n",
       "2968       1.041441      0.658405         -0.022060     -0.031759   \n",
       "2969      -0.539297      0.097823          0.065100      0.016414   \n",
       "2970      -0.551646      0.132859         -0.029741     -0.026670   \n",
       "\n",
       "      diabp_stddev  meanbp_stddev  resprate_stddev  tempc_stddev  spo2_stddev  \\\n",
       "0         0.026722      -0.025099        -0.700168     -0.113932    -0.042762   \n",
       "1         0.014587       0.037638        -0.347862     -0.101546    -0.018473   \n",
       "2        -0.048238      -0.064594        -0.313192     -0.119714    -0.001438   \n",
       "3         0.012835       0.008907        -0.018688     -0.066404    -0.042251   \n",
       "4        -0.032613      -0.041233        -0.560680     -0.134095    -0.023838   \n",
       "...            ...            ...              ...           ...          ...   \n",
       "2966      0.050465       0.005370        -0.074307     -0.069785     0.021901   \n",
       "2967     -0.021687      -0.074604         0.230779     -0.051405    -0.022380   \n",
       "2968     -0.065296       0.342646        -0.375325     -0.118352    -0.037418   \n",
       "2969      0.021569       0.079971         0.223881     -0.115571     0.078197   \n",
       "2970     -0.053370      -0.074738        -0.481953      0.021343    -0.024507   \n",
       "\n",
       "      gcseye_stddev  gcsverbal_stddev  gcsmotor_stddev  heartrate_first  \\\n",
       "0         -0.054623         -0.696918        -0.769890        -1.241070   \n",
       "1         -1.069636         -0.696918        -0.769890        -0.299599   \n",
       "2          0.388982          1.970708        -0.371864        -0.770334   \n",
       "3         -0.338743          0.659022        -0.068008         0.312356   \n",
       "4          0.051502         -0.696918        -0.769890        -0.017158   \n",
       "...             ...               ...              ...              ...   \n",
       "2966      -1.069636         -0.299347        -0.769890         1.159680   \n",
       "2967      -0.524861         -0.696918         2.324226         0.171136   \n",
       "2968      -0.441552         -0.696918        -0.769890        -2.229614   \n",
       "2969      -0.095112          1.301948        -0.164944         0.830165   \n",
       "2970       0.720678          1.904832         1.520399         0.265283   \n",
       "\n",
       "      sysbp_first  diabp_first  meanbp_first  resprate_first  tempc_first  \\\n",
       "0       -0.100946    -0.093761     -0.277365       -0.176019    -0.090217   \n",
       "1        0.244989     0.060789      0.378146        0.701921     0.305525   \n",
       "2        0.201747    -0.117538     -0.327789       -0.803119     0.165851   \n",
       "3        0.763893     0.476888      1.941287        0.952761     0.212409   \n",
       "4       -0.187430     0.048901      0.075602        0.325661    -0.113496   \n",
       "...           ...          ...           ...             ...          ...   \n",
       "2966     0.028780     0.144009      0.428570        1.454441     0.212409   \n",
       "2967     0.677409    -0.117538     -1.033723        0.701921     0.119293   \n",
       "2968     0.201747    -0.272089     -0.781604       -0.552279    -0.113496   \n",
       "2969    -0.100946     0.108344      0.680689       -1.053958    -0.439401   \n",
       "2970    -0.360398    -0.176981     -0.781604       -0.176019     0.677988   \n",
       "\n",
       "      spo2_first  gcseye_first  gcsverbal_first  gcsmotor_first  \\\n",
       "0      -0.015482      0.729111         0.910102        0.608975   \n",
       "1      -0.056425      0.729111         0.910102        0.608975   \n",
       "2      -0.008658     -0.907586        -1.251107        0.069738   \n",
       "3      -0.008658      0.729111         0.369800        0.069738   \n",
       "4      -0.008658      0.729111         0.910102        0.608975   \n",
       "...          ...           ...              ...             ...   \n",
       "2966    0.004989      0.729111         0.910102        0.608975   \n",
       "2967   -0.042777     -1.725934        -1.251107       -2.087210   \n",
       "2968   -0.042777      0.729111         0.910102        0.608975   \n",
       "2969   -0.138311      0.729111         0.369800        0.608975   \n",
       "2970   -0.022306     -0.089238        -1.251107        0.069738   \n",
       "\n",
       "      heartrate_last  sysbp_last  diabp_last  meanbp_last  resprate_last  \\\n",
       "0          -0.521863    1.715295    0.616779     0.846636      -0.029003   \n",
       "1          -0.313804    0.682207    1.280328     1.020767       1.692185   \n",
       "2          -0.230580    0.086196   -0.227737    -0.198151      -0.315867   \n",
       "3          -0.188968    0.046461   -0.348382    -0.024020      -0.029003   \n",
       "4           0.726492    0.006727   -0.107092    -0.067553       1.118455   \n",
       "...              ...         ...         ...          ...            ...   \n",
       "2966        0.518433    1.198751    1.400973     1.020767       0.257862   \n",
       "2967       -0.272192   -0.907158   -0.408705     0.672505      -0.029003   \n",
       "2968       -0.022521   -0.390614   -1.011931    -0.546413      -0.459299   \n",
       "2969       -3.559525   -3.529610   -2.459673    -2.723052      -2.897648   \n",
       "2970        1.225833    0.006727   -0.408705    -0.328749      -0.459299   \n",
       "\n",
       "      tempc_last  spo2_last  gcseye_last  gcsverbal_last  gcsmotor_last  \\\n",
       "0      -0.048489   0.009782     0.659401        0.896608       0.536315   \n",
       "1      -0.021452   0.236984     0.659401        0.896608       0.536315   \n",
       "2      -0.055249  -0.217421     0.659401        0.896608       0.536315   \n",
       "3      -0.041730   0.577788     0.659401       -0.730035       0.536315   \n",
       "4      -0.001174   0.123383    -0.255992        0.896608       0.536315   \n",
       "...          ...        ...          ...             ...            ...   \n",
       "2966   -0.075527  -0.103820     0.659401        0.896608       0.536315   \n",
       "2967   -0.048489   0.577788    -2.086777       -1.272249       0.536315   \n",
       "2968    0.012345   0.009782     0.659401        0.896608       0.536315   \n",
       "2969   -0.109323  -0.899028    -0.255992       -0.730035      -0.060988   \n",
       "2970    0.188087  -0.103820    -0.255992        0.354394       0.536315   \n",
       "\n",
       "      chloride_serum_min  creatinine_min  sodium_serum_min  hemoglobin_min  \\\n",
       "0               1.093242       -0.663478          0.163419        0.285937   \n",
       "1               0.793315       -0.435926          0.507737        0.487113   \n",
       "2              -2.655837       -0.663478         -1.213852        1.694168   \n",
       "3              -0.256426       -0.891030          0.163419       -0.166709   \n",
       "4               1.393168        0.322582          0.163419       -0.217003   \n",
       "...                  ...             ...               ...             ...   \n",
       "2966           -0.406390       -0.435926         -0.525217       -0.367884   \n",
       "2967           -0.406390        0.246731         -0.525217        0.436819   \n",
       "2968           -1.606095        1.232790         -1.730329        0.587701   \n",
       "2969            0.493389        1.612044          0.679896        2.096520   \n",
       "2970           -3.855542       -0.587627         -1.902488       -1.273176   \n",
       "\n",
       "      platelet_count_min  urea_nitrogen_min  glucose_serum_min  \\\n",
       "0               0.076969          -0.734973          -0.012647   \n",
       "1              -0.000699          -0.477509          -0.012129   \n",
       "2               0.872452          -0.476000          -0.007468   \n",
       "3               0.670751          -0.731453          -0.011784   \n",
       "4               0.273945           0.984810          -0.013252   \n",
       "...                  ...                ...                ...   \n",
       "2966           -0.880643          -0.593669          -0.010576   \n",
       "2967           -0.264909           0.821883          -0.015064   \n",
       "2968           -0.683765           0.512624          -0.011180   \n",
       "2969           -0.831423           2.574353          -0.011180   \n",
       "2970           -0.280167          -0.945672          -0.012561   \n",
       "\n",
       "      bicarbonate_min  potassium_serum_min  anion_gap_min  \\\n",
       "0            0.669296            -0.124032      -0.915664   \n",
       "1            0.066001            -0.301095      -0.563366   \n",
       "2            2.680281            -1.717605      -0.397756   \n",
       "3            1.272592            -2.071733      -0.638644   \n",
       "4           -0.939492            -0.124032       0.062941   \n",
       "...               ...                  ...            ...   \n",
       "2966         0.468198            -0.478159      -0.512178   \n",
       "2967        -0.738393            -0.478159       0.526649   \n",
       "2968        -1.341689            -0.301095       1.896696   \n",
       "2969        -0.336196             2.886052       1.896696   \n",
       "2970         0.669296            -1.717605       0.391150   \n",
       "\n",
       "      leukocytes_blood_manual_min  hematocrit_min  chloride_serum_max  \\\n",
       "0                       -0.348052        0.099873            0.214809   \n",
       "1                       -0.060979        0.502304            0.510556   \n",
       "2                        1.230034        1.542830           -2.151170   \n",
       "3                        0.063069       -0.119478           -0.228812   \n",
       "4                       -0.121743       -0.197396            0.362682   \n",
       "...                           ...             ...                 ...   \n",
       "2966                    -0.135230       -0.414490           -0.672433   \n",
       "2967                     0.214830        0.322694           -0.672433   \n",
       "2968                    -0.401998        0.279656           -1.855423   \n",
       "2969                     1.065230        2.344742            0.066935   \n",
       "2970                     0.131539       -1.403649           -1.707549   \n",
       "\n",
       "      creatinine_max  sodium_serum_max  hemoglobin_max  platelet_count_max  \\\n",
       "0          -0.011713         -0.309154       -0.534404            0.297850   \n",
       "1          -0.011635          0.431631        0.320511            0.179330   \n",
       "2          -0.011679         -0.494351        1.507893            0.455851   \n",
       "3          -0.011739          0.061238       -0.011956            1.143237   \n",
       "4          -0.011601         -0.494351        0.035539            0.156544   \n",
       "...              ...               ...             ...                 ...   \n",
       "2966       -0.011670         -0.494351       -0.296928           -0.630374   \n",
       "2967       -0.011316         -0.679547       -0.154442            0.201483   \n",
       "2968       -0.011238         -1.420333        1.127931           -0.764876   \n",
       "2969       -0.011420         -0.309154        1.080435           -1.184207   \n",
       "2970       -0.011635         -1.420333       -1.199338           -0.440488   \n",
       "\n",
       "      urea_nitrogen_max  glucose_serum_max  bicarbonate_max  \\\n",
       "0             -0.994593          -0.024332        -0.000648   \n",
       "1             -0.090891          -0.021989        -0.009273   \n",
       "2             -0.444643          -0.017503         0.094229   \n",
       "3             -0.712930          -0.023036         0.033853   \n",
       "4              0.329004          -0.025130        -0.086899   \n",
       "...                 ...                ...              ...   \n",
       "2966          -0.760493          -0.020095         0.016602   \n",
       "2967           0.676810          -0.023983         0.033853   \n",
       "2968           2.620960          -0.017553        -0.000648   \n",
       "2969           1.840625          -0.023933        -0.052399   \n",
       "2970          -1.020605          -0.022388         0.007977   \n",
       "\n",
       "      potassium_serum_max  anion_gap_max  leukocytes_blood_manual_max  \\\n",
       "0               -1.025656      -0.767333                    -0.018388   \n",
       "1                0.292875      -0.091176                    -0.000665   \n",
       "2               -0.366390      -0.828988                     0.024072   \n",
       "3                0.622508      -0.514545                    -0.017100   \n",
       "4               -0.696023       1.220035                     0.012420   \n",
       "...                   ...            ...                          ...   \n",
       "2966            -0.696023      -0.391233                    -0.000369   \n",
       "2967            -0.586146      -0.074734                    -0.011540   \n",
       "2968             1.611406       1.663956                    -0.045848   \n",
       "2969             1.171896       0.636361                     0.007900   \n",
       "2970            -0.256513       1.458437                    -0.023798   \n",
       "\n",
       "      hematocrit_max  chloride_serum_avg  creatinine_avg  sodium_serum_avg  \\\n",
       "0          -0.395681           -0.007656       -0.014171         -0.015245   \n",
       "1           0.390295           -0.009259       -0.013774          0.012011   \n",
       "2           0.916153           -0.031538       -0.014085         -0.072093   \n",
       "3          -0.103317           -0.014468       -0.014352          0.003250   \n",
       "4           0.164904           -0.006054       -0.013275         -0.023033   \n",
       "...              ...                 ...             ...               ...   \n",
       "2966       -0.288525           -0.016472       -0.013880         -0.040554   \n",
       "2967       -0.188810           -0.017731       -0.012278         -0.053070   \n",
       "2968        1.050925           -0.026598       -0.011229         -0.112234   \n",
       "2969        1.332044           -0.010381       -0.012015          0.000330   \n",
       "2970       -1.231100           -0.025813       -0.013960         -0.092389   \n",
       "\n",
       "      hemoglobin_avg  platelet_count_avg  urea_nitrogen_avg  \\\n",
       "0          -0.012701            0.347919          -0.948893   \n",
       "1          -0.012045           -0.067964          -0.387671   \n",
       "2          -0.010550            0.218245          -0.646831   \n",
       "3          -0.012580            0.950606          -0.886384   \n",
       "4          -0.012630            0.006333           0.343322   \n",
       "...              ...                 ...                ...   \n",
       "2966       -0.013052           -0.742526          -0.717218   \n",
       "2967       -0.012299            0.139068           0.787500   \n",
       "2968       -0.011756           -0.688077           2.200226   \n",
       "2969       -0.010586           -1.028378           2.287762   \n",
       "2970       -0.013832           -0.335299          -1.015465   \n",
       "\n",
       "      glucose_serum_avg  bicarbonate_avg  potassium_serum_avg  anion_gap_avg  \\\n",
       "0             -0.020354         0.019154            -0.013272      -1.114836   \n",
       "1             -0.018131        -0.019468            -0.011258      -0.206481   \n",
       "2             -0.012610         0.170743            -0.014433      -0.872370   \n",
       "3             -0.018743         0.068637            -0.013154      -0.659500   \n",
       "4             -0.021086        -0.108780            -0.012621       0.272497   \n",
       "...                 ...              ...                  ...            ...   \n",
       "2966          -0.016265         0.019958            -0.012700      -0.209341   \n",
       "2967          -0.020678        -0.006364            -0.012291       0.406005   \n",
       "2968          -0.012913        -0.050189            -0.010504       1.899387   \n",
       "2969          -0.019127        -0.060986            -0.006756       1.328147   \n",
       "2970          -0.019289         0.020533            -0.013398       0.793368   \n",
       "\n",
       "      leukocytes_blood_manual_avg  hematocrit_avg  chloride_serum_stddev  \\\n",
       "0                       -0.162093       -0.233373              -0.012429   \n",
       "1                       -0.083122        0.450207              -0.012014   \n",
       "2                       -0.000619        1.647657              -0.011455   \n",
       "3                       -0.175868        0.104515              -0.011562   \n",
       "4                        0.315003       -0.175926              -0.012592   \n",
       "...                           ...             ...                    ...   \n",
       "2966                    -0.086127       -0.386152              -0.011885   \n",
       "2967                     0.082395        0.265825              -0.011921   \n",
       "2968                    -0.263500        0.504531              -0.012078   \n",
       "2969                     0.299922        2.027906              -0.011878   \n",
       "2970                    -0.004147       -1.206194              -0.010893   \n",
       "\n",
       "      creatinine_stddev  sodium_serum_stddev  hemoglobin_stddev  \\\n",
       "0             -0.011540            -0.590509          -0.011974   \n",
       "1             -0.011498            -0.343805          -0.011836   \n",
       "2             -0.011504             0.964784          -0.011819   \n",
       "3             -0.011538            -0.013936          -0.011738   \n",
       "4             -0.011538            -0.698913          -0.011672   \n",
       "...                 ...                  ...                ...   \n",
       "2966          -0.011525             0.060371          -0.011835   \n",
       "2967          -0.011205            -0.108793          -0.011934   \n",
       "2968          -0.011282             0.503888          -0.011802   \n",
       "2969          -0.011485            -1.443223          -0.011992   \n",
       "2970          -0.011497            -0.102045          -0.011892   \n",
       "\n",
       "      glucose_serum_stddev  bicarbonate_stddev  potassium_serum_stddev  \\\n",
       "0                -0.030961           -0.601701               -1.056430   \n",
       "1                -0.029291           -0.226259                0.125189   \n",
       "2                -0.027636           -0.299876                0.896400   \n",
       "3                -0.030063           -0.282218                2.463369   \n",
       "4                -0.031460           -1.112750               -0.219378   \n",
       "...                    ...                 ...                     ...   \n",
       "2966             -0.027643            0.316081               -0.427042   \n",
       "2967             -0.029347            3.064577               -0.380575   \n",
       "2968             -0.026767            1.913836                1.704332   \n",
       "2969             -0.031491           -0.790454               -0.482464   \n",
       "2970             -0.030286           -0.634064                0.404345   \n",
       "\n",
       "      chloride_serum_first  creatinine_first  sodium_serum_first  \\\n",
       "0                 0.743687         -0.694348           -0.191987   \n",
       "1                 0.474016         -0.173894            0.614182   \n",
       "2                -2.627203         -0.463035           -1.481858   \n",
       "3                -0.469833         -0.867833           -0.191987   \n",
       "4                 1.013358          0.057419            0.130480   \n",
       "...                    ...               ...                 ...   \n",
       "2966              0.069509         -0.405207            0.130480   \n",
       "2967              0.069509          1.618781           -0.836923   \n",
       "2968             -1.683354          1.792265           -1.643092   \n",
       "2969              0.204345          1.271811            0.291714   \n",
       "2970             -3.705888         -0.173894           -2.126793   \n",
       "\n",
       "      hemoglobin_first  platelet_count_first  urea_nitrogen_first  \\\n",
       "0            -0.406075              0.116251            -0.789275   \n",
       "1             0.464202             -0.020737            -0.276849   \n",
       "2             1.160423              0.739696            -0.305407   \n",
       "3             0.159605              0.750668            -0.891840   \n",
       "4             0.203119             -0.207427             0.379972   \n",
       "...                ...                   ...                  ...   \n",
       "2966         -0.101478             -0.497942            -0.758304   \n",
       "2967         -0.188505              0.068022             1.442229   \n",
       "2968          1.203937             -0.637141             2.378993   \n",
       "2969          1.160423             -1.128429             2.177884   \n",
       "2970         -1.015268             -0.301427            -0.959413   \n",
       "\n",
       "      glucose_serum_first  bicarbonate_first  potassium_serum_first  \\\n",
       "0               -0.022292           0.207578              -0.788282   \n",
       "1               -0.022242           0.012654              -0.025925   \n",
       "2               -0.020149           2.156819              -1.768456   \n",
       "3               -0.022641           0.792351              -0.897190   \n",
       "4               -0.023489          -1.351814              -0.243741   \n",
       "...                   ...                ...                    ...   \n",
       "2966            -0.019750           0.207578              -0.570466   \n",
       "2967            -0.022292          -0.572118              -0.134833   \n",
       "2968            -0.018703          -0.961966               2.043330   \n",
       "2969            -0.021893          -0.377194               1.607697   \n",
       "2970            -0.020348           0.987275              -1.659547   \n",
       "\n",
       "      anion_gap_first  leukocytes_blood_manual_first  hematocrit_first  \\\n",
       "0           -1.346000                      -0.054095         -0.572535   \n",
       "1            0.043446                      -0.216607          0.465424   \n",
       "2           -0.126777                       0.737925          1.165595   \n",
       "3           -0.373601                       0.148029          0.173951   \n",
       "4            0.017912                      -0.110297          0.278954   \n",
       "...               ...                            ...               ...   \n",
       "2966        -0.026771                      -0.490395         -0.095195   \n",
       "2967        -0.099116                       0.159315         -0.189184   \n",
       "2968         2.101017                      -0.185685          1.126822   \n",
       "2969         1.037123                       0.299594          1.307862   \n",
       "2970         1.888238                       0.062597         -1.151258   \n",
       "\n",
       "      chloride_serum_last  creatinine_last  sodium_serum_last  \\\n",
       "0                0.656699        -0.695650          -0.087780   \n",
       "1                0.183603        -0.508245           0.112531   \n",
       "2               -2.339573        -0.695650          -1.690266   \n",
       "3                0.183603        -0.883055           0.513153   \n",
       "4                0.814397         0.116439          -0.488402   \n",
       "...                   ...              ...                ...   \n",
       "2966            -1.077985        -0.383308          -1.289645   \n",
       "2967            -1.077985         0.053970          -0.488402   \n",
       "2968            -1.866477         0.866059          -1.289645   \n",
       "2969             0.499000         1.178401           0.112531   \n",
       "2970            -2.181874        -0.570713          -1.690266   \n",
       "\n",
       "      hemoglobin_last  platelet_count_last  urea_nitrogen_last  \\\n",
       "0            0.157334            -0.178773           -0.863655   \n",
       "1            0.430555             0.701722           -0.447977   \n",
       "2            1.523437             0.575731           -0.612072   \n",
       "3           -0.498395             0.946249           -0.749180   \n",
       "4           -0.553039             0.463571            0.272386   \n",
       "...               ...                  ...                 ...   \n",
       "2966        -0.389107            -1.005746           -0.521972   \n",
       "2967         0.594487            -0.032757            0.391649   \n",
       "2968         0.867708            -0.538783            0.261505   \n",
       "2969         1.960590            -0.897985            2.046090   \n",
       "2970        -0.607683            -0.314282           -0.826657   \n",
       "\n",
       "      glucose_serum_last  bicarbonate_last  potassium_serum_last  \\\n",
       "0              -0.015096          0.214490             -0.408989   \n",
       "1              -0.013025         -0.196256             -0.900551   \n",
       "2              -0.001803          2.062846             -0.408989   \n",
       "3              -0.011385          1.446727             -0.900551   \n",
       "4              -0.015010         -1.428493             -0.736697   \n",
       "...                  ...               ...                   ...   \n",
       "2966           -0.006292          0.214490              0.082574   \n",
       "2967           -0.013456          1.446727             -0.081281   \n",
       "2968           -0.005688          0.009117              0.737990   \n",
       "2969           -0.013629         -1.017747              2.048824   \n",
       "2970           -0.015010          0.625235             -0.572843   \n",
       "\n",
       "      anion_gap_last  leukocytes_blood_manual_last  hematocrit_last  \n",
       "0          -0.979015                     -0.516496         0.100735  \n",
       "1           0.024266                      0.217026         0.473387  \n",
       "2          -0.658492                      0.160877         1.557531  \n",
       "3          -1.200746                     -0.014856        -0.475707  \n",
       "4           0.140620                      0.490582        -0.508395  \n",
       "...              ...                           ...              ...  \n",
       "2966        0.061587                      0.718153        -0.414065  \n",
       "2967       -0.438956                     -0.033435         0.564168  \n",
       "2968        1.598340                     -0.298061         0.631974  \n",
       "2969        0.939732                      0.841330         2.294428  \n",
       "2970        0.720196                      0.061206        -0.600858  \n",
       "\n",
       "[2971 rows x 140 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataMatrix = pd.read_csv(dataDirName + 'data_matrix/data_matrix_standardised.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix.anchor_time = dataMatrix.anchor_time.apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S'))\n",
    "dataMatrix.death_datetime = dataMatrix.death_datetime.apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S'))\n",
    "dataMatrix['target'] = (dataMatrix['death_datetime'] < (dataMatrix['anchor_time'] + pd.Timedelta(days=7)))\n",
    "dataMatrix.target.fillna(value=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "False    2524\n",
       "True      447\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMatrix.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate positive and negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrixPositive = dataMatrix[dataMatrix.target == True]\n",
    "dataMatrixNegative = dataMatrix[dataMatrix.target == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate different data imbalances and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1050, 447, '70_30'),\n",
       " (1125, 375, '75_25'),\n",
       " (1200, 300, '80_20'),\n",
       " (1275, 225, '85_15'),\n",
       " (1350, 150, '90_10')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalSamples = 1500\n",
    "dataSizeList = []\n",
    "# dataSizeList = [(447, 447, '50_50'), (int(447 * 65/35), 447, '65_35')]\n",
    "for proportion in [70, 75, 80, 85, 90]:\n",
    "    negativeSize = int(totalSamples * proportion / 100)\n",
    "    positiveSize = min(dataMatrixPositive.shape[0], int(totalSamples - (totalSamples * proportion / 100)))\n",
    "    label = str(proportion) + '_' + str(100 - proportion)\n",
    "    dataSizeList.append((negativeSize, positiveSize, label))\n",
    "dataSizeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 16:48:40,296 - Pipeline - INFO - dirName: 70_30_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 16:48:40,297 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 16:48:40,298 - Pipeline - INFO - Reading data\n",
      "2023-09-25 16:48:40,569 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 16:48:40,577 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 16:50:25,309 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 16:50:25,310 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:50:25,333 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:50:25,334 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 16:51:28,670 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 16:51:48,618 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 16:51:54,889 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 16:51:58,521 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 16:52:47,669 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 16:52:51,000 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.35, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 16:52:51,002 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:52:54,236 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 16:52:54,238 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:52:54,238 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:52:54,239 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 16:53:31,005 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 16:53:52,085 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 16:53:57,661 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 16:54:02,451 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 16:54:54,069 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 16:54:57,616 - Pipeline - INFO - params: {'max_depth': 9, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.3, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 16:54:57,618 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:54:59,951 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 16:54:59,952 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:55:03,729 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:55:03,730 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:55:04,712 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 16:55:04,713 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:55:05,397 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:55:05,399 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:55:06,168 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 16:55:06,169 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:55:23,734 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:55:23,741 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:55:26,830 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 16:55:26,832 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:55:38,457 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:55:38,459 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:55:40,876 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 16:55:40,878 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:55:42,940 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:56:00,018 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 16:56:00,019 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:56:01,352 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 16:56:12,460 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 16:56:12,461 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 16:56:12,464 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 16:56:12,471 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 16:56:12,471 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 16:56:43,988 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 16:57:01,560 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 16:57:05,642 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 16:57:08,480 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 16:57:46,298 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 16:57:48,758 - Pipeline - INFO - params: {'max_depth': 7, 'scale_pos_weight': 0.2, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 16:57:48,759 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 16:57:49,236 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 16:58:42,992 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 16:58:42,993 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 16:58:42,994 - Pipeline - INFO - Building the model\n",
      "2023-09-25 16:58:42,995 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 16:59:12,047 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 16:59:25,157 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 16:59:28,306 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 16:59:30,830 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:00:01,509 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:00:03,919 - Pipeline - INFO - params: {'max_depth': 8, 'scale_pos_weight': 0.2, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.2, 'colsample_bytree': 0.8, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 17:00:03,922 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:00:05,705 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 17:00:05,706 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:00:06,310 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:00:06,312 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.112391  , 0.11233068, 0.11371803, 0.11184812, 0.11429024]), 'score_time': array([0.02610898, 0.02510858, 0.02491307, 0.02405047, 0.02425218]), 'test_accuracy': array([0.88      , 0.89333333, 0.87625418, 0.87959866, 0.83946488]), 'test_balanced_accuracy': array([0.82049097, 0.82672134, 0.81626993, 0.81532745, 0.76370638]), 'test_average_precision': array([0.84176482, 0.89156736, 0.85537759, 0.83873246, 0.80488339]), 'test_f1': array([0.76923077, 0.78666667, 0.76129032, 0.76315789, 0.68      ]), 'test_roc_auc': array([0.91053837, 0.91831301, 0.89476519, 0.89498061, 0.8865252 ]), 'test_mccf1_score': array([0.80595882, 0.82364593, 0.79900161, 0.80190294, 0.73182312])}, 'lr': {'fit_time': array([0.02990961, 0.02539539, 0.02415919, 0.02488542, 0.0281055 ]), 'score_time': array([0.00946236, 0.00924683, 0.00919151, 0.00907755, 0.00919795]), 'test_accuracy': array([0.86      , 0.88666667, 0.85618729, 0.89632107, 0.85284281]), 'test_balanced_accuracy': array([0.80627296, 0.82847862, 0.81530052, 0.84373654, 0.7963701 ]), 'test_average_precision': array([0.78759053, 0.87596676, 0.84370467, 0.85020694, 0.80476749]), 'test_f1': array([0.74074074, 0.78205128, 0.74556213, 0.80254777, 0.725     ]), 'test_roc_auc': array([0.87459396, 0.91309441, 0.88668677, 0.92228565, 0.88625592]), 'test_mccf1_score': array([0.77923141, 0.81693424, 0.78096413, 0.83353628, 0.7659904 ])}, 'lgbm': {'fit_time': array([0.23180795, 0.22344708, 0.22343993, 0.22404981, 0.22890186]), 'score_time': array([0.01300883, 0.0120883 , 0.01212692, 0.01174879, 0.01187181]), 'test_accuracy': array([0.87333333, 0.89333333, 0.87625418, 0.87625418, 0.85953177]), 'test_balanced_accuracy': array([0.79951009, 0.82672134, 0.81626993, 0.80964563, 0.78123654]), 'test_average_precision': array([0.86124577, 0.88428783, 0.85267328, 0.86930538, 0.84021836]), 'test_f1': array([0.74324324, 0.78666667, 0.76129032, 0.75496689, 0.71232877]), 'test_roc_auc': array([0.90473401, 0.91037861, 0.89907368, 0.92169324, 0.90855235]), 'test_mccf1_score': array([0.7876358 , 0.82364593, 0.79900161, 0.79537088, 0.76158681])}, 'mlp': {'fit_time': array([1.5590663 , 1.59349632, 1.61883736, 1.61987996, 1.69148493]), 'score_time': array([0.01215529, 0.01172638, 0.01174426, 0.01229906, 0.01193118]), 'test_accuracy': array([0.84      , 0.88666667, 0.81270903, 0.84615385, 0.82943144]), 'test_balanced_accuracy': array([0.78555834, 0.84147186, 0.78449483, 0.79825506, 0.76984597]), 'test_average_precision': array([0.75976402, 0.87088669, 0.80410531, 0.80732406, 0.75986795]), 'test_f1': array([0.70731707, 0.79268293, 0.69230769, 0.72289157, 0.68322981]), 'test_roc_auc': array([0.86005645, 0.90910059, 0.85830461, 0.87930849, 0.84387118]), 'test_mccf1_score': array([0.74983027, 0.82319717, 0.73223273, 0.76223821, 0.72979463])}, 'xgb_min': {'fit_time': array([0.14372492, 0.14453626, 0.144943  , 0.14260483, 0.14627266]), 'score_time': array([0.01520658, 0.01443863, 0.01365709, 0.01422787, 0.0140059 ]), 'test_accuracy': array([0.83333333, 0.86      , 0.85284281, 0.82274247, 0.83946488]), 'test_balanced_accuracy': array([0.76132914, 0.78028649, 0.79305795, 0.73198514, 0.77695498]), 'test_average_precision': array([0.79349416, 0.81600121, 0.81210709, 0.78305582, 0.77927735]), 'test_f1': array([0.67532468, 0.71232877, 0.72151899, 0.62937063, 0.69620253]), 'test_roc_auc': array([0.88364663, 0.88897172, 0.89395735, 0.87381517, 0.87925463]), 'test_mccf1_score': array([0.7264892 , 0.76240228, 0.76375141, 0.69263123, 0.74205934])}, 'lr_min': {'fit_time': array([0.00547671, 0.00539374, 0.00552511, 0.00560379, 0.00560069]), 'score_time': array([0.00854611, 0.00798154, 0.00798869, 0.00792098, 0.00789714]), 'test_accuracy': array([0.83666667, 0.85333333, 0.82608696, 0.8361204 , 0.82943144]), 'test_balanced_accuracy': array([0.77669205, 0.78204377, 0.7674763 , 0.78120961, 0.76322167]), 'test_average_precision': array([0.75324632, 0.80740045, 0.78631945, 0.7950368 , 0.76715727]), 'test_f1': array([0.69565217, 0.71052632, 0.67901235, 0.6993865 , 0.67515924]), 'test_roc_auc': array([0.84418766, 0.86799084, 0.86810642, 0.87898535, 0.87887764]), 'test_mccf1_score': array([0.74089644, 0.75757654, 0.72581425, 0.74296605, 0.72443909])}, 'lgbm_min': {'fit_time': array([0.14968729, 0.17966962, 0.15289426, 0.15449858, 0.25545359]), 'score_time': array([0.01080799, 0.0107913 , 0.01038337, 0.0109849 , 0.01089072]), 'test_accuracy': array([0.83      , 0.85      , 0.86287625, 0.83277592, 0.84280936]), 'test_balanced_accuracy': array([0.74596624, 0.76992918, 0.7968548 , 0.74240629, 0.75945174]), 'test_average_precision': array([0.81161827, 0.82234574, 0.81912761, 0.77567163, 0.77718879]), 'test_f1': array([0.65306122, 0.69387755, 0.73202614, 0.64788732, 0.67586207]), 'test_roc_auc': array([0.88806646, 0.88843921, 0.89013356, 0.85765834, 0.87823137]), 'test_mccf1_score': array([0.71120546, 0.74605976, 0.77483667, 0.70907231, 0.73105874])}, 'mlp_min': {'fit_time': array([1.03302622, 1.09333467, 1.0506525 , 1.03471661, 1.03996801]), 'score_time': array([0.01512027, 0.01023555, 0.00992155, 0.01001859, 0.01006818]), 'test_accuracy': array([0.80666667, 0.83666667, 0.78595318, 0.79598662, 0.78595318]), 'test_balanced_accuracy': array([0.75211673, 0.77344374, 0.73904028, 0.73621284, 0.73572813]), 'test_average_precision': array([0.72102569, 0.79260611, 0.739342  , 0.69863348, 0.68107966]), 'test_f1': array([0.6547619 , 0.6918239 , 0.63218391, 0.63030303, 0.62790698]), 'test_roc_auc': array([0.82847862, 0.85840567, 0.83827014, 0.79572383, 0.8104804 ]), 'test_mccf1_score': array([0.70328121, 0.73840217, 0.6817683 , 0.68290605, 0.6786252 ])}, 'xgb_ensemble': {'fit_time': array([0.09366369, 0.07876563, 0.08122087, 0.08315206, 0.08266354]), 'score_time': array([0.01756191, 0.01682067, 0.01623678, 0.02266788, 0.01695633]), 'test_accuracy': array([0.89333333, 0.84      , 0.88666667, 0.89333333, 0.87248322]), 'test_balanced_accuracy': array([0.84872854, 0.74875027, 0.80928059, 0.82786351, 0.82053532]), 'test_average_precision': array([0.8669242 , 0.77337661, 0.85763607, 0.88327207, 0.83605709]), 'test_f1': array([0.8       , 0.65714286, 0.76056338, 0.78378378, 0.75949367]), 'test_roc_auc': array([0.91784395, 0.84220822, 0.90915018, 0.91871332, 0.87560333]), 'test_mccf1_score': array([0.82970188, 0.71672691, 0.80349518, 0.82018905, 0.79546319])}, 'lr_ensemble': {'fit_time': array([0.005373  , 0.00534892, 0.00526762, 0.00514722, 0.00511312]), 'score_time': array([0.00949025, 0.0092175 , 0.00915885, 0.00909448, 0.00926852]), 'test_accuracy': array([0.89333333, 0.86666667, 0.86      , 0.88666667, 0.8590604 ]), 'test_balanced_accuracy': array([0.84177353, 0.78135188, 0.78363399, 0.83014562, 0.80419043]), 'test_average_precision': array([0.88713579, 0.79913266, 0.85725473, 0.89606336, 0.84920139]), 'test_f1': array([0.79487179, 0.71428571, 0.71232877, 0.77922078, 0.73417722]), 'test_roc_auc': array([0.92197348, 0.85285807, 0.91653988, 0.94001304, 0.88569548]), 'test_mccf1_score': array([0.82651832, 0.76533144, 0.76029116, 0.81383973, 0.7737818 ])}}\n",
      "2023-09-25 17:00:07,120 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 17:00:07,123 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 17:00:07,384 - Pipeline - INFO - dirName: 75_25_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 17:00:07,385 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 17:00:07,386 - Pipeline - INFO - Reading data\n",
      "2023-09-25 17:00:07,705 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 17:00:07,711 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 17:01:58,140 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 17:01:58,142 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:01:58,142 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:01:58,143 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:03:01,319 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:03:31,186 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:03:39,280 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:03:45,157 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:04:49,484 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:04:53,941 - Pipeline - INFO - params: {'max_depth': 7, 'scale_pos_weight': 0.25, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.7, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 17:04:53,942 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:04:56,699 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 17:04:56,700 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:04:56,701 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:04:56,701 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:05:32,245 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:05:45,090 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:05:48,151 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:05:49,829 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:06:14,970 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:06:16,663 - Pipeline - INFO - params: {'max_depth': 3, 'scale_pos_weight': 0.35, 'n_estimators': 70, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.7, 'subsample': 0.6, 'reg_alpha': 0}\n",
      "2023-09-25 17:06:16,664 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:06:18,102 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 17:06:18,103 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:06:22,014 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:06:22,015 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:06:23,158 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 17:06:23,159 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:06:23,815 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:06:23,816 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:06:24,753 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 17:06:24,754 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:06:41,793 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:06:41,794 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:06:44,909 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 17:06:44,910 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:06:56,176 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:06:56,177 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:06:58,090 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 17:06:58,091 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:07:00,116 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:07:17,311 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 17:07:17,312 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:07:18,668 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:07:29,908 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 17:07:29,910 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 17:07:29,911 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 17:07:29,917 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 17:07:29,917 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:08:01,268 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:08:09,584 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:08:11,802 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:08:13,055 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:08:33,984 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:08:35,270 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 80, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:08:35,273 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 17:08:35,757 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 17:09:27,695 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 17:09:27,696 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:09:27,697 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:09:27,698 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:09:56,712 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:10:08,450 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:10:11,363 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:10:13,445 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:10:40,524 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:10:42,612 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.1, 'n_estimators': 90, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.9, 'reg_alpha': 0.1}\n",
      "2023-09-25 17:10:42,613 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:10:44,235 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 17:10:44,236 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:10:44,842 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:10:44,843 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.17148685, 0.17097425, 0.16964674, 0.17044115, 0.25264287]), 'score_time': array([0.02658534, 0.026021  , 0.02552366, 0.0264523 , 0.02536631]), 'test_accuracy': array([0.89333333, 0.89      , 0.86333333, 0.87666667, 0.88333333]), 'test_balanced_accuracy': array([0.79741689, 0.81338197, 0.75932791, 0.7772662 , 0.79532409]), 'test_average_precision': array([0.81626831, 0.80288185, 0.80292285, 0.81491189, 0.81122413]), 'test_f1': array([0.73770492, 0.7480916 , 0.66666667, 0.69918699, 0.72440945]), 'test_roc_auc': array([0.88364028, 0.87102368, 0.88423822, 0.89948577, 0.87909591]), 'test_mccf1_score': array([0.78624294, 0.79061529, 0.72599622, 0.75331761, 0.77243291])}, 'lr': {'fit_time': array([0.04025292, 0.03770089, 0.03848076, 0.03673291, 0.04172277]), 'score_time': array([0.00959969, 0.009377  , 0.00953245, 0.00937963, 0.009547  ]), 'test_accuracy': array([0.89      , 0.86333333, 0.87666667, 0.87666667, 0.89      ]), 'test_balanced_accuracy': array([0.8224707 , 0.79113848, 0.81362114, 0.79998804, 0.81792633]), 'test_average_precision': array([0.78022523, 0.73833987, 0.76933636, 0.80667737, 0.78341359]), 'test_f1': array([0.75555556, 0.70072993, 0.73381295, 0.72180451, 0.7518797 ]), 'test_roc_auc': array([0.87700311, 0.87000718, 0.89195169, 0.87467113, 0.8844774 ]), 'test_mccf1_score': array([0.79547542, 0.74862473, 0.77596345, 0.76773042, 0.79305556])}, 'lgbm': {'fit_time': array([0.31071758, 0.23223662, 0.21995664, 0.22670603, 0.22362828]), 'score_time': array([0.01207829, 0.0119071 , 0.01175451, 0.01189566, 0.01165533]), 'test_accuracy': array([0.89      , 0.89      , 0.87666667, 0.87      , 0.87666667]), 'test_balanced_accuracy': array([0.79066013, 0.7952045 , 0.77272184, 0.75920832, 0.78181057]), 'test_average_precision': array([0.83654217, 0.80373117, 0.82014035, 0.8193123 , 0.82813776]), 'test_f1': array([0.72727273, 0.73170732, 0.69421488, 0.67226891, 0.704     ]), 'test_roc_auc': array([0.90911265, 0.87975365, 0.89135374, 0.90468787, 0.88704855]), 'test_mccf1_score': array([0.77807996, 0.78063395, 0.75031883, 0.7331629 , 0.75627589])}, 'mlp': {'fit_time': array([1.58328223, 1.62409377, 1.58569527, 1.63120651, 1.77560902]), 'score_time': array([0.01227999, 0.01226997, 0.01179671, 0.01186442, 0.01212502]), 'test_accuracy': array([0.88      , 0.83333333, 0.86      , 0.85      , 0.87333333]), 'test_balanced_accuracy': array([0.8067448 , 0.76668261, 0.78892609, 0.75956709, 0.81595312]), 'test_average_precision': array([0.72364487, 0.72893393, 0.76580927, 0.74088442, 0.78372629]), 'test_f1': array([0.73134328, 0.65277778, 0.69565217, 0.65648855, 0.73239437]), 'test_roc_auc': array([0.83837599, 0.85464004, 0.86193494, 0.84423583, 0.89210117]), 'test_mccf1_score': array([0.77540894, 0.70619919, 0.74403773, 0.71352941, 0.77402413])}, 'xgb_min': {'fit_time': array([0.06301308, 0.05860925, 0.05920529, 0.05785465, 0.05779147]), 'score_time': array([0.01332688, 0.01319718, 0.01341677, 0.01354289, 0.0127089 ]), 'test_accuracy': array([0.87      , 0.87      , 0.87      , 0.86666667, 0.87666667]), 'test_balanced_accuracy': array([0.76375269, 0.76829706, 0.77738579, 0.7615403 , 0.7772662 ]), 'test_average_precision': array([0.77953556, 0.75551231, 0.76800284, 0.76708109, 0.80309764]), 'test_f1': array([0.67768595, 0.68292683, 0.69291339, 0.67213115, 0.69918699]), 'test_roc_auc': array([0.89189189, 0.86863191, 0.86899067, 0.8561349 , 0.86629993]), 'test_mccf1_score': array([0.7364354 , 0.73965744, 0.74595643, 0.73116678, 0.75331761])}, 'lr_min': {'fit_time': array([0.02518392, 0.01775599, 0.01741576, 0.01964855, 0.02060246]), 'score_time': array([0.0083909 , 0.00826454, 0.00809669, 0.00834632, 0.00814676]), 'test_accuracy': array([0.89      , 0.84333333, 0.87      , 0.85      , 0.87      ]), 'test_balanced_accuracy': array([0.8088376 , 0.75514231, 0.77284143, 0.76865582, 0.76375269]), 'test_average_precision': array([0.80175742, 0.76271389, 0.77976781, 0.76270804, 0.80928591]), 'test_f1': array([0.74418605, 0.64661654, 0.688     , 0.66666667, 0.67768595]), 'test_roc_auc': array([0.89577852, 0.87239895, 0.89422387, 0.86934944, 0.89189189]), 'test_mccf1_score': array([0.78815377, 0.70441564, 0.74283058, 0.72056773, 0.7364354 ])}, 'lgbm_min': {'fit_time': array([0.10424089, 0.10959673, 0.1020937 , 0.09891891, 0.10501742]), 'score_time': array([0.01026416, 0.01056647, 0.01077747, 0.01102185, 0.01034832]), 'test_accuracy': array([0.88      , 0.87333333, 0.86333333, 0.86333333, 0.88333333]), 'test_balanced_accuracy': array([0.78402296, 0.76596508, 0.75932791, 0.75932791, 0.78623535]), 'test_average_precision': array([0.80630804, 0.76777377, 0.79265526, 0.7810971 , 0.8161726 ]), 'test_f1': array([0.70967742, 0.68333333, 0.66666667, 0.66666667, 0.71544715]), 'test_roc_auc': array([0.89619708, 0.86289165, 0.89488161, 0.86259268, 0.88190624]), 'test_mccf1_score': array([0.76157721, 0.74180497, 0.72599622, 0.72599622, 0.76697652])}, 'mlp_min': {'fit_time': array([1.03756499, 1.03952551, 1.06391191, 1.03664041, 1.04237771]), 'score_time': array([0.00995445, 0.01212549, 0.00993657, 0.00984788, 0.00988078]), 'test_accuracy': array([0.85      , 0.84333333, 0.82      , 0.81666667, 0.88333333]), 'test_balanced_accuracy': array([0.76865582, 0.76423105, 0.73965558, 0.77379813, 0.81350155]), 'test_average_precision': array([0.72860012, 0.72091544, 0.67594713, 0.73508168, 0.79333285]), 'test_f1': array([0.66666667, 0.65693431, 0.61428571, 0.64968153, 0.74074074]), 'test_roc_auc': array([0.84202344, 0.83454915, 0.8329945 , 0.85099259, 0.87305669]), 'test_mccf1_score': array([0.72056773, 0.71168619, 0.67474529, 0.701255  , 0.78299097])}, 'xgb_ensemble': {'fit_time': array([0.12791944, 0.07212853, 0.07147336, 0.07206368, 0.07100177]), 'score_time': array([0.0166707 , 0.01565218, 0.01633239, 0.0162313 , 0.01570868]), 'test_accuracy': array([0.90666667, 0.9       , 0.85333333, 0.92      , 0.85333333]), 'test_balanced_accuracy': array([0.80993789, 0.79565217, 0.71552795, 0.8484472 , 0.69565217]), 'test_average_precision': array([0.82993968, 0.85156769, 0.81093396, 0.80452023, 0.76215192]), 'test_f1': array([0.75862069, 0.73684211, 0.59259259, 0.80645161, 0.56      ]), 'test_roc_auc': array([0.90161491, 0.92      , 0.92496894, 0.92596273, 0.87726708]), 'test_mccf1_score': array([0.80403092, 0.7870161 , 0.67059025, 0.84029947, 0.6508236 ])}, 'lr_ensemble': {'fit_time': array([0.00514722, 0.00522947, 0.00508451, 0.00513792, 0.00504637]), 'score_time': array([0.00947452, 0.00944734, 0.00946045, 0.00915098, 0.00914788]), 'test_accuracy': array([0.89333333, 0.9       , 0.88      , 0.91333333, 0.86      ]), 'test_balanced_accuracy': array([0.80124224, 0.79565217, 0.7826087 , 0.83416149, 0.71987578]), 'test_average_precision': array([0.83781785, 0.85601967, 0.81384917, 0.85300159, 0.72175653]), 'test_f1': array([0.73333333, 0.73684211, 0.7       , 0.78688525, 0.60377358]), 'test_roc_auc': array([0.92298137, 0.91478261, 0.90956522, 0.91552795, 0.83478261]), 'test_mccf1_score': array([0.78078205, 0.7870161 , 0.75287988, 0.82471091, 0.68163309])}}\n",
      "2023-09-25 17:10:45,672 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 17:10:45,675 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 17:10:45,917 - Pipeline - INFO - dirName: 80_20_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 17:10:45,918 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 17:10:45,918 - Pipeline - INFO - Reading data\n",
      "2023-09-25 17:10:46,219 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 17:10:46,227 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 17:13:25,855 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 17:13:25,857 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:13:25,857 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:13:25,858 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:14:26,720 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:14:52,093 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:14:58,809 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:15:03,200 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:15:56,414 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:15:59,740 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.35, 'n_estimators': 80, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.3, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 17:15:59,742 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:16:01,847 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 17:16:01,848 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:16:01,849 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:16:01,849 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:16:35,912 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:16:46,162 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:16:49,313 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:16:51,157 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:17:19,919 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:17:21,674 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.5, 'reg_alpha': 0.001}\n",
      "2023-09-25 17:17:21,676 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:17:23,216 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 17:17:23,217 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:17:26,781 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:17:26,782 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:17:27,877 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 17:17:27,879 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:17:28,500 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:17:28,501 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:17:29,439 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 17:17:29,441 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:17:46,887 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:17:46,890 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:17:50,141 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 17:17:50,143 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:18:01,229 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:18:01,230 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:18:03,645 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 17:18:03,646 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:18:05,803 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:18:22,806 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 17:18:22,808 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:18:24,161 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:18:35,376 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 17:18:35,377 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 17:18:35,377 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 17:18:35,383 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 17:18:35,384 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:19:05,680 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:19:13,873 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:19:17,192 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:19:18,986 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:19:48,506 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:19:50,279 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 120, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.2, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:19:50,280 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 17:19:50,847 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 17:20:43,197 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 17:20:43,198 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:20:43,199 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:20:43,200 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:21:10,846 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:21:22,801 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:21:28,097 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:21:31,883 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:22:21,112 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:22:24,707 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.4, 'n_estimators': 170, 'min_child_weight': 1, 'gamma': 0.4, 'colsample_bytree': 0.9, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 17:22:24,709 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:22:27,054 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 17:22:27,056 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:22:27,648 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:22:27,650 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.1178925 , 0.11865664, 0.11730766, 0.11816454, 0.11653686]), 'score_time': array([0.02501273, 0.02477837, 0.02459836, 0.02488899, 0.02404094]), 'test_accuracy': array([0.90666667, 0.91333333, 0.91333333, 0.89666667, 0.92      ]), 'test_balanced_accuracy': array([0.78191153, 0.79246079, 0.81166045, 0.78208735, 0.8125    ]), 'test_average_precision': array([0.8497334 , 0.81072462, 0.79097367, 0.78193471, 0.83421922]), 'test_f1': array([0.70833333, 0.72916667, 0.74509804, 0.69306931, 0.76      ]), 'test_roc_auc': array([0.94528448, 0.89556228, 0.91398833, 0.88810746, 0.905     ]), 'test_mccf1_score': array([0.76502998, 0.78227904, 0.79211655, 0.7495127 , 0.80622359])}, 'lr': {'fit_time': array([0.03046846, 0.0304749 , 0.03155994, 0.0274837 , 0.02978945]), 'score_time': array([0.01057744, 0.01015544, 0.01033044, 0.00985813, 0.00993824]), 'test_accuracy': array([0.9 , 0.91, 0.9 , 0.91, 0.92]), 'test_balanced_accuracy': array([0.80976159, 0.7903861 , 0.80976159, 0.80958577, 0.83125   ]), 'test_average_precision': array([0.77008019, 0.8333938 , 0.7900084 , 0.76109989, 0.82604899]), 'test_f1': array([0.72222222, 0.72164948, 0.72222222, 0.73786408, 0.77358491]), 'test_roc_auc': array([0.94894156, 0.89886771, 0.90252479, 0.86651663, 0.90611111]), 'test_mccf1_score': array([0.77084039, 0.77541303, 0.77084039, 0.78567498, 0.81458642])}, 'lgbm': {'fit_time': array([0.2441237 , 0.2306211 , 0.24052095, 0.23900986, 0.23635721]), 'score_time': array([0.01302242, 0.01227021, 0.01234269, 0.01262712, 0.01211405]), 'test_accuracy': array([0.92      , 0.90666667, 0.90333333, 0.91      , 0.91      ]), 'test_balanced_accuracy': array([0.80301006, 0.77551164, 0.7990365 , 0.79678599, 0.78125   ]), 'test_average_precision': array([0.86698775, 0.83720517, 0.78676345, 0.80565504, 0.85350431]), 'test_f1': array([0.75      , 0.70212766, 0.7184466 , 0.72727273, 0.71578947]), 'test_roc_auc': array([0.95463816, 0.91898164, 0.91356635, 0.89528096, 0.92541667]), 'test_mccf1_score': array([0.79952416, 0.76128657, 0.76959261, 0.77888759, 0.77290634])}, 'mlp': {'fit_time': array([1.63434815, 1.63151979, 1.54065752, 1.60670781, 1.69461417]), 'score_time': array([0.01225758, 0.01206017, 0.01201391, 0.01211548, 0.0117712 ]), 'test_accuracy': array([0.87333333, 0.89666667, 0.89      , 0.88      , 0.91      ]), 'test_balanced_accuracy': array([0.76756453, 0.78848724, 0.82273718, 0.78451368, 0.81875   ]), 'test_average_precision': array([0.6919173 , 0.75380765, 0.76353696, 0.7229437 , 0.79626031]), 'test_f1': array([0.64814815, 0.69902913, 0.71794872, 0.67272727, 0.74766355]), 'test_roc_auc': array([0.89457768, 0.86827484, 0.87432309, 0.83493917, 0.87152778]), 'test_mccf1_score': array([0.70941928, 0.75350975, 0.76522782, 0.72918216, 0.79270393])}, 'xgb_min': {'fit_time': array([0.06676364, 0.06436777, 0.06395292, 0.06496644, 0.16487527]), 'score_time': array([0.01347256, 0.01251173, 0.01263189, 0.01452446, 0.01296687]), 'test_accuracy': array([0.89333333, 0.91      , 0.91333333, 0.88333333, 0.91333333]), 'test_balanced_accuracy': array([0.74161333, 0.77758633, 0.82446023, 0.74818904, 0.78958333]), 'test_average_precision': array([0.80264453, 0.77074989, 0.77813513, 0.7533961 , 0.81783694]), 'test_f1': array([0.64444444, 0.70967742, 0.75471698, 0.63917526, 0.72916667]), 'test_roc_auc': array([0.90266545, 0.86440678, 0.89148323, 0.87200225, 0.89423611]), 'test_mccf1_score': array([0.71675077, 0.76829609, 0.79844847, 0.70711344, 0.78325522])}, 'lr_min': {'fit_time': array([0.01746273, 0.01301813, 0.01387835, 0.0124042 , 0.01403236]), 'score_time': array([0.00893331, 0.00880003, 0.008461  , 0.0085125 , 0.00877118]), 'test_accuracy': array([0.88333333, 0.90333333, 0.90666667, 0.88666667, 0.90333333]), 'test_balanced_accuracy': array([0.75458893, 0.78623673, 0.80751108, 0.76306351, 0.78333333]), 'test_average_precision': array([0.76021424, 0.82078107, 0.79869585, 0.70531063, 0.80047565]), 'test_f1': array([0.64646465, 0.70707071, 0.73076923, 0.66      , 0.70707071]), 'test_roc_auc': array([0.91806737, 0.91300373, 0.90737745, 0.84703566, 0.890625  ]), 'test_mccf1_score': array([0.71197354, 0.76216093, 0.77937418, 0.72264014, 0.76295837])}, 'lgbm_min': {'fit_time': array([0.14988279, 0.16483212, 0.14839935, 0.15119195, 0.14961815]), 'score_time': array([0.01165032, 0.0111599 , 0.01070809, 0.01075387, 0.01067734]), 'test_accuracy': array([0.91      , 0.89      , 0.90666667, 0.89      , 0.91666667]), 'test_balanced_accuracy': array([0.77758633, 0.77153808, 0.7947113 , 0.75233842, 0.79166667]), 'test_average_precision': array([0.81262468, 0.76863714, 0.7905095 , 0.71051934, 0.82910548]), 'test_f1': array([0.70967742, 0.67326733, 0.72      , 0.65263158, 0.73684211]), 'test_roc_auc': array([0.90182151, 0.87094732, 0.88627892, 0.84105774, 0.89798611]), 'test_mccf1_score': array([0.76829609, 0.73311408, 0.77232454, 0.71957169, 0.7903507 ])}, 'mlp_min': {'fit_time': array([1.04522514, 1.04250121, 1.04120731, 1.05443883, 1.03460312]), 'score_time': array([0.00982618, 0.00976634, 0.0098815 , 0.0097456 , 0.00985932]), 'test_accuracy': array([0.86      , 0.86333333, 0.88666667, 0.84333333, 0.87666667]), 'test_balanced_accuracy': array([0.76566566, 0.76134046, 0.82706238, 0.73609255, 0.76041667]), 'test_average_precision': array([0.64562801, 0.73647689, 0.76223736, 0.62255606, 0.71870043]), 'test_f1': array([0.63157895, 0.63063063, 0.71666667, 0.5840708 , 0.64761905]), 'test_roc_auc': array([0.80786272, 0.82333497, 0.87488572, 0.75624165, 0.82875   ]), 'test_mccf1_score': array([0.69397067, 0.69396024, 0.76377224, 0.65474644, 0.71056019])}, 'xgb_ensemble': {'fit_time': array([0.14253378, 0.23193598, 0.13260865, 0.13542604, 0.13609958]), 'score_time': array([0.01788616, 0.01727438, 0.01700926, 0.01766324, 0.01751423]), 'test_accuracy': array([0.92      , 0.90666667, 0.91333333, 0.92666667, 0.93333333]), 'test_balanced_accuracy': array([0.83243089, 0.80416667, 0.80833333, 0.82916667, 0.88333333]), 'test_average_precision': array([0.8092024 , 0.81740672, 0.82194908, 0.78568133, 0.80307137]), 'test_f1': array([0.76923077, 0.73076923, 0.74509804, 0.78431373, 0.82758621]), 'test_roc_auc': array([0.84696495, 0.90277778, 0.89138889, 0.87833333, 0.89583333]), 'test_mccf1_score': array([0.81072054, 0.77994448, 0.7927895 , 0.82528426, 0.85670991])}, 'lr_ensemble': {'fit_time': array([0.01219296, 0.01054049, 0.00916004, 0.0097611 , 0.01000929]), 'score_time': array([0.01071906, 0.00926495, 0.0093112 , 0.00918341, 0.009202  ]), 'test_accuracy': array([0.9       , 0.89333333, 0.91333333, 0.92      , 0.92      ]), 'test_balanced_accuracy': array([0.76759761, 0.78333333, 0.83333333, 0.825     , 0.85      ]), 'test_average_precision': array([0.82883099, 0.79243205, 0.84978181, 0.82699181, 0.8477972 ]), 'test_f1': array([0.68085106, 0.69230769, 0.76363636, 0.76923077, 0.78571429]), 'test_roc_auc': array([0.89740667, 0.91861111, 0.94222222, 0.90416667, 0.91222222]), 'test_mccf1_score': array([0.74269566, 0.74806093, 0.80493989, 0.81182528, 0.8227174 ])}}\n",
      "2023-09-25 17:22:28,548 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 17:22:28,551 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 17:22:28,809 - Pipeline - INFO - dirName: 85_15_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 17:22:28,810 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 17:22:28,811 - Pipeline - INFO - Reading data\n",
      "2023-09-25 17:22:29,157 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 17:22:29,165 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 17:24:22,016 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 17:24:22,017 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:24:22,018 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:24:22,018 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:25:20,443 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:25:46,484 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:25:54,570 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:26:00,621 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:27:05,124 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:27:09,592 - Pipeline - INFO - params: {'max_depth': 6, 'scale_pos_weight': 0.4, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.7, 'reg_alpha': 0}\n",
      "2023-09-25 17:27:09,593 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:27:12,228 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 17:27:12,229 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:27:12,230 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:27:12,231 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:27:46,169 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:28:03,489 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:28:06,188 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:28:08,095 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:28:33,045 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:28:34,754 - Pipeline - INFO - params: {'max_depth': 6, 'scale_pos_weight': 0.4, 'n_estimators': 50, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.4, 'subsample': 0.9, 'reg_alpha': 0.001}\n",
      "2023-09-25 17:28:34,755 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:28:36,224 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 17:28:36,225 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:28:40,274 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:28:40,276 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:28:41,372 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 17:28:41,373 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:28:42,023 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:28:42,024 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:28:42,991 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 17:28:42,992 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:29:00,015 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:29:00,016 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:29:02,489 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 17:29:02,490 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:29:14,019 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:29:14,020 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:29:15,813 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 17:29:15,814 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:29:17,542 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:29:33,176 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 17:29:33,177 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:29:34,537 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:29:45,692 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 17:29:45,693 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 17:29:45,693 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 17:29:45,700 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 17:29:45,700 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:30:21,054 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:30:29,472 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:30:32,794 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:30:34,948 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:31:04,278 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:31:05,827 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.25, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:31:05,828 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 17:31:06,345 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 17:32:01,825 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 17:32:01,827 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:32:01,828 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:32:01,828 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:32:28,923 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:32:37,144 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:32:39,341 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:32:40,616 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:33:00,876 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:33:02,311 - Pipeline - INFO - params: {'max_depth': 1, 'scale_pos_weight': 0.15, 'n_estimators': 80, 'min_child_weight': 2, 'gamma': 0.0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:33:02,314 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:33:03,587 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 17:33:03,588 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:33:04,241 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:33:04,242 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.15948296, 0.16921115, 0.15621185, 0.1569078 , 0.16115832]), 'score_time': array([0.02586007, 0.0253222 , 0.02517962, 0.0252912 , 0.02554679]), 'test_accuracy': array([0.94666667, 0.92      , 0.91666667, 0.92333333, 0.95      ]), 'test_balanced_accuracy': array([0.82759233, 0.7837358 , 0.74052288, 0.7627451 , 0.84248366]), 'test_average_precision': array([0.81202576, 0.77951531, 0.71550407, 0.79215154, 0.88201158]), 'test_f1': array([0.78378378, 0.68421053, 0.63768116, 0.67605634, 0.80519481]), 'test_roc_auc': array([0.91699219, 0.92693537, 0.88784314, 0.89812636, 0.95546841]), 'test_mccf1_score': array([0.82726531, 0.74476821, 0.71284085, 0.74244057, 0.84390515])}, 'lr': {'fit_time': array([0.03017092, 0.02959275, 0.02818799, 0.02983069, 0.02954173]), 'score_time': array([0.03361011, 0.01112318, 0.00955558, 0.01043749, 0.00944781]), 'test_accuracy': array([0.91      , 0.92      , 0.91      , 0.92      , 0.94333333]), 'test_balanced_accuracy': array([0.80610795, 0.7837358 , 0.73660131, 0.77908497, 0.84771242]), 'test_average_precision': array([0.80268384, 0.72313982, 0.65953242, 0.77367306, 0.7951821 ]), 'test_f1': array([0.68235294, 0.68421053, 0.61971831, 0.68421053, 0.79012346]), 'test_roc_auc': array([0.9317294 , 0.86363636, 0.90065359, 0.89716776, 0.93124183]), 'test_mccf1_score': array([0.74016758, 0.74476821, 0.69627247, 0.74552043, 0.82977138])}, 'lgbm': {'fit_time': array([0.15926933, 0.154387  , 0.25244474, 0.14996028, 0.15280628]), 'score_time': array([0.01194406, 0.01180959, 0.01188612, 0.01218629, 0.01191688]), 'test_accuracy': array([0.93333333, 0.92666667, 0.90666667, 0.92      , 0.94333333]), 'test_balanced_accuracy': array([0.78213778, 0.76882102, 0.69803922, 0.74248366, 0.81111111]), 'test_average_precision': array([0.82720566, 0.77278349, 0.73426419, 0.79226261, 0.8502832 ]), 'test_f1': array([0.71428571, 0.68571429, 0.5625    , 0.64705882, 0.76712329]), 'test_roc_auc': array([0.92205256, 0.91441761, 0.89063181, 0.90379085, 0.93673203]), 'test_mccf1_score': array([0.77336736, 0.74998828, 0.65695032, 0.72157332, 0.81536037])}, 'mlp': {'fit_time': array([1.47130585, 1.51574039, 1.60381961, 1.40841913, 1.43945932]), 'score_time': array([0.01204276, 0.01192045, 0.01179338, 0.01178122, 0.0119772 ]), 'test_accuracy': array([0.92333333, 0.90666667, 0.90333333, 0.90666667, 0.93333333]), 'test_balanced_accuracy': array([0.84215199, 0.75710227, 0.76928105, 0.77124183, 0.83267974]), 'test_average_precision': array([0.81269855, 0.70357448, 0.60895048, 0.74565476, 0.76553432]), 'test_f1': array([0.73563218, 0.63157895, 0.64197531, 0.65      , 0.75609756]), 'test_roc_auc': array([0.91557173, 0.83620384, 0.86466231, 0.87102397, 0.91089325]), 'test_mccf1_score': array([0.78345773, 0.70175367, 0.7085871 , 0.71555081, 0.80158598])}, 'xgb_min': {'fit_time': array([0.06735921, 0.06442881, 0.06436419, 0.06534147, 0.06510282]), 'score_time': array([0.01319408, 0.01237369, 0.01250601, 0.01234317, 0.01234698]), 'test_accuracy': array([0.91      , 0.90333333, 0.89333333, 0.90333333, 0.91666667]), 'test_balanced_accuracy': array([0.71200284, 0.7175071 , 0.65359477, 0.70522876, 0.72222222]), 'test_average_precision': array([0.69955521, 0.67428404, 0.67560872, 0.63279035, 0.71612727]), 'test_f1': array([0.58461538, 0.57971014, 0.46666667, 0.56716418, 0.61538462]), 'test_roc_auc': array([0.89044744, 0.85200639, 0.8540305 , 0.80906318, 0.87058824]), 'test_mccf1_score': array([0.67212792, 0.66403416, 0.58399178, 0.65702887, 0.69915538])}, 'lr_min': {'fit_time': array([0.01451397, 0.01491952, 0.01425672, 0.01414275, 0.01381564]), 'score_time': array([0.00880075, 0.00932288, 0.00815964, 0.00825906, 0.00808501]), 'test_accuracy': array([0.89333333, 0.9       , 0.90666667, 0.9       , 0.92      ]), 'test_balanced_accuracy': array([0.71164773, 0.734375  , 0.70718954, 0.72156863, 0.76078431]), 'test_average_precision': array([0.6493849 , 0.637649  , 0.69967812, 0.67294398, 0.74213777]), 'test_f1': array([0.55555556, 0.59459459, 0.57575758, 0.58333333, 0.66666667]), 'test_roc_auc': array([0.85555753, 0.82581676, 0.86884532, 0.85594771, 0.88357298]), 'test_mccf1_score': array([0.64195734, 0.6726187 , 0.66526128, 0.66564664, 0.73391517])}, 'lgbm_min': {'fit_time': array([0.1062541 , 0.10365629, 0.11155128, 0.10496402, 0.10982585]), 'score_time': array([0.01015115, 0.0097611 , 0.01031947, 0.00975895, 0.00967002]), 'test_accuracy': array([0.9       , 0.89666667, 0.88666667, 0.91333333, 0.92      ]), 'test_balanced_accuracy': array([0.68732244, 0.72301136, 0.6496732 , 0.72026144, 0.73333333]), 'test_average_precision': array([0.61494805, 0.66417322, 0.66142499, 0.68687816, 0.75352034]), 'test_f1': array([0.53125   , 0.57534247, 0.4516129 , 0.60606061, 0.63636364]), 'test_roc_auc': array([0.84561435, 0.84818892, 0.84801743, 0.84854031, 0.8908061 ]), 'test_mccf1_score': array([0.62943474, 0.65748781, 0.56813995, 0.69019658, 0.7151154 ])}, 'mlp_min': {'fit_time': array([1.03782344, 1.0544064 , 1.04566741, 1.03123999, 1.05140996]), 'score_time': array([0.01012111, 0.01330876, 0.0098381 , 0.00943494, 0.01454926]), 'test_accuracy': array([0.85333333, 0.87      , 0.86      , 0.90333333, 0.87333333]), 'test_balanced_accuracy': array([0.67879972, 0.70738636, 0.66143791, 0.76013072, 0.70588235]), 'test_average_precision': array([0.5433936 , 0.5762231 , 0.505464  , 0.62841774, 0.59572432]), 'test_f1': array([0.46341463, 0.51851852, 0.44736842, 0.63291139, 0.525     ]), 'test_roc_auc': array([0.80530895, 0.75097656, 0.78056645, 0.80244009, 0.73551198]), 'test_mccf1_score': array([0.56187291, 0.60726325, 0.55173169, 0.70200886, 0.61330559])}, 'xgb_ensemble': {'fit_time': array([0.04535365, 0.04181027, 0.04232955, 0.04231811, 0.04211879]), 'score_time': array([0.0171032 , 0.01646996, 0.01578069, 0.01664686, 0.01561904]), 'test_accuracy': array([0.94      , 0.91333333, 0.93333333, 0.95333333, 0.88      ]), 'test_balanced_accuracy': array([0.79615385, 0.69047619, 0.76190476, 0.83333333, 0.59136213]), 'test_average_precision': array([0.80483043, 0.62973489, 0.73905888, 0.83502681, 0.59511539]), 'test_f1': array([0.72727273, 0.55172414, 0.6875    , 0.8       , 0.30769231]), 'test_roc_auc': array([0.93923077, 0.8593577 , 0.88815061, 0.90217793, 0.85418974]), 'test_mccf1_score': array([0.78252177, 0.65119558, 0.75446575, 0.84112092, 0.45968777])}, 'lr_ensemble': {'fit_time': array([0.00607634, 0.00565219, 0.00587201, 0.00583696, 0.00626063]), 'score_time': array([0.00999427, 0.0094099 , 0.00934815, 0.00920653, 0.0091579 ]), 'test_accuracy': array([0.93333333, 0.9       , 0.92666667, 0.94666667, 0.88666667]), 'test_balanced_accuracy': array([0.79230769, 0.68272425, 0.77796235, 0.80952381, 0.61517165]), 'test_average_precision': array([0.80828343, 0.59511509, 0.75450086, 0.85673999, 0.61036368]), 'test_f1': array([0.70588235, 0.51612903, 0.68571429, 0.76470588, 0.37037037]), 'test_roc_auc': array([0.92115385, 0.80324843, 0.88002953, 0.92801772, 0.87264673]), 'test_mccf1_score': array([0.76377782, 0.61622928, 0.74786029, 0.81378914, 0.50802055])}}\n",
      "2023-09-25 17:33:05,031 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 17:33:05,034 - Pipeline - INFO - Completed !!!\n",
      "2023-09-25 17:33:05,275 - Pipeline - INFO - dirName: 90_10_samples_icd_vb_0_va_72_lb_0_la_72\n",
      "2023-09-25 17:33:05,276 - Pipeline - INFO - Running Predictions for vb_0_va_72_lb_0_la_72, targetStart : 0, targetEnd : 7\n",
      "2023-09-25 17:33:05,276 - Pipeline - INFO - Reading data\n",
      "2023-09-25 17:33:05,592 - Pipeline - INFO - Formatting data\n",
      "2023-09-25 17:33:05,600 - Pipeline - INFO - Performing SFS\n",
      "2023-09-25 17:35:12,373 - Pipeline - INFO - Building XGBoost model with all the features\n",
      "2023-09-25 17:35:12,374 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:35:12,375 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:35:12,375 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:36:07,481 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:36:31,967 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:36:37,357 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:36:41,146 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:37:24,925 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:37:28,108 - Pipeline - INFO - params: {'max_depth': 8, 'scale_pos_weight': 0.35, 'n_estimators': 60, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:37:28,110 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:37:30,235 - Pipeline - INFO - Building XGBoost model with the selected features\n",
      "2023-09-25 17:37:30,237 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:37:30,237 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:37:30,238 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:37:59,587 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:38:12,387 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:38:15,949 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:38:18,586 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:38:52,487 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:38:54,834 - Pipeline - INFO - params: {'max_depth': 4, 'scale_pos_weight': 0.3, 'n_estimators': 100, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.9, 'reg_alpha': 0}\n",
      "2023-09-25 17:38:54,837 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:38:56,715 - Pipeline - INFO - Building LR model with all the features\n",
      "2023-09-25 17:38:56,717 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:39:00,001 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:00,002 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:39:01,030 - Pipeline - INFO - Building LR model with the selected features\n",
      "2023-09-25 17:39:01,032 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:39:01,653 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:01,655 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:39:02,519 - Pipeline - INFO - Building LGBM model with all the features\n",
      "2023-09-25 17:39:02,521 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:39:19,711 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:19,717 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:39:22,795 - Pipeline - INFO - Building LGBM model with the selected features\n",
      "2023-09-25 17:39:22,797 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:39:34,875 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:34,877 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:39:37,734 - Pipeline - INFO - Building MLP model with all the features\n",
      "2023-09-25 17:39:37,735 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:39,583 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:39:55,021 - Pipeline - INFO - Building MLP model with the selected features\n",
      "2023-09-25 17:39:55,022 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:39:56,497 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:40:08,197 - Pipeline - INFO - Get Outputs from first level models\n",
      "2023-09-25 17:40:08,199 - Pipeline - INFO - Obtaining output probabilities\n",
      "2023-09-25 17:40:08,199 - Pipeline - INFO - Split data to test and train sets\n",
      "2023-09-25 17:40:08,206 - Pipeline - INFO - Performing Hyperparameter optimisation for XGBoost\n",
      "2023-09-25 17:40:08,207 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:40:36,658 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:40:45,116 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:40:46,784 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:40:47,727 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:41:01,775 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:41:02,688 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.4, 'n_estimators': 50, 'min_child_weight': 3, 'gamma': 0.0, 'colsample_bytree': 0.9, 'subsample': 0.8, 'reg_alpha': 0}\n",
      "2023-09-25 17:41:02,690 - Pipeline - INFO - Performing Hyperparameter optimisation for Logistic Regression\n",
      "2023-09-25 17:41:03,242 - Pipeline - INFO - Building individual models\n",
      "2023-09-25 17:41:53,899 - Pipeline - INFO - Building Ensemble XGBoost model with all the features\n",
      "2023-09-25 17:41:53,902 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:41:53,903 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:41:53,904 - Pipeline - INFO - Hyperparameter optimisation for: {'max_depth': range(1, 10), 'scale_pos_weight': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]}\n",
      "2023-09-25 17:42:19,143 - Pipeline - INFO - Hyperparameter optimisation for: {'n_estimators': range(50, 250, 10)}\n",
      "2023-09-25 17:42:28,942 - Pipeline - INFO - Hyperparameter optimisation for: {'min_child_weight': range(1, 10)}\n",
      "2023-09-25 17:42:31,457 - Pipeline - INFO - Hyperparameter optimisation for: {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
      "2023-09-25 17:42:33,055 - Pipeline - INFO - Hyperparameter optimisation for: {'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
      "2023-09-25 17:42:55,876 - Pipeline - INFO - Hyperparameter optimisation for: {'reg_alpha': [0, 1e-05, 0.001, 0.1, 10]}\n",
      "2023-09-25 17:42:57,374 - Pipeline - INFO - params: {'max_depth': 2, 'scale_pos_weight': 0.25, 'n_estimators': 80, 'min_child_weight': 1, 'gamma': 0.0, 'colsample_bytree': 0.8, 'subsample': 0.6, 'reg_alpha': 0}\n",
      "2023-09-25 17:42:57,375 - Pipeline - INFO - Performing cross-validation\n",
      "2023-09-25 17:42:58,850 - Pipeline - INFO - Building Ensemble LR model with all the features\n",
      "2023-09-25 17:42:58,851 - Pipeline - INFO - Performing Hyperparameter optimisation\n",
      "2023-09-25 17:42:59,429 - Pipeline - INFO - Building the model\n",
      "2023-09-25 17:42:59,430 - Pipeline - INFO - Performing cross-validation\n",
      "Scores:  {'xgb': {'fit_time': array([0.10844398, 0.11103749, 0.1083622 , 0.11713386, 0.13678122]), 'score_time': array([0.0259726 , 0.02430272, 0.02381659, 0.02486467, 0.02385497]), 'test_accuracy': array([0.93666667, 0.95333333, 0.94666667, 0.95333333, 0.95333333]), 'test_balanced_accuracy': array([0.68781015, 0.77401705, 0.73333333, 0.82592593, 0.76666667]), 'test_average_precision': array([0.69269931, 0.76613749, 0.71896254, 0.80628031, 0.79952367]), 'test_f1': array([0.53658537, 0.69565217, 0.63636364, 0.74074074, 0.69565217]), 'test_roc_auc': array([0.90558595, 0.93663316, 0.86654321, 0.95666667, 0.92654321]), 'test_mccf1_score': array([0.63823421, 0.76014482, 0.71671745, 0.79179372, 0.76193103])}, 'lr': {'fit_time': array([0.02692056, 0.02644849, 0.0284977 , 0.02748609, 0.02705765]), 'score_time': array([0.00992894, 0.00996256, 0.00939226, 0.00983787, 0.00933862]), 'test_accuracy': array([0.94333333, 0.93666667, 0.95333333, 0.94333333, 0.94666667]), 'test_balanced_accuracy': array([0.768482  , 0.76479196, 0.78148148, 0.80555556, 0.77777778]), 'test_average_precision': array([0.66093427, 0.70630743, 0.70921187, 0.75753821, 0.65264509]), 'test_f1': array([0.65306122, 0.62745098, 0.70833333, 0.69090909, 0.68      ]), 'test_roc_auc': array([0.88459091, 0.90520422, 0.87506173, 0.93950617, 0.87987654]), 'test_mccf1_score': array([0.72298934, 0.70106165, 0.76986096, 0.75112783, 0.7451171 ])}, 'lgbm': {'fit_time': array([0.23317742, 0.22938561, 0.22584558, 0.22756553, 0.23390055]), 'score_time': array([0.01214314, 0.01220822, 0.01235366, 0.0121758 , 0.01212525]), 'test_accuracy': array([0.94666667, 0.94666667, 0.94333333, 0.95333333, 0.95333333]), 'test_balanced_accuracy': array([0.72413793, 0.73953429, 0.71666667, 0.7962963 , 0.76666667]), 'test_average_precision': array([0.74272117, 0.75622253, 0.71093037, 0.82117603, 0.81687523]), 'test_f1': array([0.61904762, 0.63636364, 0.60465116, 0.72      , 0.69565217]), 'test_roc_auc': array([0.93116173, 0.95062985, 0.85703704, 0.95259259, 0.94111111]), 'test_mccf1_score': array([0.70365206, 0.71457486, 0.69261292, 0.77747382, 0.76193103])}, 'mlp': {'fit_time': array([1.43497896, 1.43890595, 1.47653031, 1.41848469, 1.56921577]), 'score_time': array([0.01368189, 0.01314354, 0.01239729, 0.01254153, 0.01315737]), 'test_accuracy': array([0.92      , 0.91666667, 0.93      , 0.94      , 0.94      ]), 'test_balanced_accuracy': array([0.72477414, 0.73832549, 0.70925926, 0.78888889, 0.75925926]), 'test_average_precision': array([0.55628128, 0.68697415, 0.62111834, 0.68979547, 0.67654022]), 'test_f1': array([0.53846154, 0.54545455, 0.55319149, 0.66666667, 0.64      ]), 'test_roc_auc': array([0.84705433, 0.89489757, 0.81555556, 0.90185185, 0.86012346]), 'test_mccf1_score': array([0.62872219, 0.63328987, 0.64514879, 0.73194527, 0.71275669])}, 'xgb_min': {'fit_time': array([0.0934782 , 0.18892193, 0.08834982, 0.08898592, 0.0911212 ]), 'score_time': array([0.01380014, 0.01342654, 0.01270342, 0.01304984, 0.01272273]), 'test_accuracy': array([0.94666667, 0.95333333, 0.94      , 0.95666667, 0.95666667]), 'test_balanced_accuracy': array([0.73953429, 0.77401705, 0.7       , 0.82777778, 0.78333333]), 'test_average_precision': array([0.69842288, 0.75748652, 0.68241794, 0.79509353, 0.78107684]), 'test_f1': array([0.63636364, 0.69565217, 0.57142857, 0.75471698, 0.72340426]), 'test_roc_auc': array([0.89031683, 0.92365441, 0.89296296, 0.94469136, 0.93419753]), 'test_mccf1_score': array([0.71457486, 0.76014482, 0.66740622, 0.80356811, 0.78317699])}, 'lr_min': {'fit_time': array([0.01414323, 0.01251173, 0.01212478, 0.01140261, 0.0133431 ]), 'score_time': array([0.00861144, 0.00813079, 0.00803232, 0.00824857, 0.00806856]), 'test_accuracy': array([0.93666667, 0.94333333, 0.94333333, 0.95      , 0.95      ]), 'test_balanced_accuracy': array([0.70320651, 0.768482  , 0.73148148, 0.82407407, 0.77962963]), 'test_average_precision': array([0.61524049, 0.68576601, 0.65261535, 0.78491174, 0.72659333]), 'test_f1': array([0.55813953, 0.65306122, 0.62222222, 0.72727273, 0.69387755]), 'test_roc_auc': array([0.86105102, 0.92747169, 0.86197531, 0.94283951, 0.88580247]), 'test_mccf1_score': array([0.65243814, 0.72298934, 0.70368087, 0.78050706, 0.7571891 ])}, 'lgbm_min': {'fit_time': array([0.19115853, 0.18690205, 0.28446007, 0.18720627, 0.18607259]), 'score_time': array([0.01170468, 0.01171803, 0.01147962, 0.01154613, 0.01155829]), 'test_accuracy': array([0.94333333, 0.95666667, 0.94333333, 0.96      , 0.96      ]), 'test_balanced_accuracy': array([0.73768927, 0.79125843, 0.71666667, 0.84444444, 0.8       ]), 'test_average_precision': array([0.7322666 , 0.81597479, 0.67561828, 0.83426216, 0.84178878]), 'test_f1': array([0.62222222, 0.72340426, 0.60465116, 0.77777778, 0.75      ]), 'test_roc_auc': array([0.89769691, 0.95724647, 0.87185185, 0.95580247, 0.95740741]), 'test_mccf1_score': array([0.70180641, 0.78155556, 0.69261292, 0.82171722, 0.80359652])}, 'mlp_min': {'fit_time': array([1.1392355 , 1.128896  , 1.07342768, 1.08053017, 1.07497907]), 'score_time': array([0.01082897, 0.01251459, 0.01013112, 0.01062012, 0.0104208 ]), 'test_accuracy': array([0.93      , 0.94      , 0.92666667, 0.93      , 0.93      ]), 'test_balanced_accuracy': array([0.71491284, 0.81282606, 0.67777778, 0.82777778, 0.73888889]), 'test_average_precision': array([0.51089815, 0.75467662, 0.56193926, 0.70912306, 0.66750091]), 'test_f1': array([0.55319149, 0.67857143, 0.5       , 0.66666667, 0.58823529]), 'test_roc_auc': array([0.74093396, 0.92708996, 0.80271605, 0.91592593, 0.88592593]), 'test_mccf1_score': array([0.64381621, 0.74053917, 0.60561425, 0.73018062, 0.67018029])}, 'xgb_ensemble': {'fit_time': array([0.05386853, 0.05367208, 0.1410892 , 0.05155587, 0.05068612]), 'score_time': array([0.0169127 , 0.01656938, 0.01608706, 0.016258  , 0.01570177]), 'test_accuracy': array([0.95333333, 0.94666667, 0.94      , 0.95333333, 0.96      ]), 'test_balanced_accuracy': array([0.73076923, 0.7619315 , 0.72346996, 0.73076923, 0.78571429]), 'test_average_precision': array([0.76143236, 0.75369504, 0.41898204, 0.79592852, 0.73695486]), 'test_f1': array([0.63157895, 0.63636364, 0.57142857, 0.63157895, 0.72727273]), 'test_roc_auc': array([0.89724874, 0.92083099, 0.79169006, 0.96069624, 0.8802521 ]), 'test_mccf1_score': array([0.71348155, 0.70998658, 0.65929671, 0.71348155, 0.78633208])}, 'lr_ensemble': {'fit_time': array([0.00586438, 0.00582361, 0.00578189, 0.00568223, 0.0060358 ]), 'score_time': array([0.00986409, 0.009583  , 0.00924158, 0.00997639, 0.00956702]), 'test_accuracy': array([0.96      , 0.94666667, 0.92666667, 0.96      , 0.96      ]), 'test_balanced_accuracy': array([0.76923077, 0.7619315 , 0.64654688, 0.76923077, 0.78571429]), 'test_average_precision': array([0.7381963 , 0.77716938, 0.51425367, 0.78175505, 0.78081362]), 'test_f1': array([0.7       , 0.63636364, 0.42105263, 0.7       , 0.72727273]), 'test_roc_auc': array([0.9079169 , 0.92083099, 0.8826502 , 0.95115104, 0.93592437]), 'test_mccf1_score': array([0.76564219, 0.70998658, 0.54226288, 0.76564219, 0.78633208])}}\n",
      "2023-09-25 17:43:00,273 - Pipeline - INFO - Saving the CV results for all the models\n",
      "2023-09-25 17:43:00,276 - Pipeline - INFO - Completed !!!\n"
     ]
    }
   ],
   "source": [
    "for (negativeSize, positiveSize, label) in dataSizeList:\n",
    "    sampledDataMatrix = pd.concat([dataMatrixPositive.sample(n=positiveSize), dataMatrixNegative.sample(n=negativeSize)]).sample(frac=1).reset_index(drop=True)\n",
    "    sampledDataMatrix.to_csv(dataDirName + 'data_matrix.csv', index=False)\n",
    "    pm.runPredictionsForAllTargets(\n",
    "        label=label + '_samples',\n",
    "        dirPath = dataDirName,\n",
    "        vitalsBefore = 0,\n",
    "        vitalsAfter = 72,\n",
    "        labsBefore = 0,\n",
    "        labsAfter = 72,\n",
    "        targetList = [7],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the data matrix file from working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.system(\n",
    "    '''rm ''' + dataDirName + '''data_matrix.csv'''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
